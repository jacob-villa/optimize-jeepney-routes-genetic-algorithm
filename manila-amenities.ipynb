{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing the Connectivity, Robustness, and Vulnerability of Jeepney Route Networks Using Genetic Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import shapely\n",
    "import folium\n",
    "import geojson\n",
    "import math\n",
    "import osmnx as ox\n",
    "from rtree import index as rtree_index\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "from shapely.ops import unary_union\n",
    "from shapely.geometry import Polygon, MultiPolygon, LineString, Point\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "from __future__ import absolute_import, division\n",
    "from math import radians, sin, cos, sqrt, atan2, exp, log\n",
    "import webbrowser\n",
    "import random\n",
    "from scipy.spatial import KDTree\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "ox.settings.log_console=True\n",
    "ox.settings.use_cache=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining classes for the dataframes\n",
    "class AmenityPoint:\n",
    "    def __init__(self, geometry, lat, lon, amenity, name, addr_city):\n",
    "        self.geometry = geometry\n",
    "        self.lat = lat\n",
    "        self.lon = lon\n",
    "        self.amenity = amenity\n",
    "        self.name = name\n",
    "        self.addr_city = addr_city\n",
    "\n",
    "class AmenityPolygon:\n",
    "    def __init__(self, geometry, lat, lon, amenity, name, addr_city):\n",
    "        self.geometry = geometry\n",
    "        self.lat = lat\n",
    "        self.lon = lon\n",
    "        self.amenity = amenity\n",
    "        self.name = name\n",
    "        self.addr_city = addr_city\n",
    "        \n",
    "class stopCandidate:\n",
    "    def __init__(self, lat, long, isTranspo, id, area):\n",
    "        self.lat = lat\n",
    "        self.long = long\n",
    "        self.isTranspo = isTranspo\n",
    "        self.enabled = False\n",
    "        self.id = id #node ID\n",
    "        self.area = area\n",
    "        self.degree = 0\n",
    "        \n",
    "    def enable(self):\n",
    "        self.enabled = True\n",
    "        \n",
    "    def disable(self):\n",
    "        self.enabled = False\n",
    "        \n",
    "    def getLat(self):\n",
    "        return self.lat\n",
    "    \n",
    "    def getLong(self):\n",
    "        return self.long\n",
    "    \n",
    "    def getArea(self):\n",
    "        return self.area\n",
    "    \n",
    "    def getDegree(self):\n",
    "        return self.degree\n",
    "    \n",
    "class networkObj():\n",
    "    def __init__(self, routes, stops, graph, conn_type):\n",
    "        self.routes = routes\n",
    "        self.stops = stops\n",
    "        self.fitness_score = 0\n",
    "        self.graph = graph\n",
    "        self.conn_type = conn_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For units\n",
    "def degrees_to_meters(angle_degrees):\n",
    "    return angle_degrees * 6371000 * math.pi / 180\n",
    "\n",
    "def meters_to_degrees(distance_meters):\n",
    "    return distance_meters / 6371000 * 180 / math.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and Export networks or graphs to pickle\n",
    "def export_networks(networks, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(networks, f)\n",
    "\n",
    "def import_networks(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        routes = pickle.load(f)\n",
    "    return routes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: SELECT THE CITY HERE, COMMENT OUT THE REMAINING CITIES\n",
    "select_city = \"Manila, Philippines\"\n",
    "city_file = 'map/Manila.graphml'\n",
    "\n",
    "# select_city = \"Makati, Philippines\"\n",
    "# city_file = 'map/Makati.graphml'\n",
    "\n",
    "# select_city = \"Mandaluyong, Philippines\"\n",
    "# city_file = 'map/Mandaluyong.graphml'\n",
    "\n",
    "\n",
    "# GENERATION OF MAIN CITY GRAPH\n",
    "# IF FIRST TIME RUNNING, RUN THIS CODE TO GENERATE THE GRAPH\n",
    "def generate_graph():\n",
    "    mode = 'drive'\n",
    "    graph = ox.graph_from_place(select_city, network_type = mode) # Generate graph of Metro manila\n",
    "    ox.save_graphml(graph, city_file) # Save it as a file\n",
    "\n",
    "def load_graph():\n",
    "    graph = ox.load_graphml(city_file)\n",
    "    \n",
    "    print(\"Graph loaded successfully\")\n",
    "    print(\"NUMBER OF EDGES: \", graph.number_of_edges())\n",
    "    print(\"NUMBER OF NODES: \", graph.number_of_nodes())\n",
    "    print('\\n')\n",
    "    return graph\n",
    "\n",
    "# NOTE: Only run this if you do not have the graph\n",
    "generate_graph()\n",
    "\n",
    "# THIS IS THE MAIN GRAPH FOR THE CITY TO BE USED FOR ALL FUNCTIONS\n",
    "CITY_GRAPH = load_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For Filtering the roads and other features\n",
    "# GETTING ROADS AND WATERWAYS\n",
    "\n",
    "# Get all the roads in Manila\n",
    "road = ox.graph_to_gdfs(CITY_GRAPH,nodes=False, edges=True)\n",
    "\n",
    "\n",
    "# Get all the roads that are not junctions (ex. Roundabouts, intersection, etc.)\n",
    "filtered_roads = road[road['junction'].isna()]\n",
    "\n",
    "# Separate roads whose widths are only one value and those that are more than 1 (lists)\n",
    "rows_with_lists = filtered_roads[filtered_roads['highway'].apply(lambda x: isinstance(x, list))]\n",
    "rows_with_strings = filtered_roads[filtered_roads['highway'].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "filter_options = ['primary', 'secondary', 'tertiary', 'trunk', 'unclassified']\n",
    "separation_options = ['primary', 'secondary', 'tertiary', 'unclassified']\n",
    "\n",
    "# Get the roads whose widths are above the threshold\n",
    "def check_list(lst):\n",
    "    return any(x in filter_options for x in lst)\n",
    "\n",
    "# Download OpenStreetMap data for the area of interest\n",
    "waterways = ox.features_from_place(select_city, tags={'waterway': True})\n",
    "filtered_rivers = waterways[waterways['waterway'].isin(['river'])]\n",
    "filtered_streams = waterways[waterways['waterway'].isin(['stream'])]\n",
    "\n",
    "# Get all the roads with the allowed road types\n",
    "filtered_roads_strings = rows_with_strings.loc[rows_with_strings['highway'].isin(filter_options)] \n",
    "filtered_roads_lists = rows_with_lists[rows_with_lists['highway'].apply(check_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will find which road or river intersects between amenities\n",
    "# Create spatial index\n",
    "filtered_roads_strings_sindex = filtered_roads_strings.sindex\n",
    "filtered_roads_lists_sindex = filtered_roads_lists.sindex\n",
    "filtered_rivers_sindex = filtered_rivers.sindex\n",
    "filtered_streams_sindex = filtered_streams.sindex\n",
    "\n",
    "def find_intersecting_features(line):\n",
    "    # Check intersection with filtered roads\n",
    "    possible_matches_roads = filtered_roads_strings.iloc[list(filtered_roads_strings_sindex.intersection(line.bounds))]\n",
    "    for index, row in possible_matches_roads.iterrows():\n",
    "        if line.intersects(row['geometry']) and row['highway'] in separation_options:\n",
    "            return True\n",
    "\n",
    "    possible_matches_lists = filtered_roads_lists.iloc[list(filtered_roads_lists_sindex.intersection(line.bounds))]\n",
    "    for index, row in possible_matches_lists.iterrows():\n",
    "        if line.intersects(row['geometry']):\n",
    "            list_highway = row['highway']\n",
    "            if any(x in separation_options for x in list_highway):\n",
    "                return True\n",
    "    \n",
    "    # Check intersection with filtered rivers\n",
    "    possible_matches_rivers = filtered_rivers.iloc[list(filtered_rivers_sindex.intersection(line.bounds))]\n",
    "    for index, row in possible_matches_rivers.iterrows():\n",
    "        if line.intersects(row['geometry']):\n",
    "            return True\n",
    "\n",
    "    # Check intersection with filtered streams\n",
    "    possible_matches_streams = filtered_streams.iloc[list(filtered_streams_sindex.intersection(line.bounds))]\n",
    "    for index, row in possible_matches_streams.iterrows():\n",
    "        if line.intersects(row['geometry']):\n",
    "            return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the building footprints data\n",
    "\n",
    "#buildingfootprints_gdf = gpd.read_file('manila_building_footprints.geojson')\n",
    "\n",
    "#buildingfootprints_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD DATA (FOR FAST TESTING)\n",
    "# Load the Manila amenities data into a Geopandas dataframe\n",
    "from shapely import wkt\n",
    "\n",
    "manila_amenities_df = pd.read_csv('manila_amenities.csv')\n",
    "manila_amenities_df['geometry'] = manila_amenities_df['geometry'].apply(wkt.loads)\n",
    "manila_amenities_gdf = gpd.GeoDataFrame(manila_amenities_df, crs='epsg:3123')\n",
    "\n",
    "# Separate into point and polygon dataframes\n",
    "manila_amenities_polygon_gdf = manila_amenities_gdf[manila_amenities_gdf['geometry'].geom_type == 'Polygon']\n",
    "manila_amenities_point_gdf = manila_amenities_gdf[manila_amenities_gdf['geometry'].geom_type == 'Point']\n",
    "manila_amenities_multipoly_gdf = manila_amenities_gdf[manila_amenities_gdf['geometry'].geom_type == 'MultiPolygon']\n",
    "\n",
    "# Append multipolygons to the polygon dataframe\n",
    "manila_amenities_polygon_gdf = gpd.GeoDataFrame(pd.concat([manila_amenities_polygon_gdf, manila_amenities_multipoly_gdf], ignore_index=True))\n",
    "\n",
    "# Reset point dataframe index\n",
    "manila_amenities_point_gdf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Add a column to the polygon dataframe to store a list of Amenity Points within the polygon\n",
    "manila_amenities_polygon_gdf['amenity_points'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For each polygon in the polygon dataframe, find all the points from the point dataframe lying inside that polygon\n",
    "# Store the list of points in the 'amenity_points' column of the polygon dataframe as a list of point indices\n",
    "\n",
    "# Create spatial index for points\n",
    "idx = rtree_index.Index()\n",
    "for j, point in manila_amenities_point_gdf.iterrows():\n",
    "    idx.insert(j, point['geometry'].bounds)\n",
    "\n",
    "# Iterate over polygons\n",
    "for i, polygon in manila_amenities_polygon_gdf.iterrows():\n",
    "    points_within_polygon = []\n",
    "    \n",
    "    # Iterate over points within the bounding box of the polygon\n",
    "    for j in idx.intersection(polygon['geometry'].bounds):\n",
    "        point = manila_amenities_point_gdf.loc[j]\n",
    "        if polygon['geometry'].intersects(point['geometry']):\n",
    "            points_within_polygon.append(j)\n",
    "    \n",
    "    manila_amenities_polygon_gdf.at[i, 'amenity_points'] = points_within_polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manila_amenities_polygon_gdf['amenity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manila_amenities_point_gdf['amenity'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Population data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANILA POPULATION DATA\n",
    "# Reading population data\n",
    "manila_population_df = pd.read_csv('manila-population-polygon.csv')\n",
    "manila_population_df['geometry'] = manila_population_df['geometry'].apply(wkt.loads)\n",
    "manila_population_gdf = gpd.GeoDataFrame(manila_population_df, crs='epsg:3123')\n",
    "\n",
    "# Create a base map centered around Manila\n",
    "map_center = (14.599512, 120.984222) # TEMPORARY WILL ZOOM TO MANILA\n",
    "m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "\n",
    "# Add points to the map\n",
    "for index, row in manila_population_gdf.iterrows():\n",
    "    folium.CircleMarker(location=[row['latitude'], row['longitude']],\n",
    "                        radius=1,  # Adjust the radius as needed for population density representation\n",
    "                        color='blue',  # Change color as needed\n",
    "                        fill=True,\n",
    "                        fill_color='blue'  # Change fill color as needed\n",
    "                        ).add_to(m)\n",
    "    \n",
    "m.save('Population Maps/population_Manila.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKATI POPULATION DATA\n",
    "# Reading population data\n",
    "makati_population_df = pd.read_csv('makati-population-polygon.csv')\n",
    "makati_population_df['geometry'] = makati_population_df['geometry'].apply(wkt.loads)\n",
    "makati_population_gdf = gpd.GeoDataFrame(makati_population_df, crs='epsg:3123')\n",
    "\n",
    "# Create a base map centered around Manila\n",
    "map_center = (14.599512, 120.984222) # TEMPORARY WILL ZOOM TO MANILA\n",
    "m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "\n",
    "# Add points to the map\n",
    "for index, row in makati_population_gdf.iterrows():\n",
    "    folium.CircleMarker(location=[row['latitude'], row['longitude']],\n",
    "                        radius=1,  # Adjust the radius as needed for population density representation\n",
    "                        color='blue',  # Change color as needed\n",
    "                        fill=True,\n",
    "                        fill_color='blue'  # Change fill color as needed\n",
    "                        ).add_to(m)\n",
    "    \n",
    "m.save('Population Maps/population_Makati.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANDALUYONG POPULATION DATA\n",
    "# Reading population data\n",
    "mandaluyong_population_df = pd.read_csv('mandaluyong-population-polygon.csv')\n",
    "mandaluyong_population_df['geometry'] = mandaluyong_population_df['geometry'].apply(wkt.loads)\n",
    "mandaluyong_population_gdf = gpd.GeoDataFrame(mandaluyong_population_df, crs='epsg:3123')\n",
    "\n",
    "# Create a base map centered around Manila\n",
    "map_center = (14.599512, 120.984222) # TEMPORARY WILL ZOOM TO MANILA\n",
    "m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "\n",
    "# Add points to the map\n",
    "for index, row in mandaluyong_population_gdf.iterrows():\n",
    "    folium.CircleMarker(location=[row['latitude'], row['longitude']],\n",
    "                        radius=1,  # Adjust the radius as needed for population density representation\n",
    "                        color='blue',  # Change color as needed\n",
    "                        fill=True,\n",
    "                        fill_color='blue'  # Change fill color as needed\n",
    "                        ).add_to(m)\n",
    "    \n",
    "m.save('Population Maps/population_Mandaluyong.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial City Network Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buckle up. We're trying to create a network out of this monstrosity of a dataframe\n",
    "# Create a networkx graph\n",
    "\n",
    "def create_network(amenities_polygon_gdf, amenities_point_gdf):\n",
    "    amenities_network = nx.Graph()\n",
    "\n",
    "   # Add polygon nodes\n",
    "    for index, row in amenities_polygon_gdf.iterrows():\n",
    "        # Check if essential columns exist in the row\n",
    "        if 'geometry' in row and 'amenity' in row and 'name' in row and 'addr_city' in row and 'amenity_points' in row:\n",
    "            # Generate a unique node identifier for polygons\n",
    "            node_id = f\"polygon_{index}\"\n",
    "            amenities_network.add_node(node_id, polygon_index=index, geometry=row['geometry'], lat=row['geometry'].centroid.y, lon=row['geometry'].centroid.x, amenity=row['amenity'], name=row.get('name', ''), addr_city=row['addr_city'], amenity_points=row['amenity_points'])\n",
    "        else:\n",
    "            print(f\"Skipping row {index} in amenities_polygon_gdf due to missing data.\")\n",
    "\n",
    "    # Add point nodes\n",
    "    for index, row in amenities_point_gdf.iterrows():\n",
    "        # Check if essential columns exist in the row\n",
    "        if 'geometry' in row and 'amenity' in row and 'name' in row and 'addr_city' in row:\n",
    "            # Generate a unique node identifier for points\n",
    "            node_id = f\"point_{index}\"\n",
    "            \n",
    "            # This part checks whether the point is a transportation or not \n",
    "            if row['amenity'] == 'transportation':\n",
    "                isTranspo = True\n",
    "            else:\n",
    "                isTranspo = False\n",
    "            amenities_network.add_node(node_id, point_index=index, geometry=row['geometry'], lat=row['y'], lon=row['x'], amenity=row['amenity'], name=row.get('name', ''), addr_city=row['addr_city'], is_in_polygon=False, isTranspo = isTranspo)\n",
    "        else:\n",
    "            print(f\"Skipping row {index} in amenities_point_gdf due to missing data.\")\n",
    "            \n",
    "    return amenities_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of Roads and Rivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting filtered roads FOR VISUALIZATION ONLY\n",
    "def plot_all_filtered_roads():\n",
    "    map_center = (14.599512, 120.984222) # TEMPORARY WILL ZOOM TO MANILA\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "\n",
    "    # Iterate through each road\n",
    "    for index, road in filtered_roads_strings.iterrows():\n",
    "        line_coords = list(road['geometry'].coords)\n",
    "\n",
    "        if road['highway'] == 'primary':\n",
    "            folium.PolyLine(locations=[(y, x) for x, y in line_coords], color='blue').add_to(m)\n",
    "\n",
    "        if road['highway'] == 'secondary':\n",
    "            folium.PolyLine(locations=[(y, x) for x, y in line_coords], color='red').add_to(m)\n",
    "\n",
    "        if road['highway'] == 'tertiary':\n",
    "            folium.PolyLine(locations=[(y, x) for x, y in line_coords], color='green').add_to(m)\n",
    "\n",
    "        if road['highway'] == 'unclassified':\n",
    "            folium.PolyLine(locations=[(y, x) for x, y in line_coords], color='orange').add_to(m)\n",
    "\n",
    "    for index, road in filtered_roads_lists.iterrows():\n",
    "        line_coords = list(road['geometry'].coords)\n",
    "        folium.PolyLine(locations=[(y, x) for x, y in line_coords], color='purple').add_to(m)\n",
    "\n",
    "    # Return the map\n",
    "    return m\n",
    "\n",
    "def plot_all_roads():\n",
    "    map_center = (14.599512, 120.984222) # TEMPORARY WILL ZOOM TO MANILA\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "\n",
    "    # Iterate through each road\n",
    "    for index, road in manila_road.iterrows():\n",
    "        line_coords = list(road['geometry'].coords)\n",
    "        folium.PolyLine(locations=[(y, x) for x, y in line_coords], color='blue').add_to(m)\n",
    "\n",
    "    # Return the map\n",
    "    return m\n",
    "\n",
    "# TEMPORARY TO BE REMOVED\n",
    "def plot_private_roads():\n",
    "    map_center = (14.599512, 120.984222) # TEMPORARY WILL ZOOM TO MANILA\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "\n",
    "    # Iterate through each road\n",
    "    for index, road in manila_private.iterrows():\n",
    "        line_coords = list(road['geometry'].coords)\n",
    "        folium.PolyLine(locations=[(y, x) for x, y in line_coords], color='blue').add_to(m)\n",
    "\n",
    "    # Return the map\n",
    "    return m\n",
    "\n",
    "# TEMPORARY TO BE REMOVED\n",
    "def plot_walk():\n",
    "    map_center = (14.599512, 120.984222) # TEMPORARY WILL ZOOM TO MANILA\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "\n",
    "    # Iterate through each road\n",
    "    for index, road in manila_walk.iterrows():\n",
    "        line_coords = list(road['geometry'].coords)\n",
    "        folium.PolyLine(locations=[(y, x) for x, y in line_coords], color='blue').add_to(m)\n",
    "\n",
    "    # Return the map\n",
    "    return m\n",
    "    \n",
    "# TEMPORARY TO BE REMOVED\n",
    "def plot_bike():\n",
    "    map_center = (14.599512, 120.984222) # TEMPORARY WILL ZOOM TO MANILA\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "\n",
    "    # Iterate through each road\n",
    "    for index, road in manila_bike.iterrows():\n",
    "        line_coords = list(road['geometry'].coords)\n",
    "        folium.PolyLine(locations=[(y, x) for x, y in line_coords], color='blue').add_to(m)\n",
    "\n",
    "    # Return the map\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Amenity and Zone Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD POINTS TO NX GRAPH\n",
    "# Function to add only points to the networkX graph\n",
    "# The other functions focuses on adding polygons, this function just iterates and adds points\n",
    "\n",
    "def add_points_to_graph(graph, graph_to_add):\n",
    "    for node_key, node_data in graph.nodes.items():\n",
    "        if 'geometry' in node_data and node_data['geometry'].geom_type in ['Point']:   \n",
    "            graph_to_add.add_node(node_key, geometry=node_data['geometry'], name=node_data['name'], lat=node_data['lat'], amenity=node_data['amenity'],\n",
    "                                lon=node_data['lon'])\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before Level 1 - Manila\n",
    "# To filter out the residential areas that do not exceed the threshold\n",
    "\n",
    "def filter_out_low_population_density_residentials(graph_to_filter, pop_graph):\n",
    "    filtered_graph = nx.Graph()\n",
    "    \n",
    "    for node_key, node_data in list(graph_to_filter.nodes.items()):\n",
    "        if 'geometry' in node_data and node_data['geometry'].geom_type in ['Polygon', 'MultiPolygon'] and node_data['amenity'] == \"residential areas\":\n",
    "            # Different Keyword\n",
    "            # is_a_zone - Will be added to the filtered graph as it means that the residential area has pop density above the threshold\n",
    "            if node_key in pop_graph and pop_graph.nodes[node_key]['is_a_zone']:\n",
    "                filtered_graph.add_node(node_key, **node_data)\n",
    "                \n",
    "        else: # If a point or any polygon taht is not residential area, add to the graph\n",
    "            if node_data['amenity'] != \"residential areas\":\n",
    "                filtered_graph.add_node(node_key, **node_data)\n",
    "    \n",
    "    # Should return a filtered graph\n",
    "    return filtered_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 1 - COMBINE AMENITIES BY POLYGON\n",
    "# Creates a copy of a graph and connects non-contiguous and non-overlapping shapes instead of merging\n",
    "\n",
    "def combine_amenities_by_polygon(graph, max_distance, max_perimeter):\n",
    "    combined_graph = nx.Graph()\n",
    "    list_to_merge = []\n",
    "    idx = rtree_index.Index()\n",
    "    \n",
    "    # Iterates through each polygon and then enlarges and gets the intersecting ones for easier iteration later\n",
    "    for node_key, node_data in graph.nodes.items():\n",
    "        # Ensure that the bounding box coordinates are passed as a tuple\n",
    "        if 'geometry' in node_data and node_data['geometry'].geom_type in ['Polygon', 'MultiPolygon']:\n",
    "            enlarged_polygon = node_data['geometry'].buffer(meters_to_degrees(max_distance))\n",
    "            bounds = enlarged_polygon.bounds\n",
    "            bounds_float = tuple(float(coord) for coord in bounds)\n",
    "            numeric_key = int(node_key.split('_')[1])\n",
    "            idx.insert(numeric_key, bounds_float)\n",
    "    \n",
    "    #Iterating through each polygon\n",
    "    for node_key, node_data in list(graph.nodes.items()):\n",
    "        if 'geometry' in node_data and node_data['geometry'].geom_type in ['Polygon', 'MultiPolygon']:\n",
    "            nodes_to_merge = []\n",
    "            \n",
    "            #Check first if it is already in a list of polygons to be merged\n",
    "            for merge_list in list_to_merge:\n",
    "                if node_key in merge_list:\n",
    "                    nodes_to_merge = merge_list\n",
    "                    break\n",
    "            \n",
    "            # If this is a new node that is not part of any list, add itself to the list for merging later\n",
    "            if not nodes_to_merge:\n",
    "                nodes_to_merge.append(node_key)\n",
    "            \n",
    "            # Distance \n",
    "            total_distance = 0 # This is to calculate the total distance\n",
    "            combined_node = graph.nodes[node_key]['geometry']\n",
    "            \n",
    "            # Then iterate through other polygons that intersect that polygon based on bounds\n",
    "            for other_node_key in idx.intersection(node_data['geometry'].bounds):\n",
    "                formatted_key = f\"polygon_{other_node_key}\"\n",
    "                other_node_data = graph.nodes[formatted_key]\n",
    "                if 'geometry' in other_node_data and other_node_data['geometry'].geom_type in ['Polygon', 'MultiPolygon']:\n",
    "                    # Check if its not the same node, it is the same amenity, and is not already in the list to merge\n",
    "                    if node_key != formatted_key and node_data['amenity'] == other_node_data['amenity']:\n",
    "                        distance = degrees_to_meters(node_data['geometry'].distance(other_node_data['geometry']))\n",
    "\n",
    "                        if distance <= max_distance:\n",
    "                            line_between_centroids = LineString([node_data['geometry'].centroid, other_node_data['geometry'].centroid])\n",
    "                            amenities_intersecting = any(graph.nodes[amenity_key]['geometry'].intersects(line_between_centroids) for amenity_key in graph.nodes if amenity_key != node_key and amenity_key != formatted_key and graph.nodes[amenity_key]['amenity'] != node_data['amenity'])\n",
    "                            \n",
    "                            # Check if it does not exceed the max perimeter\n",
    "                            combined_node = shapely.ops.unary_union([combined_node, graph.nodes[formatted_key]['geometry']])\n",
    "                            total_distance += degrees_to_meters(combined_node.length)\n",
    "                            \n",
    "                            if not amenities_intersecting and total_distance < max_perimeter and not find_intersecting_features(line_between_centroids):\n",
    "                                nodes_to_merge.append(formatted_key)\n",
    "            \n",
    "            if nodes_to_merge not in list_to_merge:\n",
    "                list_to_merge.append(nodes_to_merge) # Add to the list to merge the polygons later\n",
    "                \n",
    "            \n",
    "                \n",
    "    temp_graph = to_graph(list_to_merge)\n",
    "    lists = graph_to_list(temp_graph)\n",
    "\n",
    "\n",
    "    # Now we will finally connect all polygons in the list\n",
    "    for merge_list in lists:\n",
    "        first = True\n",
    "        for node_key in merge_list:\n",
    "            if first:\n",
    "                combined_node = graph.nodes[node_key]['geometry']\n",
    "                combined_node_amenity = graph.nodes[node_key]['amenity']\n",
    "                combined_node_key = node_key\n",
    "                combined_node_geometry = graph.nodes[node_key]['geometry']\n",
    "                combined_node_name = graph.nodes[node_key]['name']\n",
    "                combined_node_lat = graph.nodes[node_key]['lat']\n",
    "                combined_node_lon = graph.nodes[node_key]['lon']\n",
    "                combined_node_points = graph.nodes[node_key]['amenity_points']\n",
    "                first = False\n",
    "            else:\n",
    "                combined_node = shapely.ops.unary_union([combined_node_geometry, graph.nodes[node_key]['geometry']])\n",
    "                combined_node_geometry = combined_node\n",
    "                combined_node_name = combine_names(combined_node_name, graph.nodes[node_key].get('name'))\n",
    "                combined_node_lat = combined_node_geometry.centroid.x\n",
    "                combined_node_lon = combined_node_geometry.centroid.x\n",
    "                combined_node_points += graph.nodes[node_key].get('amenity_points', 0)\n",
    "                \n",
    "        combined_graph.add_node(combined_node_key, geometry=combined_node_geometry, name=combined_node_name, lat=combined_node_lat, amenity=combined_node_amenity,\n",
    "                                lon=combined_node_lon, amenity_points=combined_node_points)\n",
    "\n",
    "    return combined_graph\n",
    "\n",
    "# TEMPORARY SOLUTION FOR NULL NAMES\n",
    "def combine_names(name1, name2):\n",
    "    # Combine names ensuring that no null values are included\n",
    "    if isinstance(name1, str) and isinstance(name2, str):\n",
    "        return f\"{name1}, {name2}\"\n",
    "    elif isinstance(name1, str):\n",
    "        return name1\n",
    "    elif isinstance(name2, str):\n",
    "        return name2\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To merge duplicates in lists\n",
    "def to_graph(nodes):\n",
    "    G = nx.Graph()\n",
    "    for part in nodes:\n",
    "        G.add_nodes_from(part)\n",
    "        G.add_edges_from(to_edges(part))\n",
    "    return G\n",
    "\n",
    "def to_edges(nodes):\n",
    "    it = iter(nodes)\n",
    "    last = next(it)\n",
    "\n",
    "    for current in it:\n",
    "        yield last, current\n",
    "        last = current\n",
    "        \n",
    "def graph_to_list(G):\n",
    "    connected_components = nx.connected_components(G)\n",
    "    lists = [list(component) for component in connected_components]\n",
    "    return lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 2 - Function to connect zones in a network\n",
    "def create_zone_network(graph, max_distance):\n",
    "    connect_graph = nx.Graph()\n",
    "    network_id = 1\n",
    "    list_to_connect = []\n",
    "    idx = rtree_index.Index()\n",
    "    \n",
    "    for node_key, node_data in graph.nodes.items():\n",
    "        enlarged_polygon = node_data['geometry'].buffer(meters_to_degrees(max_distance))\n",
    "        bounds = enlarged_polygon.bounds\n",
    "        bounds_float = tuple(float(coord) for coord in bounds)\n",
    "        numeric_key = int(node_key.split('_')[1])\n",
    "        idx.insert(numeric_key, bounds_float)\n",
    "    \n",
    "    for node_key, node_data in list(graph.nodes.items()):\n",
    "        if 'geometry' in node_data and node_data['geometry'].geom_type in ['Polygon', 'MultiPolygon']:\n",
    "            connect_nodes = []\n",
    "            \n",
    "            #Check first if it is already in a list of polygons to be connected\n",
    "            for connect_list in list_to_connect:\n",
    "                if node_key in connect_list:\n",
    "                    connect_nodes = connect_list\n",
    "                    break\n",
    "            \n",
    "            # If this is a new node that is not part of any list, add itself to the list for merging later\n",
    "            if not connect_nodes:\n",
    "                connect_nodes.append(node_key)\n",
    "                \n",
    "            # If this is not a residential area that is its own zone\n",
    "            if node_key not in pop_graph or not pop_graph.nodes[node_key]['is_a_zone']:\n",
    "                for other_node_key in idx.intersection(node_data['geometry'].bounds):\n",
    "                    formatted_key = f\"polygon_{other_node_key}\"\n",
    "                    other_node_data = graph.nodes[formatted_key]\n",
    "                    if 'geometry' in other_node_data and other_node_data['geometry'].geom_type in ['Polygon', 'MultiPolygon']:\n",
    "                        if node_key != formatted_key:\n",
    "\n",
    "                            distance = degrees_to_meters(node_data['geometry'].distance(other_node_data['geometry']))\n",
    "\n",
    "                            # Check if they are within distance of each other\n",
    "                            if distance <= max_distance:\n",
    "                                line_between_centroids = LineString([node_data['geometry'].centroid, other_node_data['geometry'].centroid])\n",
    "                                if not find_intersecting_features(line_between_centroids):\n",
    "                                    if formatted_key not in pop_graph or not pop_graph.nodes[formatted_key]['is_a_zone']:\n",
    "                                        connect_nodes.append(formatted_key)\n",
    "                                \n",
    "            if connect_nodes not in list_to_connect:\n",
    "                list_to_connect.append(connect_nodes) # Add to the list to merge the polygons later\n",
    "                \n",
    "    temp_graph = to_graph(list_to_connect)\n",
    "    lists = graph_to_list(temp_graph)\n",
    "\n",
    "    # Now we will finally connect all polygons in the list\n",
    "    for merge_list in lists:\n",
    "        first = True\n",
    "        for node_key in merge_list:\n",
    "            if first:\n",
    "                combined_node = graph.nodes[node_key]['geometry']\n",
    "                combined_node_amenity = graph.nodes[node_key]['amenity']\n",
    "                combined_node_key = node_key\n",
    "                combined_node_geometry = graph.nodes[node_key]['geometry']\n",
    "                combined_node_name = graph.nodes[node_key]['name']\n",
    "                combined_node_lat = graph.nodes[node_key]['lat']\n",
    "                combined_node_lon = graph.nodes[node_key]['lon']\n",
    "                combined_node_points = graph.nodes[node_key]['amenity_points']\n",
    "                first = False\n",
    "            else:\n",
    "                combined_node = shapely.ops.unary_union([combined_node_geometry, graph.nodes[node_key]['geometry']])\n",
    "                combined_node_geometry = combined_node\n",
    "                combined_node_name = combine_names(combined_node_name, graph.nodes[node_key].get('name'))\n",
    "                combined_node_lat = combined_node_geometry.centroid.x\n",
    "                combined_node_lon = combined_node_geometry.centroid.x\n",
    "                combined_node_points += graph.nodes[node_key].get('amenity_points', 0)\n",
    "                \n",
    "        network_id += 1\n",
    "        connect_graph.add_node(combined_node_key, geometry=combined_node_geometry, name=combined_node_name, lat=combined_node_lat, amenity=combined_node_amenity,\n",
    "                                lon=combined_node_lon, amenity_points=combined_node_points, network_id=network_id)\n",
    "\n",
    "    return connect_graph\n",
    "\n",
    "# TEMPORARY SOLUTION FOR NULL NAMES\n",
    "def combine_names(name1, name2):\n",
    "    # Combine names ensuring that no null values are included\n",
    "    if isinstance(name1, str) and isinstance(name2, str):\n",
    "        return f\"{name1}, {name2}\"\n",
    "    elif isinstance(name1, str):\n",
    "        return name1\n",
    "    elif isinstance(name2, str):\n",
    "        return name2\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to check population density - To be used for the zone connection\n",
    "# Uses the combined graph\n",
    "# Formula: Population Density = Total Population / Total Area\n",
    "\n",
    "def check_residential_population_density(graph, threshold, population_gdf):\n",
    "    # Create an R-tree index for efficient spatial querying\n",
    "    idx = rtree_index.Index()\n",
    "    \n",
    "    # Populate the R-tree index with points\n",
    "    for index, row in population_gdf.iterrows():\n",
    "        idx.insert(index, (row['longitude'], row['latitude'], row['longitude'], row['latitude']))\n",
    "    \n",
    "    pop_graph = nx.Graph()\n",
    "    \n",
    "    for node_key, node_data in graph.nodes.items():\n",
    "        # Check if its a polygon and is a residential area\n",
    "        if 'geometry' in node_data and node_data['geometry'].geom_type in ['Polygon', 'MultiPolygon'] and node_data['amenity'] == \"residential areas\":\n",
    "            total_pop = 0\n",
    "            \n",
    "            # Query the R-tree index to find points within the polygon\n",
    "            for point_idx in idx.intersection(node_data['geometry'].bounds):\n",
    "                point = population_gdf.loc[point_idx]\n",
    "                if Point(point['longitude'], point['latitude']).within(node_data['geometry']):\n",
    "                    total_pop += point['phl_general_2020']  # Add the density\n",
    "            \n",
    "            if total_pop > threshold:\n",
    "                node_data[\"is_a_zone\"] = True\n",
    "            else:\n",
    "                node_data[\"is_a_zone\"] = False\n",
    "            \n",
    "            pop_graph.add_node(node_key, density=total_pop, **node_data)\n",
    "    return pop_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Function to plot/visualize main graph network on the map\n",
    "def plot_network_on_map(amenities_network, initial_location=[0, 0], zoom_start=10):\n",
    "    # Create a map centered at the initial location\n",
    "    map_center = (14.599512, 120.984222) # TEMPORARY WILL ZOOM TO MANILA\n",
    "    m = folium.Map(location=map_center, zoom_start=zoom_start, tiles='openstreetmap')\n",
    "    \n",
    "    #Colours for Visualization\n",
    "    amenity_colors = {\n",
    "        'education': 'green',\n",
    "        'finance': 'blue',\n",
    "        'government offices': 'red',\n",
    "        'government areas': 'red',\n",
    "        'government' : 'red',\n",
    "        'grocery': 'orange',\n",
    "        'health': 'magenta',\n",
    "        'malls': 'yellow',\n",
    "        'residential areas': 'brown',\n",
    "        'security': 'gray',\n",
    "        'transportation': 'lightblue',\n",
    "        'groceries' : 'indigo',\n",
    "        'mall' : 'violet',\n",
    "        'others': 'black'\n",
    "    }\n",
    "\n",
    "    # Iterate over the nodes in the network\n",
    "    for node, data in amenities_network.nodes(data=True):\n",
    "        # Check if the node has a geometry attribute\n",
    "        if 'geometry' in data:\n",
    "            # Get the geometry of the node\n",
    "            geometry = data['geometry']\n",
    "\n",
    "            # Check the geometry type and plot accordingly\n",
    "            if geometry.geom_type == 'Point':\n",
    "                # Plot a marker for points    \n",
    "                #folium.Marker(location=[geometry.y, geometry.x], popup=f\"{data['name']}\").add_to(m)\n",
    "                continue\n",
    "            elif geometry.geom_type in ['Polygon', 'MultiPolygon']:\n",
    "                # Plot polygons or multipolygons\n",
    "                color = amenity_colors[data.get('amenity')]\n",
    "                if geometry.geom_type == 'Polygon':\n",
    "                    polygons = [geometry]\n",
    "                else:\n",
    "                    polygons = geometry.geoms\n",
    "\n",
    "                for polygon in polygons:\n",
    "                    coordinates = []\n",
    "                    for point in polygon.exterior.coords:\n",
    "                        coordinates.append([point[1], point[0]])\n",
    "                    folium.Polygon(locations=coordinates, fill=True, color=color, fill_opacity=0.4).add_to(m)\n",
    "\n",
    "    # Return the map\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to visualize the stops\n",
    "def plot_stops_on_map(network_map, stops, initial_location=[0, 0], zoom_start=10):\n",
    "    # Iterate over the nodes in the network\n",
    "    for stop in stops:\n",
    "        folium.Marker(location=[stop.lat, stop.long], popup=f\"{stop.isTranspo}\").add_to(network_map)\n",
    "        \n",
    "    return network_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Function to plot/visualize connected zones on the map\n",
    "import random\n",
    "\n",
    "# This is to better visualize the networks\n",
    "def plot_connected_zones_network_on_map(graph, initial_location=[0, 0], zoom_start=10):\n",
    "    # Create a map centered at the initial location\n",
    "    map_center = (14.599512, 120.984222) # TEMPORARY WILL ZOOM TO MANILA\n",
    "    m = folium.Map(location=map_center, zoom_start=zoom_start, tiles='openstreetmap')\n",
    "    \n",
    "    #Colours for Visualization\n",
    "    colors = [\n",
    "    \"Red\", \"Green\", \"Blue\", \"Yellow\", \"Orange\", \"Purple\", \"Cyan\", \"Magenta\", \"Maroon\",\n",
    "    \"Olive\", \"Lime\", \"Teal\", \"Navy\", \"Aqua\", \"Fuchsia\", \"Coral\", \"Indigo\", \"Violet\"]\n",
    "    \n",
    "    color_map = {}\n",
    "\n",
    "    # Iterate over the nodes in the network\n",
    "    for node, data in graph.nodes(data=True):\n",
    "        # Check if the node has a geometry attribute\n",
    "        if 'geometry' in data:\n",
    "            # Get the geometry of the node\n",
    "            geometry = data['geometry']\n",
    "\n",
    "            # Check the geometry type and plot accordingly\n",
    "            if geometry.geom_type == 'Point':\n",
    "                # Plot a marker for points    \n",
    "                #folium.Marker(location=[geometry.y, geometry.x], popup=f\"{data['name']}\").add_to(m)\n",
    "                continue\n",
    "            elif geometry.geom_type in ['Polygon', 'MultiPolygon']:\n",
    "                \n",
    "                network_id = data[\"network_id\"]\n",
    "                \n",
    "                if network_id not in color_map:\n",
    "                    color = random.choice(colors)\n",
    "                    color_map[network_id] = color\n",
    "                else:\n",
    "                    color = color_map[network_id]\n",
    "                \n",
    "                if geometry.geom_type == 'Polygon':\n",
    "                    polygons = [geometry]\n",
    "                else:\n",
    "                    polygons = geometry.geoms\n",
    "\n",
    "                for polygon in polygons:\n",
    "                    coordinates = []\n",
    "                    for point in polygon.exterior.coords:\n",
    "                        coordinates.append([point[1], point[0]])\n",
    "                    folium.Polygon(locations=coordinates, fill=True, color=color, fill_opacity=0.4).add_to(m)\n",
    "\n",
    "    # Return the map\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5 - Function to plot/visualize residential areas based on population density on the map\n",
    "# This is to better visualize which residential areas can become zones\n",
    "def plot_population_zones_map(graph, initial_location=[0, 0], zoom_start=10):\n",
    "    # Create a map centered at the initial location\n",
    "    map_center = (14.599512, 120.984222) # TEMPORARY WILL ZOOM TO MANILA\n",
    "    m = folium.Map(location=map_center, zoom_start=zoom_start, tiles='openstreetmap')\n",
    "\n",
    "    # Iterate over the nodes in the network\n",
    "    for node, data in graph.nodes(data=True):\n",
    "        # Check if the node has a geometry attribute\n",
    "        if 'geometry' in data:\n",
    "            # Get the geometry of the node\n",
    "            geometry = data['geometry']\n",
    "\n",
    "            # Check the geometry type and plot accordingly\n",
    "            if geometry.geom_type == 'Point':\n",
    "                # Plot a marker for points    \n",
    "                #folium.Marker(location=[geometry.y, geometry.x], popup=f\"{data['name']}\").add_to(m)\n",
    "                continue\n",
    "            elif geometry.geom_type in ['Polygon', 'MultiPolygon']:\n",
    "                if geometry.geom_type == 'Polygon':\n",
    "                    polygons = [geometry]\n",
    "                else:\n",
    "                    polygons = geometry.geoms\n",
    "\n",
    "                for polygon in polygons:\n",
    "                    coordinates = []\n",
    "                    for point in polygon.exterior.coords:\n",
    "                        coordinates.append([point[1], point[0]])\n",
    "                    \n",
    "                    if (data['is_a_zone']):\n",
    "                        folium.Polygon(locations=coordinates, fill=True, color=\"green\", fill_opacity=0.4).add_to(m)\n",
    "                    else:\n",
    "                        folium.Polygon(locations=coordinates, fill=True, color=\"red\", fill_opacity=0.4).add_to(m)\n",
    "\n",
    "    # Return the map\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CREATING STOPS\n",
    "# It should return a list of coordinates/nodes for stop and a graph of stops\n",
    "# if residential area, check if the population density\n",
    "\n",
    "# Global Variables used:\n",
    "# list_of_stops - List of stops\n",
    "# graph_of_stops - graph of all stops placed\n",
    "# CITY_GRAPH - graph of the city road networks\n",
    "import random\n",
    "\n",
    "def place_stops_on_roads(amenity_graph, graph_of_stops, list_of_stops):\n",
    "    global CITY_GRAPH  \n",
    "    for node_key, node_data in amenity_graph.nodes(data=True):\n",
    "        # All tranportation points are automatically stops\n",
    "        if node_data['geometry'].geom_type in ['Point']:\n",
    "            if node_data['amenity'] == 'transportation':\n",
    "                nearest_node = ox.distance.nearest_nodes(CITY_GRAPH, node_data['lon'], node_data['lat'])\n",
    "                \n",
    "                # If there is an existing node in the main graph, then add it to the list and the stop graph\n",
    "                if nearest_node is not None:\n",
    "                    if not graph_of_stops.has_node(nearest_node):\n",
    "                        lon = CITY_GRAPH.nodes[nearest_node]['x']\n",
    "                        lat = CITY_GRAPH.nodes[nearest_node]['y']\n",
    "                        isTranspo = True\n",
    "                        graph_of_stops.add_node(nearest_node, lon=lon, lat=lat, isTranspo=isTranspo)\n",
    "                        list_of_stops.append(stopCandidate(CITY_GRAPH.nodes[nearest_node]['y'], CITY_GRAPH.nodes[nearest_node]['x'], True, nearest_node, 0))\n",
    "        \n",
    "        else:\n",
    "            # Calculate the number of stops based on node size and population density\n",
    "            num_stops, node_size = calculate_num_stops(node_key, node_data)\n",
    "            \n",
    "            buffer_poly = node_data['geometry'].buffer(meters_to_degrees(30))\n",
    "            # Get the roads surrounding and inside the node polygons\n",
    "            relevant_edges = get_relevant_edges(buffer_poly)\n",
    "            \n",
    "            # Place stops randomly on these roads\n",
    "            place_stops_along_edges(relevant_edges, buffer_poly, num_stops, node_size, graph_of_stops, list_of_stops)\n",
    "\n",
    "def calculate_num_stops(node_key, node_data):\n",
    "    # Example calculation based on node size and population density\n",
    "    node_size = degrees_to_meters(node_data['geometry'].area) # Size of the node polygon\n",
    "    # Adjust factors and formula as needed\n",
    "    num_stops = 0\n",
    "    \n",
    "    if node_key in pop_graph:\n",
    "        pop_density = pop_graph.nodes[node_key]['density']\n",
    "        num_stops = node_size * pop_density / 10000000  # Adjust this factor as needed\n",
    "        \n",
    "        if num_stops < 1:\n",
    "            num_stops = 1\n",
    "        elif num_stops > 3:\n",
    "            num_stops = 3\n",
    "    else:\n",
    "        list_sum = len(node_data['amenity_points'])\n",
    "\n",
    "        if list_sum > 0:\n",
    "            num_stops = 5\n",
    "        else:\n",
    "            num_stops = 3\n",
    "        \n",
    "    return int(num_stops), node_size\n",
    "\n",
    "\n",
    "# Create spatial index\n",
    "filtered_roads_strings_sindex = filtered_roads_strings.sindex\n",
    "filtered_roads_lists_sindex = filtered_roads_lists.sindex\n",
    "def get_relevant_edges(polygon):\n",
    "    relevant_edges = []\n",
    "    \n",
    "    # Check intersection with filtered roads\n",
    "    possible_matches_roads = filtered_roads_strings.iloc[list(filtered_roads_strings_sindex.intersection(polygon.bounds))]\n",
    "    for index, row in possible_matches_roads.iterrows():\n",
    "        if polygon.intersects(row['geometry']) and row['highway'] in ['primary', 'secondary', 'tertiary', 'residential']:\n",
    "            relevant_edges.append(row)\n",
    "\n",
    "    possible_matches_lists = filtered_roads_lists.iloc[list(filtered_roads_lists_sindex.intersection(polygon.bounds))]\n",
    "    for index, row in possible_matches_lists.iterrows():\n",
    "        if polygon.intersects(row['geometry']):\n",
    "            list_highway = row['highway']\n",
    "            if any(x in ['primary', 'secondary', 'tertiary', 'residential'] for x in list_highway):\n",
    "                relevant_edges.append(row)\n",
    "    return relevant_edges\n",
    "\n",
    "def place_stops_along_edges(edges, polygon, num_stops, node_size, graph_of_stops, list_of_stops):\n",
    "    # Place stops randomly along the edges within the polygon\n",
    "    \n",
    "    if len(edges) > 0:\n",
    "        for _ in range(num_stops):\n",
    "            edge = random.choice(edges)\n",
    "            # Calculate the intersection between the edge and the polygon\n",
    "            intersecting_line = edge['geometry'].intersection(polygon)\n",
    "            if intersecting_line.is_empty:\n",
    "                continue\n",
    "\n",
    "            # Calculate the length of the intersecting part of the edge\n",
    "            intersecting_length = intersecting_line.length\n",
    "\n",
    "            # Generate a random position along the intersecting part of the edge\n",
    "            random_position = random.uniform(0, intersecting_length)\n",
    "\n",
    "            # Calculate the coordinate along the edge at the random position\n",
    "            stop_location = calculate_coordinate_along_edge(intersecting_line, random_position)\n",
    "            #print(\"Stop placed at:\", stop_location)\n",
    "            \n",
    "            nearest_node = ox.distance.nearest_nodes(CITY_GRAPH, stop_location[0], stop_location[1])\n",
    "            \n",
    "            # If there is an existing node in the main graph, then add it to the list and the stop graph\n",
    "            if nearest_node is not None:\n",
    "                if not graph_of_stops.has_node(nearest_node):\n",
    "                    lon = CITY_GRAPH.nodes[nearest_node]['x']\n",
    "                    lat = CITY_GRAPH.nodes[nearest_node]['y']\n",
    "                    isTranspo = False\n",
    "                    graph_of_stops.add_node(nearest_node, lon=lon, lat=lat, isTranspo=isTranspo)\n",
    "                    list_of_stops.append(stopCandidate(CITY_GRAPH.nodes[nearest_node]['y'], CITY_GRAPH.nodes[nearest_node]['x'], False,  nearest_node, node_size))\n",
    "            else:\n",
    "                _ -= 1\n",
    "        \n",
    "            \n",
    "\n",
    "def calculate_coordinate_along_edge(edge, position):\n",
    "    # Calculate the coordinate along the edge at the given position\n",
    "    point = edge.interpolate(position)\n",
    "    return point.x, point.y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the graph into a geojson for loading into QGIS\n",
    "\n",
    "def graph_to_geojson(graph, filename):\n",
    "    # Initialize an empty list to hold GeoJSON features\n",
    "    features = []\n",
    "\n",
    "    # Iterate over the nodes in the graph\n",
    "    for node, data in graph.nodes(data=True):\n",
    "        # Check if the node has a geometry attribute\n",
    "        if 'geometry' in data:\n",
    "            # Convert the geometry to a GeoJSON-compatible format\n",
    "            geometry = shapely.geometry.shape(data['geometry'])\n",
    "            # Create a copy of the properties to check for NaN values\n",
    "            properties = data.copy()\n",
    "            # Remove the geometry from the properties\n",
    "            properties.pop('geometry', None)\n",
    "            # Check for NaN values in the properties\n",
    "            if all(not (isinstance(value, float) and np.isnan(value)) for value in properties.values()):\n",
    "                # Create a GeoJSON feature for the node\n",
    "                feature = geojson.Feature(geometry=geometry, properties=properties)\n",
    "                # Add the feature to the list\n",
    "                features.append(feature)\n",
    "\n",
    "    # Create a GeoJSON FeatureCollection\n",
    "    feature_collection = geojson.FeatureCollection(features)\n",
    "\n",
    "    # Return the GeoJSON FeatureCollection\n",
    "    return feature_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Route Network Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V2 - Graph with the snapping function\n",
    "# Generate Route Network from connected routes\n",
    "\n",
    "# Global Variables used:\n",
    "# graph_of_stops - Graph of stops that will be used to create routes\n",
    "def generate_route_network(stop_nodes, max_walking_dist, max_stops, max_routes, graph_of_stops, connection_type=\"Default\"):\n",
    "    global route_count\n",
    "    overall_graph = nx.Graph()\n",
    "    \n",
    "    stop_node_coordinates = [[n.lat, n.long] for n in stop_nodes]\n",
    "    stop_nodes_kd_tree = KDTree(stop_node_coordinates)\n",
    "    next_nodes = [n for n in stop_nodes]\n",
    "    enable_stop_nodes(next_nodes)\n",
    "    route_network = []\n",
    "    num_routes = 0 # Count number of routes\n",
    "\n",
    "    while num_routes < max_routes:\n",
    "        next_nodes = [n for n in stop_nodes] # Resets the list of nodes so that nodes can be reused in a different\n",
    "        selected_node = random.choice(next_nodes) # For the first node\n",
    "        next_nodes.remove(selected_node)\n",
    "        route_gen = generate_route(selected_node, next_nodes, stop_nodes_kd_tree, max_walking_dist, connection_type, max_stops, overall_graph)\n",
    "        \n",
    "        if len(route_gen) > 1:\n",
    "            # A route is a list of connections between two nodes\n",
    "            snap_route_to_road(route_gen, overall_graph, graph_of_stops)\n",
    "            route_count += 1\n",
    "            \n",
    "            #snapped_edges = list(snapped_route.edges(data='road_path', default=1))\n",
    "            #snapped_route = connect_snapped_edges(snapped_edges)\n",
    "            route_network.append(route_gen)   \n",
    "            num_routes += 1\n",
    "               \n",
    "    return route_network, overall_graph\n",
    "\n",
    "def snap_route_to_road(route, overall_graph, graph_of_stops):\n",
    "    global connection_count\n",
    "    \n",
    "    # Directly add nodes based on node identifiers\n",
    "    for connection in route:\n",
    "        overall_graph.add_node(connection[0], **graph_of_stops.nodes[connection[0]]) # The origin\n",
    "        overall_graph.add_node(connection[-1], **graph_of_stops.nodes[connection[-1]]) # The destination\n",
    "        \n",
    "        name = f\"{connection[0]}_{connection[-1]}\" # \"node1_node2\" as name\n",
    "        \n",
    "        distance_travelled = 0\n",
    "        # Get the total distance from point A to point B\n",
    "        for i in range(len(connection)-1):\n",
    "            node_data = CITY_GRAPH.nodes[connection[i]]\n",
    "            next_node_data = CITY_GRAPH.nodes[connection[i+1]]\n",
    "            distance_travelled += haversine(node_data['y'], node_data['x'], next_node_data['y'], next_node_data['x'])\n",
    "        \n",
    "        overall_graph.add_edge(connection[0], connection[-1], road_path=connection, edge_name=name, edge_id = connection_count, route_id = route_count, distance = distance_travelled) # Add edge\n",
    "        connection_count += 1 # Global variable - increment the number of connections\n",
    "        \n",
    "        \n",
    "        if not overall_graph.has_node(connection[0]):\n",
    "                print(\"missing \", connection[0], \" in route\")\n",
    "        \n",
    "        if not overall_graph.has_node(connection[-1]):\n",
    "                print(\"missing \", connection[-1], \" in route \")\n",
    "\n",
    "\n",
    "# Generate route from stop nodes\n",
    "def generate_route(source, next_nodes, stop_nodes_kd_tree, max_walking_dist, connection_type, max_stops, network_graph):\n",
    "    short_route_list = [] # List of nx.shortest_path results\n",
    "    totalDistance = 0\n",
    "    orig_node = source\n",
    "    num_stops = 0 # Count number of stops\n",
    "    \n",
    "    # CONFIGURATION\n",
    "    max_tries = 3 # This is the max number of tries before breaking the loop || To avoid longer runtimes\n",
    "    current_tries = 0\n",
    "\n",
    "    while totalDistance < MAX_DISTANCE and num_stops < max_stops:\n",
    "        \n",
    "        #print(f\"Selected node is {selected_node.getLat()}, {selected_node.getLong()}\")\n",
    "        disable_surrounding_nodes(next_nodes, stop_nodes_kd_tree, orig_node, max_walking_dist)\n",
    "        enabled_nodes = [n for n in next_nodes if n.enabled]\n",
    "        dest_node = get_enabled_node_with_highest_edge_probability(orig_node, enabled_nodes, connection_type) # Getting the destination node\n",
    "        \n",
    "        if (dest_node == None or dest_node.id == orig_node.id):\n",
    "            break\n",
    "        \n",
    "        next_nodes.remove(dest_node) # Remove it as a candidate\n",
    "        \n",
    "        connection_edge = network_graph.has_edge(orig_node.id, dest_node.id) # This is to check if there is already an existing edge. If true, then it should not connect\n",
    "        \n",
    "        if not nx.has_path(CITY_GRAPH, orig_node.id, dest_node.id) or connection_edge:\n",
    "            current_tries += 1\n",
    "            if current_tries == max_tries:\n",
    "                break\n",
    "        else:\n",
    "            shortest_route = nx.shortest_path(CITY_GRAPH, orig_node.id, dest_node.id)\n",
    "            distance_travelled = 0\n",
    "            # Get the total distance from point A to point B\n",
    "            for i in range(len(shortest_route)-1):\n",
    "                node_data = CITY_GRAPH.nodes[shortest_route[i]]\n",
    "                next_node_data = CITY_GRAPH.nodes[shortest_route[i+1]]\n",
    "                \n",
    "                distance_travelled += haversine(node_data['y'], node_data['x'], next_node_data['y'], next_node_data['x'])\n",
    "\n",
    "            # Checks if it does not exceed the max distance\n",
    "            if totalDistance + distance_travelled <= MAX_DISTANCE:\n",
    "                \n",
    "                # Updating local degree count used for connection probability\n",
    "                orig_node.degree += 1\n",
    "                dest_node.degree += 1\n",
    "                \n",
    "                totalDistance += distance_travelled\n",
    "                short_route_list.append(shortest_route)\n",
    "                num_stops += 1\n",
    "                \n",
    "                orig_node = dest_node # Now change the origin to the destination\n",
    "            else:\n",
    "                break\n",
    "    if len(short_route_list) > 4 and totalDistance > 7:\n",
    "        print(f\"# OF CONNECTIONS AND TOTAL DISTANCE: {len(short_route_list)} - {totalDistance}\")\n",
    "        return short_route_list\n",
    "    \n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Disable surrounding nodes\n",
    "def disable_surrounding_nodes(next_nodes, stop_nodes_kd_tree, source_node, max_distance):\n",
    "    source = (source_node.getLat(), source_node.getLong())\n",
    "    \n",
    "    for node in next_nodes:\n",
    "        point = (node.getLat(), node.getLong())\n",
    "        distance = geodesic(source, point).meters\n",
    "        if distance <= max_distance:\n",
    "            node.disable()\n",
    "        \n",
    "def get_enabled_node_with_highest_edge_probability(source_node, enabled_nodes, connection_type):\n",
    "    highest_edge_prob = 0\n",
    "    highest_edge_prob_node = None\n",
    "\n",
    "    prob_list = []\n",
    "    for n in enabled_nodes:\n",
    "        # TODO: fix probability\n",
    "        edge_prob = get_edge_probability(source_node, n, len(enabled_nodes), connection_type)\n",
    "        prob_list.append(edge_prob)\n",
    "    \n",
    "    \n",
    "    min_score = min(prob_list)\n",
    "    if min_score < 0: # Shift the scores to ensure all are positive\n",
    "        prob_list = [score - min_score for score in prob_list]\n",
    "    total = sum(prob_list)\n",
    "    selection_p = [score / total for score in prob_list]\n",
    "    \n",
    "    chosen_node = np.random.choice(enabled_nodes, 1, p=selection_p)[0]    \n",
    "\n",
    "    return chosen_node\n",
    "\n",
    "# Probabilities of candidate nodes based on distance, area, node degree, and if transpo stop\n",
    "def get_edge_probability(source, destination, normalization_factor, connection_type):\n",
    "    source_coord = [source.getLat(), source.getLong()]\n",
    "    dest_coord = [destination.getLat(), destination.getLong()]\n",
    "\n",
    "    base_prob = exp(-(euclidean(source_coord, dest_coord))) / float(normalization_factor)\n",
    "\n",
    "    if connection_type == \"Default\":\n",
    "        if destination.isTranspo:\n",
    "            return base_prob * 2\n",
    "        return base_prob\n",
    "    elif connection_type == \"Area\":\n",
    "        if destination.isTranspo:\n",
    "            return base_prob * 2\n",
    "        # need to fine tune based on values of area\n",
    "        # getting the distribution of all areas would be computationally costly\n",
    "        print(f\"TEST AREA: {destination.getArea()}\")\n",
    "        return base_prob * (1 + (log(destination.getArea()) / destination.getArea()))\n",
    "    elif connection_type == \"Degree\":\n",
    "        if destination.isTranspo:\n",
    "            return base_prob * 2 * (1 + (destination.getDegree() / 10))\n",
    "        return base_prob * (1 + (destination.getDegree() / 10))\n",
    "\n",
    "def radius(stops):\n",
    "    circles = []\n",
    "    for stop in stops:\n",
    "        stop_point = Point(stop[1], stop[0])  # Create a Point object from [lat, lon] coordinates\n",
    "        circle = stop_point.buffer(radius / 111000)  # Buffer the Point to create a circle (assuming 1 degree is approximately 111000 meters)\n",
    "        circles.append(circle)\n",
    "    return circles\n",
    "\n",
    "def enable_stop_nodes(stop_nodes):\n",
    "    for n in stop_nodes:\n",
    "        n.enable()\n",
    "\n",
    "def all_nodes_disabled(stop_nodes):\n",
    "    return get_num_disabled(stop_nodes) == len(stop_nodes)\n",
    "\n",
    "def get_num_disabled(stop_nodes):\n",
    "    return sum(1 for n in stop_nodes if not n.enabled)\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Use geopy's geodesic function to calculate the distance\n",
    "    distance = geodesic((lat1, lon1), (lat2, lon2)).kilometers\n",
    "    return distance\n",
    "\n",
    "# Markers for visualization purposes\n",
    "def add_markers(used_stops, network_graph):\n",
    "    for stop in used_stops:\n",
    "        #popup_text = f\"Name: {stop.name}<br>Type: {stop.a_type}<br>Coordinates: {stop.getLat()}, {stop.getLong()}\"\n",
    "        lat = network_graph.nodes[stop]['lat']\n",
    "        long = network_graph.nodes[stop]['lon']\n",
    "        folium.Marker(location=[lat, long]).add_to(m)\n",
    "        \n",
    "def add_stops_to_list(routes):\n",
    "    used_stops = []\n",
    "    for route in routes:\n",
    "        for conn in route:\n",
    "            if conn[0] not in used_stops:\n",
    "                used_stops.append(conn[0])\n",
    "            if conn[-1] not in used_stops:\n",
    "                used_stops.append(conn[-1])\n",
    "    return used_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: CONNECT THE ROUTE REVERSAL\n",
    "# Reverse route traversal\n",
    "def get_reverse_route(network):\n",
    "    reverse_route_network = []\n",
    "    \n",
    "    for route in network.routes:\n",
    "        index = len(route)-1\n",
    "        \n",
    "        reverse_route = []\n",
    "        totalDistance = 0\n",
    "        while index >= 0:\n",
    "            connection = route[index] # Get the connection\n",
    "            rev_origin = connection[-1]\n",
    "            rev_dest = connection[0]\n",
    "            \n",
    "            if nx.has_path(CITY_GRAPH, rev_origin, rev_dest):\n",
    "                rev_path = nx.shortest_path(CITY_GRAPH, rev_origin, rev_dest) # Get the path\n",
    "                \n",
    "                distance_travelled = 0\n",
    "                # Get the total distance from point A to point B\n",
    "                for i in range(len(rev_path)-1):\n",
    "                    node_data = CITY_GRAPH.nodes[rev_path[i]]\n",
    "                    next_node_data = CITY_GRAPH.nodes[rev_path[i+1]]\n",
    "                    distance_travelled += haversine(node_data['y'], node_data['x'], next_node_data['y'], next_node_data['x'])\n",
    "                    \n",
    "                totalDistance += distance_travelled\n",
    "                \n",
    "                reverse_route.append(rev_path)\n",
    "                index -= 1\n",
    "            else:\n",
    "                # there is no reverse route for this so append nothing to the \n",
    "                reverse_route_network.append([])\n",
    "                break\n",
    "    \n",
    "        # Checks if it does not exceed the max distance\n",
    "        if totalDistance <= MAX_DISTANCE:\n",
    "            reverse_route_network.append(reverse_route)\n",
    "        else:\n",
    "            reverse_route_network.append([])\n",
    "            \n",
    "    return reverse_route_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GA VERSION 1\n",
    "\n",
    "# # This implementation takes only 2 parents from the whole generation and generates the population from them\n",
    "# # Instead of the what's in the paper that says the whole population will go through crossovers and mutations\n",
    "# # Cite Nayeem et al for GA with elitism and growing population size\n",
    "# def perform_genetic_algorithm(network_population, graph_of_stops, population_size, num_elites, num_generations, mutation_probability, \n",
    "#                               num_mutations_probabilities, num_crossovers_probabilities, mutation_threshold_dist, num_failure_removal,\n",
    "#                                       weight_random_failure, weight_targeted_failure, weight_connectivity,\n",
    "#                               with_elitism=False, with_growing_population=False, num_mutations_per_generation=1):\n",
    "    \n",
    "    \n",
    "#     # Do this for the assigned number of generations for the GA\n",
    "#     for i in range(num_generations):\n",
    "#         print(\"NEW NETWORK POPULATION\", flush=True)\n",
    "#         new_network_population = []\n",
    "\n",
    "#         # Evaluate the fitness of each network in the population\n",
    "#         for network in network_population:\n",
    "#             road_snapped_network_graph = network.graph\n",
    "#             network.fitness_score = compute_fitness_score(road_snapped_network_graph, num_failure_removal,\n",
    "#                           weight_random_failure, weight_targeted_failure, weight_connectivity)\n",
    "#             print(\"Network score: \", network.fitness_score, flush=True)\n",
    "#         sorted_network_population = sorted(network_population, key=lambda x: x.fitness_score, reverse=True)\n",
    "        \n",
    "#         # Most naive selection approach: get top two scoring networks as parents\n",
    "#         # But should be random with weighted probabilities so that elites are not always parents\n",
    "#         \"\"\"\n",
    "#         parent1 = sorted_network_population[0]\n",
    "#         parent2 = sorted_network_population[1]\n",
    "#         \"\"\"\n",
    "\n",
    "#         print(\"Choosing parents: \", flush=True)\n",
    "#         # Roulette Wheel Selection \n",
    "#         # Chromosomes with higher fitness have a bigger \"slice of the pie\", but are not \n",
    "#         # guaranteed to be selected as parents\n",
    "#         # This is to prevent premature convergence and ensure that the best networks are not always selected as parents\n",
    "        \n",
    "#         fitness_scores = [network.fitness_score for network in sorted_network_population]\n",
    "#         min_score = min(fitness_scores)\n",
    "#         if min_score < 0: # Shift the scores to ensure all are positive\n",
    "#             fitness_scores = [score - min_score for score in fitness_scores]\n",
    "#         max = sum(fitness_scores)\n",
    "#         selection_p = [score / max for score in fitness_scores]\n",
    "        \n",
    "#         parent1 = np.random.choice(sorted_network_population, 1, p=selection_p)[0]\n",
    "#         print(\"parent1 score, \", parent1.fitness_score, flush=True)\n",
    "#         sorted_network_population.remove(parent1)\n",
    "        \n",
    "#         fitness_scores = [network.fitness_score for network in sorted_network_population]\n",
    "#         min_score = min(fitness_scores)\n",
    "#         if min_score < 0: # Shift the scores to ensure all are positive\n",
    "#             fitness_scores = [score - min_score for score in fitness_scores]\n",
    "#         max = sum(fitness_scores)\n",
    "#         selection_p = [score / max for score in fitness_scores]\n",
    "        \n",
    "#         parent2 = np.random.choice(sorted_network_population, 1, p=selection_p)[0]\n",
    "#         print(\"parent2 score, \", parent2.fitness_score, flush=True)\n",
    "#         sorted_network_population.append(parent1)\n",
    "#         sorted_network_population = sorted(network_population, key=lambda x: x.fitness_score, reverse=True)\n",
    "\n",
    "\n",
    "#         # Take num_elites number of the best networks and automatically add them to the next generation\n",
    "#         if (with_elitism):\n",
    "#             for i in range(num_elites):\n",
    "#                 new_network_population.append(sorted_network_population[i])\n",
    "\n",
    "#         # Ex: population_size = 20 and num_elites = 2\n",
    "#         # If no elitism and no growing population, then we will have 10 iterations to produce 20 in the next generation\n",
    "#         # Also, if elitism and growing population, then we will have 10 iterations to produce 22 in the next generation\n",
    "#         if (not with_elitism and not with_growing_population or with_elitism and with_growing_population):\n",
    "#             num_iterations = int(population_size / 2)\n",
    "\n",
    "#         # If with elitism only, maintain the population size and account for the already added elites\n",
    "#         elif (with_elitism):  \n",
    "#             num_iterations = int((population_size - num_elites) / 2)\n",
    "            \n",
    "        \n",
    "\n",
    "#         print(\"GETTING CHILDREN\", flush=True)\n",
    "#         # Generate the population\n",
    "#         for i in range(num_iterations):\n",
    "            \n",
    "#             # Get 2 children from crossovers between the two parents\n",
    "#             child1, child2 = crossover_split_index(parent1, parent2)\n",
    "#             #child1, child2 = crossover_swap_routes(parent1, parent2, num_crossovers_probabilities)\n",
    "            \n",
    "#             index_array = list(range(len(num_mutations_probabilities)))\n",
    "#             num_mutations = np.random.choice(index_array, 1, p=num_mutations_probabilities)[0]\n",
    "\n",
    "#             for j in range(num_mutations):\n",
    "#                 # Apply mutations to the children based on mutation probability hyperparameter\n",
    "#                 if np.random.rand() < mutation_probability:\n",
    "#                     mutate(child1, graph_of_stops)\n",
    "                    \n",
    "#                 if np.random.rand() < mutation_probability:\n",
    "#                     mutate(child2, graph_of_stops)\n",
    "            \n",
    "#             # Add the children to the new population\n",
    "#             new_network_population.append(child1)\n",
    "#             new_network_population.append(child2)\n",
    "#             print(\"ADDED CHILDREN\", flush=True)\n",
    "#         # Assign to next generation\n",
    "#         network_population = new_network_population\n",
    "#         print()\n",
    "\n",
    "#     return network_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GA VERSION 2 - Finding the optimal Network\n",
    "# TODO: WORKING IN PROGRESS\n",
    "\n",
    "# This implementation takes only 2 parents from the whole generation and generates the population from them\n",
    "# Instead of the what's in the paper that says the whole population will go through crossovers and mutations\n",
    "# Cite Nayeem et al for GA with elitism and growing population size\n",
    "def perform_genetic_algorithm(network_population, graph_of_stops, population_size, num_elites, num_generations, mutation_probability, \n",
    "                              num_mutations_probabilities, num_crossovers_probabilities, mutation_threshold_dist, num_failure_removal,\n",
    "                                      weight_random_failure, weight_targeted_failure, weight_connectivity, optimal_fitness_score,\n",
    "                              with_elitism=False, with_growing_population=False, num_mutations_per_generation=1):\n",
    "    \n",
    "    max_fitness_score = 0 # This is the max score of the current population\n",
    "    max_score_list = [] # This is to store all the max scores of each generation\n",
    "    \n",
    "    generation_num = 1\n",
    "    # This will continue to loop until the generation with the max score is equal to the optimal score\n",
    "    #while True:\n",
    "    for _ in range(100): # Test only\n",
    "        print(f\"Generation {generation_num}\", flush=True)\n",
    "        \n",
    "        # Evaluate the fitness of each network in the population\n",
    "        for network in network_population:\n",
    "            network_graph = network.graph\n",
    "            network.fitness_score = compute_fitness_score(network_graph, num_failure_removal, weight_random_failure, weight_targeted_failure, weight_connectivity)\n",
    "\n",
    "        # Sort the network population by fitness score\n",
    "        sorted_network_population = sorted(network_population, key=lambda x: x.fitness_score, reverse=True)\n",
    "        fitness_scores = [network.fitness_score for network in sorted_network_population]\n",
    "        \n",
    "        # The max network score of this generation\n",
    "        max_fitness_score = max(fitness_scores)\n",
    "        max_score_list.append(max_fitness_score)\n",
    "        print(f\"Generation {generation_num} Max Score: {max_fitness_score}\", flush=True)\n",
    "        \n",
    "        # The average network score of this generation\n",
    "        total_score = sum(fitness_scores)\n",
    "        average_score = total_score / len(fitness_scores)\n",
    "        print(f\"Generation {generation_num} Average Score: {average_score}\", flush=True)\n",
    "        \n",
    "        # Check if the score is optimal. If it is, then stop\n",
    "        if max_fitness_score <= optimal_fitness_score:\n",
    "            print(f\"WE FOUND THE OPTIMAL NETWORK IN GENERATION {generation_num}\")\n",
    "            most_optimal_network = sorted_network_population[-1]\n",
    "            print(f\"Fitness Score of the most optimal network: {most_optimal_network.fitness_score}\")\n",
    "            break\n",
    "        \n",
    "        \n",
    "        # Choosing 10% of the networks to be parents using Roulette Wheel Selection\n",
    "        print(\"Choosing parents...\", flush=True)\n",
    "        \n",
    "        #Getting the number of parents to be selected\n",
    "        num_parents = int(len(network_population) * 0.10)\n",
    "        if num_parents % 2 == 1:\n",
    "            num_parents += 1\n",
    "        \n",
    "        # List of parents\n",
    "        parent_networks = []\n",
    "        print(\"NUM PARENTS \", num_parents)\n",
    "        for i in range(num_parents):\n",
    "            # Get the list of all fitness scores\n",
    "            fitness_scores = [network.fitness_score for network in sorted_network_population]\n",
    "            \n",
    "            # Shift the scores to ensure all are positive\n",
    "            min_score = min(fitness_scores)\n",
    "            if min_score < 0:\n",
    "                fitness_scores = [score - min_score for score in fitness_scores]\n",
    "            \n",
    "            # Get the probabilities\n",
    "            total = sum(fitness_scores)\n",
    "            selection_p = [score / total for score in fitness_scores]\n",
    "            \n",
    "            # Getting the parent\n",
    "            chosen_parent = np.random.choice(sorted_network_population, 1, p=selection_p)[0]\n",
    "            print(f\"parent {i} Score, \", chosen_parent.fitness_score, flush=True)\n",
    "            sorted_network_population.remove(chosen_parent)\n",
    "            parent_networks.append(chosen_parent)\n",
    "            \n",
    "            \n",
    "        # Add back all the removed parent networks\n",
    "        sorted_network_population.extend(parent_networks)\n",
    "        \n",
    "        # Sort the networks by fitness function again\n",
    "        sorted_network_population = sorted(network_population, key=lambda x: x.fitness_score, reverse=True)\n",
    "        \n",
    "        # Pairing the parents\n",
    "        parent_pairs = [parent_networks[i:i+2] for i in range(0, len(parent_networks), 2)]\n",
    "\n",
    "        # Each parent pair will now produce children\n",
    "        print(\"GETTING CHILDREN\", flush=True)\n",
    "        children_networks = []\n",
    "        for pair in parent_pairs:\n",
    "            parent1 = pair[0]\n",
    "            parent2 = pair[1]\n",
    "                   \n",
    "            # Get 2 children from crossovers between the two parents\n",
    "            child1, child2 = crossover_split_index(parent1, parent2)\n",
    "            \n",
    "            # Getting the number of mutations\n",
    "            index_array = list(range(len(num_mutations_probabilities)))\n",
    "            num_mutations = np.random.choice(index_array, 1, p=num_mutations_probabilities)[0]\n",
    "\n",
    "            for j in range(num_mutations):\n",
    "                # Apply mutations to the children based on mutation probability hyperparameter\n",
    "                if np.random.rand() < mutation_probability:\n",
    "                    mutate(child1, graph_of_stops)\n",
    "                    \n",
    "                if np.random.rand() < mutation_probability:\n",
    "                    mutate(child2, graph_of_stops)\n",
    "            \n",
    "            # Add the children to the list of children\n",
    "            children_networks.append(child1)\n",
    "            children_networks.append(child2)\n",
    "            \n",
    "        \n",
    "        # Preparing the next generation\n",
    "        \n",
    "        # Remove the lowest scored networks and replace it with the children\n",
    "        network_population = sorted_network_population[len(children_networks):]\n",
    "        network_population.extend(children_networks)\n",
    "        \n",
    "        # Increment the generation number\n",
    "        generation_num += 1\n",
    "        print()\n",
    "\n",
    "    print(f\"Highest score of all generations: {max(max_score_list)}\")\n",
    "    return network_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CROSSOVER SPLIT INDEX FUNCTION\n",
    "\n",
    "# # This crossover implementation splits both networks at an index and exchanges halves\n",
    "# # Assumes that ideally both networks have the same number of routes (same length)\n",
    "# def crossover_split_index(network1, network2):\n",
    "#     # Split both networks at a random index\n",
    "#     # network.routes is a list of routes or list of lists of shortest_path\n",
    "#     if len(network1.routes) < len(network2.routes):\n",
    "#         split_index = random.randint(0, len(network2.routes)-1)\n",
    "#     else:\n",
    "#         split_index = random.randint(0, len(network1.routes)-1)\n",
    "        \n",
    "#     # Create new graphs for the left and right sides\n",
    "#     route_graph1 = nx.Graph()\n",
    "#     route_graph2 = nx.Graph()\n",
    "    \n",
    "#     route_network1 = []\n",
    "#     route_network2 = []\n",
    "    \n",
    "#     used_stops1 = []\n",
    "#     used_stops2 = []\n",
    "    \n",
    "#     conn_type1 = network1.conn_type\n",
    "#     conn_type2 = network2.conn_type\n",
    "    \n",
    "#     count = 0\n",
    "#     for route in network1.routes:\n",
    "#         if count < split_index: # if 0-split_index -> child1 graph\n",
    "#             for connection in route:\n",
    "#                 route_graph1.add_node(connection[0], **network1.graph.nodes[connection[0]])\n",
    "#                 if connection[0] not in used_stops1:\n",
    "#                     used_stops1.append(connection[0])\n",
    "                    \n",
    "#                 route_graph1.add_node(connection[-1], **network1.graph.nodes[connection[-1]])\n",
    "#                 if connection[-1] not in used_stops1:\n",
    "#                     used_stops1.append(connection[-1])\n",
    "                \n",
    "#                 route_graph1.add_edge(connection[0], connection[-1], **network1.graph.get_edge_data(connection[0], connection[-1]))\n",
    "#             route_network1.append(route.copy())\n",
    "            \n",
    "                \n",
    "#         else: # else its for child2 graph\n",
    "#             for connection in route:\n",
    "#                 route_graph2.add_node(connection[0], **network1.graph.nodes[connection[0]])\n",
    "#                 if connection[0] not in used_stops2:\n",
    "#                     used_stops2.append(connection[0])\n",
    "                    \n",
    "#                 route_graph2.add_node(connection[-1], **network1.graph.nodes[connection[-1]])\n",
    "#                 if connection[-1] not in used_stops2:\n",
    "#                     used_stops2.append(connection[-1])\n",
    "                \n",
    "#                 route_graph2.add_edge(connection[0], connection[-1], **network1.graph.get_edge_data(connection[0], connection[-1]))\n",
    "#             route_network2.append(route.copy())\n",
    "#         count += 1\n",
    "        \n",
    "#     count = 0\n",
    "#     for route in network2.routes:\n",
    "#         if count >= split_index: # if split_index-end -> child1 graph\n",
    "#             for connection in route:\n",
    "#                 route_graph1.add_node(connection[0], **network2.graph.nodes[connection[0]])\n",
    "#                 if connection[0] not in used_stops1:\n",
    "#                     used_stops1.append(connection[0])\n",
    "                    \n",
    "#                 route_graph1.add_node(connection[-1], **network2.graph.nodes[connection[-1]])\n",
    "#                 if connection[-1] not in used_stops1:\n",
    "#                     used_stops1.append(connection[-1])\n",
    "                \n",
    "#                 route_graph1.add_edge(connection[0], connection[-1], **network2.graph.get_edge_data(connection[0], connection[-1]))\n",
    "#             route_network1.append(route.copy())\n",
    "                \n",
    "                \n",
    "#         else: # else its for child2 graph\n",
    "#             for connection in route:\n",
    "#                 route_graph2.add_node(connection[0], **network2.graph.nodes[connection[0]])\n",
    "#                 if connection[0] not in used_stops2:\n",
    "#                     used_stops2.append(connection[0])\n",
    "                    \n",
    "#                 route_graph2.add_node(connection[-1], **network2.graph.nodes[connection[-1]])\n",
    "#                 if connection[-1] not in used_stops2:\n",
    "#                     used_stops2.append(connection[-1])\n",
    "                \n",
    "#                 route_graph2.add_edge(connection[0], connection[-1], **network2.graph.get_edge_data(connection[0], connection[-1]))\n",
    "#             route_network2.append(route.copy())\n",
    "#         count += 1\n",
    "    \n",
    "#     child1 = networkObj(route_network1, used_stops1, route_graph1, conn_type1)\n",
    "#     child2 = networkObj(route_network2, used_stops2, route_graph2, conn_type2)\n",
    "    \n",
    "#     print(\"* Checking Child 1 for errors:\", flush=True)\n",
    "#     # TODO: DELETE FOR TESTING IF GRAPH IS CONSISTENT WITH ITS LIST OF ROUTES\n",
    "#     print(\"Checking for graph and route consistency...\", flush=True)\n",
    "#     check_graph_with_route(child1)\n",
    "#     print(\"Checking for graph and list of stops consistency...\", flush=True)\n",
    "#     check_graph_with_stops(child1)\n",
    "#     print(\"Checking if order of routes is correct...\", flush=True)\n",
    "#     check_order_route(child1.routes)\n",
    "#     print(\"Checking for list of stops and route consistency...\", flush=True)\n",
    "#     check_stops_routes(child1)\n",
    "#     print(\"Checking for duplicates in routes...\")\n",
    "#     check_duplicate_routes(child1)\n",
    "#     print()\n",
    "    \n",
    "#     print(\"* Checking Child 2 for errors:\", flush=True)\n",
    "#     # TODO: DELETE FOR TESTING IF GRAPH IS CONSISTENT WITH ITS LIST OF ROUTES\n",
    "#     print(\"Checking for graph and route consistency...\", flush=True)\n",
    "#     check_graph_with_route(child2)\n",
    "#     print(\"Checking for graph and list of stops consistency...\", flush=True)\n",
    "#     check_graph_with_stops(child2)\n",
    "#     print(\"Checking if order of routes is correct...\", flush=True)\n",
    "#     check_order_route(child2.routes)\n",
    "#     print(\"Checking for list of stops and route consistency...\", flush=True)\n",
    "#     check_stops_routes(child2)\n",
    "#     print(\"Checking for duplicates in routes...\")\n",
    "#     check_duplicate_routes(child2)\n",
    "\n",
    "#     return child1, child2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V2 - Crossover routes should not have the same routes\n",
    "# CROSSOVER SPLIT INDEX FUNCTION\n",
    "\n",
    "def crossover_split_index(network1, network2):\n",
    "    # Split both networks based on which routes do not have the same connections\n",
    "    # network.routes is a list of routes or list of lists of shortest_path\n",
    "    routes_same1 = []\n",
    "    routes_not_same1 = []\n",
    "    for route in network1.routes:\n",
    "        not_same = True\n",
    "        \n",
    "        for connection in route:\n",
    "            if network2.graph.has_edge(connection[0], connection[-1]):\n",
    "                not_same = False\n",
    "                continue\n",
    "            \n",
    "        if not_same:\n",
    "            routes_not_same1.append(route)\n",
    "        else:\n",
    "            routes_same1.append(route)\n",
    "    \n",
    "    routes_same2 = []\n",
    "    routes_not_same2 = []\n",
    "    for route in network2.routes:\n",
    "        not_same = True\n",
    "        \n",
    "        for connection in route:\n",
    "            if network1.graph.has_edge(connection[0], connection[-1]):\n",
    "                not_same = False\n",
    "                continue\n",
    "            \n",
    "        if not_same:\n",
    "            routes_not_same2.append(route)\n",
    "        else:\n",
    "            routes_same2.append(route)\n",
    "    \n",
    "    # Create new graphs for the left and right sides\n",
    "    route_graph1 = nx.Graph()\n",
    "    route_graph2 = nx.Graph()\n",
    "    \n",
    "    route_network1 = []\n",
    "    route_network2 = []\n",
    "    \n",
    "    used_stops1 = []\n",
    "    used_stops2 = []\n",
    "    \n",
    "    conn_type1 = network1.conn_type\n",
    "    conn_type2 = network2.conn_type\n",
    "    \n",
    "    # If all are the same, then do not split\n",
    "    if len(routes_not_same1) == 0:\n",
    "        test_graph_net1 = network1.graph.copy()\n",
    "        test_routes_net1 = [copy.deepcopy(r) for r in network1.routes]\n",
    "        test_stops_net1 = [copy.deepcopy(s) for s in network1.stops]\n",
    "        child1 = networkObj(test_routes_net1, test_stops_net1, test_graph_net1, network1.conn_type)\n",
    "\n",
    "        test_graph_net2 = network2.graph.copy()\n",
    "        test_routes_net2 = [copy.deepcopy(r) for r in network2.routes]\n",
    "        test_stops_net2 = [copy.deepcopy(s) for s in network2.stops]\n",
    "        child2 = networkObj(test_routes_net2, test_stops_net2, test_graph_net2, network2.conn_type)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # PARENT 1\n",
    "        # All not same routes from parent 1 will go to child 2\n",
    "        for route in routes_not_same1:\n",
    "            for connection in route:\n",
    "                route_graph2.add_node(connection[0], **network1.graph.nodes[connection[0]])\n",
    "                if connection[0] not in used_stops2:\n",
    "                    used_stops2.append(connection[0])\n",
    "                    \n",
    "                route_graph2.add_node(connection[-1], **network1.graph.nodes[connection[-1]])\n",
    "                if connection[-1] not in used_stops2:\n",
    "                    used_stops2.append(connection[-1])\n",
    "                \n",
    "                route_graph2.add_edge(connection[0], connection[-1], **network1.graph.get_edge_data(connection[0], connection[-1]))\n",
    "            route_network2.append(route.copy())\n",
    "        \n",
    "        # All same routes from parent 1 will go to child 1\n",
    "        for route in routes_same1:\n",
    "            for connection in route:\n",
    "                route_graph1.add_node(connection[0], **network1.graph.nodes[connection[0]])\n",
    "                if connection[0] not in used_stops1:\n",
    "                    used_stops1.append(connection[0])\n",
    "                    \n",
    "                route_graph1.add_node(connection[-1], **network1.graph.nodes[connection[-1]])\n",
    "                if connection[-1] not in used_stops1:\n",
    "                    used_stops1.append(connection[-1])\n",
    "                \n",
    "                route_graph1.add_edge(connection[0], connection[-1], **network1.graph.get_edge_data(connection[0], connection[-1]))\n",
    "            route_network1.append(route.copy())\n",
    "            \n",
    "        # PARENT 2\n",
    "        # All not same routes from parent 2 will go to child 1\n",
    "        for route in routes_not_same2:\n",
    "            for connection in route:\n",
    "                route_graph1.add_node(connection[0], **network2.graph.nodes[connection[0]])\n",
    "                if connection[0] not in used_stops1:\n",
    "                    used_stops1.append(connection[0])\n",
    "                    \n",
    "                route_graph1.add_node(connection[-1], **network2.graph.nodes[connection[-1]])\n",
    "                if connection[-1] not in used_stops1:\n",
    "                    used_stops1.append(connection[-1])\n",
    "                \n",
    "                route_graph1.add_edge(connection[0], connection[-1], **network2.graph.get_edge_data(connection[0], connection[-1]))\n",
    "            route_network1.append(route.copy())\n",
    "        \n",
    "        # All same routes from parent 2 will go to child 2\n",
    "        for route in routes_same2:\n",
    "            for connection in route:\n",
    "                route_graph2.add_node(connection[0], **network2.graph.nodes[connection[0]])\n",
    "                if connection[0] not in used_stops2:\n",
    "                    used_stops2.append(connection[0])\n",
    "                    \n",
    "                route_graph2.add_node(connection[-1], **network2.graph.nodes[connection[-1]])\n",
    "                if connection[-1] not in used_stops2:\n",
    "                    used_stops2.append(connection[-1])\n",
    "                \n",
    "                route_graph2.add_edge(connection[0], connection[-1], **network2.graph.get_edge_data(connection[0], connection[-1]))\n",
    "            route_network2.append(route.copy())\n",
    "    \n",
    "        child1 = networkObj(route_network1, used_stops1, route_graph1, conn_type1)\n",
    "        child2 = networkObj(route_network2, used_stops2, route_graph2, conn_type2)\n",
    "    \n",
    "    print(\"* Checking Child 1 for errors:\", flush=True)\n",
    "    # TODO: DELETE FOR TESTING IF GRAPH IS CONSISTENT WITH ITS LIST OF ROUTES\n",
    "    print(\"Checking for graph and route consistency...\", flush=True)\n",
    "    check_graph_with_route(child1)\n",
    "    print(\"Checking for graph and list of stops consistency...\", flush=True)\n",
    "    check_graph_with_stops(child1)\n",
    "    print(\"Checking if order of routes is correct...\", flush=True)\n",
    "    check_order_route(child1.routes)\n",
    "    print(\"Checking for list of stops and route consistency...\", flush=True)\n",
    "    check_stops_routes(child1)\n",
    "    print(\"Checking for duplicates in routes...\")\n",
    "    check_duplicate_routes(child1)\n",
    "    print()\n",
    "    \n",
    "    print(\"* Checking Child 2 for errors:\", flush=True)\n",
    "    # TODO: DELETE FOR TESTING IF GRAPH IS CONSISTENT WITH ITS LIST OF ROUTES\n",
    "    print(\"Checking for graph and route consistency...\", flush=True)\n",
    "    check_graph_with_route(child2)\n",
    "    print(\"Checking for graph and list of stops consistency...\", flush=True)\n",
    "    check_graph_with_stops(child2)\n",
    "    print(\"Checking if order of routes is correct...\", flush=True)\n",
    "    check_order_route(child2.routes)\n",
    "    print(\"Checking for list of stops and route consistency...\", flush=True)\n",
    "    check_stops_routes(child2)\n",
    "    print(\"Checking for duplicates in routes...\")\n",
    "    check_duplicate_routes(child2)\n",
    "\n",
    "    return child1, child2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUTATION FUNCTION\n",
    "\n",
    "# Modify the stop connections of a random route in the network\n",
    "# Randomly select a route and randomly select a stop in that route\n",
    "# Then randomly select another stop that is a not too far from the selected stop based on threshold\n",
    "# Swap connections with that stop\n",
    "def mutate(network_to_mutate, graph_of_stops):\n",
    "    global set_walk_distance, MAX_DISTANCE\n",
    "    \n",
    "    # This is to copy the original network to be compared later\n",
    "    test_graph_net2 = network_to_mutate.graph.copy()\n",
    "    test_routes_net2 = [copy.deepcopy(r) for r in network_to_mutate.routes]\n",
    "    test_stops_net2 = network_to_mutate.stops.copy()\n",
    "    test_stops_connType2 = network_to_mutate.conn_type\n",
    "    copy_test_network = networkObj(test_routes_net2, test_stops_net2, test_graph_net2, test_stops_connType2)\n",
    "    \n",
    "    # Randomly select a route\n",
    "    random_route = random.choice(network_to_mutate.routes)\n",
    "\n",
    "    \n",
    "    # TODO: This is a temporary solution, it chooses either of the connections within the route except for the first and last connection\n",
    "    # Randomly select a stop in the route\n",
    "    # random_node_connection = random.choice(random_route) # Choose a random connection in the route\n",
    "    index_array = list(range(1, len(random_route)-1))\n",
    "    connection_index = random.choice(index_array)\n",
    "    random_node_connection = random_route[connection_index]\n",
    "    \n",
    "    connection_stop_index = random.choice([0, -1]) # Choose whether the origin or destination node\n",
    "    random_stop = random_node_connection[connection_stop_index] # The random stop to be swapped\n",
    "    \n",
    "    print(\"PICKED NODE TO SWAP - \", random_stop)\n",
    "    \n",
    "    # Get the old total distance\n",
    "    old_total_distance = 0\n",
    "    for connection in random_route:\n",
    "        edge_data = network_to_mutate.graph.get_edge_data(connection[0], connection[-1])\n",
    "        \n",
    "        if edge_data == None:\n",
    "            print(\"-- ERROR MISSING EDGE INFORMATION: \", connection[0], \" - \", connection[-1])\n",
    "        else:\n",
    "            old_total_distance += edge_data['distance']\n",
    "    \n",
    "    \n",
    "    # This is to get the subset distance (Distance without the connection with chosen random stop)\n",
    "    if connection_stop_index == 0: # If it is the origin node in that connection (A, B, C and B is the chosen. Get B-C and A-B)\n",
    "        prev_connection = random_route[connection_index-1] # Get the previous connection\n",
    "        prev_node = prev_connection[0] # Get the origin node for that connection\n",
    "        distance1 = network_to_mutate.graph.get_edge_data(prev_node, random_stop)['distance'] # Get the distance of the previous connection\n",
    "        distance2 = network_to_mutate.graph.get_edge_data(random_stop, random_node_connection[-1])['distance'] # Get the distance of the current connection\n",
    "        distance_to_subtract = distance1 + distance2\n",
    "        \n",
    "        # Previous connection: node1 - random_node\n",
    "        # Current connection: random_node - node2\n",
    "        node1 = prev_node # Setting the partner nodes\n",
    "        node2 = random_node_connection[-1]\n",
    "        \n",
    "    else: #If it is the dest node in that connection\n",
    "        distance1 = network_to_mutate.graph.get_edge_data(random_node_connection[0], random_stop)['distance'] # Get the distance of the current connection\n",
    "        next_connection = random_route[connection_index+1] # Get the next route\n",
    "        next_node = next_connection[-1] # Get the destination node for the next connection\n",
    "        distance2 = network_to_mutate.graph.get_edge_data(random_stop, next_node)['distance']\n",
    "        distance_to_subtract = distance1 + distance2\n",
    "        \n",
    "        # Previous connection: node1 - random_node\n",
    "        # Current connection: random_node - node2\n",
    "        node2 = next_node\n",
    "        node1 = random_node_connection[0]\n",
    "        \n",
    "    subset_distance = old_total_distance - distance_to_subtract\n",
    "    # Get the route id\n",
    "    random_route_id = network_to_mutate.graph.get_edge_data(random_node_connection[0], random_node_connection[-1])['route_id']\n",
    "    \n",
    "    # Will try searching for a random stop 50 times (arbitrary)\n",
    "    for i in range(50):\n",
    "        # Get a random stop\n",
    "        new_random_stop, new_random_stop_data = random.choice(list(graph_of_stops.nodes(data=True)))\n",
    "        \n",
    "        # Check if the new random stop is not within walking distance with the other stop in the route\n",
    "        # Walking distance between node1 in route and stop to be swapped with\n",
    "        source = (new_random_stop_data['lat'], new_random_stop_data['lon'])\n",
    "        point = (graph_of_stops.nodes[node1]['lat'], graph_of_stops.nodes[node1]['lon'])\n",
    "        walking_distance1 = geodesic(source, point).meters\n",
    "        \n",
    "        # Walking distance between node2 in route and stop to be swapped with\n",
    "        source = (new_random_stop_data['lat'], new_random_stop_data['lon'])\n",
    "        point = (graph_of_stops.nodes[node2]['lat'], graph_of_stops.nodes[node2]['lon'])\n",
    "        walking_distance2 = geodesic(source, point).meters\n",
    "        \n",
    "        # Check if it already has been used in the route\n",
    "        isCandidate = True\n",
    "        for connection in random_route:\n",
    "            if new_random_stop == connection[0] or new_random_stop == connection[-1]:\n",
    "                isCandidate = False\n",
    "                print(\"NEW NODE WAS ALREADY USED\", flush=True)\n",
    "                continue\n",
    "        \n",
    "        # Check if the edge has already been used\n",
    "        has_edge1 = network_to_mutate.graph.has_edge(node1, new_random_stop)\n",
    "        has_edge2 = network_to_mutate.graph.has_edge(new_random_stop, node2)\n",
    "        \n",
    "        if has_edge1:\n",
    "            print(f\"** Already have edge 1\")\n",
    "        if has_edge2:\n",
    "            print(f\"** Already have edge 2\")\n",
    "            \n",
    "        if i == 49:\n",
    "            print(\"------REACHED END\")\n",
    "        \n",
    "        # If it is not within walking distances, has not been used in the same route, has a path, has no existing edge\n",
    "        if walking_distance1 >= set_walk_distance and walking_distance2 >= set_walk_distance and isCandidate and nx.has_path(CITY_GRAPH, node1, new_random_stop) and nx.has_path(CITY_GRAPH, new_random_stop, node2) and not has_edge1 and not has_edge2:\n",
    "            # DISTANCE 1: Get the total distance from point A to point B\n",
    "            shortest_route1 = nx.shortest_path(CITY_GRAPH, node1, new_random_stop)\n",
    "            distance_travelled1 = 0\n",
    "            for i in range(len(shortest_route1)-1):\n",
    "                node_data = CITY_GRAPH.nodes[shortest_route1[i]]\n",
    "                next_node_data = CITY_GRAPH.nodes[shortest_route1[i+1]]\n",
    "                distance_travelled1 += haversine(node_data['y'], node_data['x'], next_node_data['y'], next_node_data['x'])\n",
    "            \n",
    "            # DISTANCE 2: Get the total distance from point A to point B\n",
    "            shortest_route2 = nx.shortest_path(CITY_GRAPH, new_random_stop, node2)\n",
    "            distance_travelled2 = 0\n",
    "            for i in range(len(shortest_route2)-1):\n",
    "                node_data = CITY_GRAPH.nodes[shortest_route2[i]]\n",
    "                next_node_data = CITY_GRAPH.nodes[shortest_route2[i+1]]\n",
    "                distance_travelled2 += haversine(node_data['y'], node_data['x'], next_node_data['y'], next_node_data['x'])\n",
    "                \n",
    "            \n",
    "            # If its within the 15km distance, then this new stop can be used\n",
    "            if subset_distance + distance_travelled1 + distance_travelled2 <= MAX_DISTANCE:\n",
    "                # Add the new stop to the used stops\n",
    "                if new_random_stop not in network_to_mutate.stops:\n",
    "                    network_to_mutate.stops.append(new_random_stop)\n",
    "                \n",
    "                # Modify the graph by adding the new node\n",
    "                network_to_mutate.graph.add_node(new_random_stop, **graph_of_stops.nodes[new_random_stop])\n",
    "                print(\"MUTATION: ADDED NEW NODE TO GRAPH \", new_random_stop)\n",
    "                \n",
    "                # Connect the new stop to the edges\n",
    "                name1 = f\"{shortest_route1[0]}_{shortest_route1[-1]}\"\n",
    "                name2 = f\"{shortest_route2[0]}_{shortest_route2[-1]}\"\n",
    "                connection_count1 = network_to_mutate.graph.get_edge_data(node1, random_stop)['edge_id']\n",
    "                connection_count2 = network_to_mutate.graph.get_edge_data(random_stop, node2)['edge_id']\n",
    "                network_to_mutate.graph.add_edge(shortest_route1[0], shortest_route1[-1], road_path=shortest_route1, edge_name=name1, edge_id = connection_count1, route_id = random_route_id, distance = distance_travelled1) # Add edge\n",
    "                network_to_mutate.graph.add_edge(shortest_route2[0], shortest_route2[-1], road_path=shortest_route2, edge_name=name2, edge_id = connection_count2, route_id = random_route_id, distance = distance_travelled2) # Add edge \n",
    "                \n",
    "                #TODO: DELETE PRINT FOR TESTING\n",
    "                print(\"MUTATION: CONNECTED NEW STOP TO EDGES\")  \n",
    "                \n",
    "                # Remove the old connections and node if it has no other connections\n",
    "                network_to_mutate.graph.remove_edge(node1, random_stop)\n",
    "                network_to_mutate.graph.remove_edge(random_stop, node2)\n",
    "                print(\"MUTATION: REMOVED OLD CONNECTIONS TO NODE\")\n",
    "                if (network_to_mutate.graph.degree(random_stop) == 0):\n",
    "                    network_to_mutate.graph.remove_node(random_stop)                \n",
    "                    network_to_mutate.stops.remove(random_stop)\n",
    "                    \n",
    "                    print(\"MUTATION: REMOVED OLD NODE \", random_stop)\n",
    "                else:\n",
    "                    print(\"MUTATION: DIDNT REMOVED OLD NODE \", random_stop)\n",
    "                \n",
    "                # TODO: Delete FOR TESTING ONLY\n",
    "                unique_nodes_G1 = set(copy_test_network.graph.nodes) - set(network_to_mutate.graph.nodes)\n",
    "                unique_edges_G1 = set(copy_test_network.graph.edges) - set(network_to_mutate.graph.edges)\n",
    "\n",
    "                unique_nodes_G2 = set(network_to_mutate.graph.nodes) - set(copy_test_network.graph.nodes)\n",
    "                unique_edges_G2 = set(network_to_mutate.graph.edges) - set(copy_test_network.graph.edges)\n",
    "                print(\"TESTING DIFFERENCES BETWEEN ORIGINAL AND OLD GRAPH\")\n",
    "                \n",
    "                # Display unique nodes and edges for G1\n",
    "                print(\"Unique nodes in original (not in new):\")\n",
    "                for node in unique_nodes_G1:\n",
    "                    print(node)\n",
    "\n",
    "                print(\"Unique edges in original (not in new):\")\n",
    "                for edge in unique_edges_G1:\n",
    "                    print(edge)\n",
    "\n",
    "                # Display unique nodes and edges for G2\n",
    "                print(\"Unique nodes in new (not in original):\")\n",
    "                for node in unique_nodes_G2:\n",
    "                    print(node)\n",
    "\n",
    "                print(\"Unique edges in new (not in original):\")\n",
    "                for edge in unique_edges_G2:\n",
    "                    print(edge)\n",
    "                \n",
    "                # Modify the route\n",
    "                if connection_stop_index == 0: #If its the origin node\n",
    "                    random_route[connection_index-1] = shortest_route1 # Change the previous connection\n",
    "                    random_route[connection_index] = shortest_route2 # Change the current connection\n",
    "                    \n",
    "                    #TODO: DELETE FOR TESTING\n",
    "                    random_route2 = copy_test_network.routes[network_to_mutate.routes.index(random_route)]\n",
    "                    print(\"ORIGINAL: \", random_route2[connection_index-1][0], \" - \", random_route2[connection_index-1][-1])\n",
    "                    print(\"ORIGINAL: \", random_route2[connection_index][0], \" - \", random_route2[connection_index][-1])\n",
    "                    print(\"MODIFIED: \", random_route[connection_index-1][0], \" - \", random_route[connection_index-1][-1])\n",
    "                    print(\"MODIFIED: \", random_route[connection_index][0], \" - \", random_route[connection_index][-1])\n",
    "                    \n",
    "                else: #else If its the dest node\n",
    "                    random_route[connection_index] = shortest_route1 # Change the current connection\n",
    "                    random_route[connection_index+1] = shortest_route2 # Change the next connection\n",
    "                    \n",
    "                    #TODO: DELETE FOR TESTING\n",
    "                    random_route2 = copy_test_network.routes[network_to_mutate.routes.index(random_route)]\n",
    "                    print(\"ORIGINAL: \", random_route2[connection_index][0], \" - \", random_route2[connection_index][-1])\n",
    "                    print(\"ORIGINAL: \", random_route2[connection_index+1][0], \" - \", random_route2[connection_index+1][-1])\n",
    "                    print(\"MODIFIED: \", random_route[connection_index][0], \" - \", random_route[connection_index][-1])\n",
    "                    print(\"MODIFIED: \", random_route[connection_index+1][0], \" - \", random_route[connection_index+1][-1])\n",
    "                    \n",
    "                print(\"MUTATION: MODIFIED THE NETWORK OBJECT'S ROUTE\")\n",
    "                \n",
    "                        \n",
    "                # TODO: DELETE FOR TESTING IF GRAPH IS CONSISTENT WITH ITS LIST OF ROUTES\n",
    "                print(\"Checking for graph and route consistency...\")\n",
    "                check_graph_with_route(network_to_mutate)\n",
    "                print(\"Checking for graph and list of stops consistency...\")\n",
    "                check_graph_with_stops(network_to_mutate)\n",
    "                print(\"Checking if order of routes is correct...\")\n",
    "                check_order_route(network_to_mutate.routes)\n",
    "                print(\"Checking for list of stops and route consistency...\")\n",
    "                check_stops_routes(network_to_mutate)\n",
    "                print(\"Checking for duplicates in routes...\")\n",
    "                check_duplicate_routes(network_to_mutate)\n",
    "                \n",
    "                print(\"MUTATION DONE\", flush=True)\n",
    "                \n",
    "                \n",
    "                # Break the loop once we swap\n",
    "                print()\n",
    "                break  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitness Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitness function\n",
    "\n",
    "def select_highest_scoring_mutation(candidate_road_snapped_networks, num_failure_removal,\n",
    "                                    weight_random_failure, weight_targeted_failure, weight_radius_of_gyration):\n",
    "    max_fitness_score = -np.inf\n",
    "    max_candidate_route_snapped_network = None\n",
    "\n",
    "    for n in candidate_road_snapped_networks:\n",
    "        fitness_score = compute_fitness_score(n, num_failure_removal,\n",
    "                                              weight_random_failure, weight_targeted_failure, weight_radius_of_gyration)\n",
    "        if fitness_score > max_fitness_score:\n",
    "            max_fitness_score = fitness_score\n",
    "            max_candidate_route_snapped_network = n\n",
    "\n",
    "    return max_candidate_route_snapped_network\n",
    "\n",
    "def compute_fitness_score(road_snapped_network_graph, num_failure_removal,\n",
    "                          weight_random_failure, weight_targeted_failure, weight_connectivity):\n",
    "\n",
    "    random_failure_robustness = compute_random_failure_robustness(road_snapped_network_graph, num_failure_removal)\n",
    "    weighted_random_failure_robustness = weight_random_failure * random_failure_robustness\n",
    "\n",
    "    targeted_failure_robustness = compute_targeted_failure_robustness(road_snapped_network_graph, num_failure_removal)\n",
    "    weighted_targeted_failure_robustness = weight_targeted_failure * targeted_failure_robustness\n",
    "\n",
    "    connectivity_score = compute_connectivity(road_snapped_network_graph)\n",
    "    weighted_connectivity = weight_connectivity * connectivity_score\n",
    "    \n",
    "    print(\"Random Failure Score: \", weighted_random_failure_robustness)\n",
    "    print(\"Target Failure Score: \", weighted_targeted_failure_robustness)\n",
    "    print(\"Connectivity: \", weighted_connectivity)\n",
    "\n",
    "    # Will use this return for now to utilize target and random failure nodes \n",
    "    return weighted_connectivity - weighted_random_failure_robustness - weighted_targeted_failure_robustness\n",
    "    # return weighted_radius_of_gyration\n",
    "\n",
    "\n",
    "### WRITTEN IN PSEUDOCODE\n",
    "def compute_connectivity(network):\n",
    "    # External connectivity - measure how connected is the jeepney route network with other modes of transpo\n",
    "    \n",
    "    # Get the ratio of transportation stops to total stops in the network\n",
    "    transpo_stops = [node for node, node_data in network.nodes(data=True) if node_data['isTranspo'] == True]\n",
    "    total_stops = len(network.nodes(data=True))\n",
    "    transpo_stop_ratio = len(transpo_stops) / total_stops\n",
    "\n",
    "    # Get the average degree of all transportation stops in the network\n",
    "    if len(transpo_stops) > 0:\n",
    "        avg_transpo_degree = sum(network.degree(stop) for stop in transpo_stops) / len(transpo_stops)\n",
    "    else:\n",
    "        avg_transpo_degree = 1\n",
    "\n",
    "    # Find a way to normalize the two values and combine them \n",
    "\n",
    "    # Internal connectivity - measure how connected is each jeepney route to other jeepney routes\n",
    "                    \n",
    "    # This counts how many nodes have intersections (Meaning node is connected to more than one route by route ID)\n",
    "    num_intersections = 0\n",
    "    for node, node_data in network.nodes(data=True):\n",
    "        connected_edges = network.edges(node)\n",
    "        unique_route_id = []\n",
    "        \n",
    "        for edge in connected_edges:\n",
    "            route_id = network[edge[0]][edge[1]]['route_id']\n",
    "            \n",
    "            if route_id not in unique_route_id:\n",
    "                unique_route_id.append(route_id)\n",
    "                \n",
    "        if len(unique_route_id) > 1:\n",
    "            num_intersections += 1\n",
    "\n",
    "    \n",
    "    # Change these weights based on what the expected values for \n",
    "    # the transpo_stop_ratio, avg_transpo_degree, and num_intersections will be\n",
    "    external_weight = 0.5\n",
    "    internal_weight = 0.5\n",
    "    \n",
    "    # TODO: Delete this\n",
    "    print(\"Transpo stop ratio: \", transpo_stop_ratio)\n",
    "    print(\"Num intersections: \", num_intersections)\n",
    "    print(\"Average degree: \", avg_transpo_degree)\n",
    "\n",
    "    # Formula subject to change\n",
    "    return external_weight * (transpo_stop_ratio * avg_transpo_degree) + internal_weight * num_intersections\n",
    "\n",
    "\n",
    "def compute_random_failure_robustness(road_snapped_network_graph, num_removals):\n",
    "    graph_copy = road_snapped_network_graph.copy() # Make a copy\n",
    "    \n",
    "    for i in range(num_removals):\n",
    "        selected_node = random.choice(list(graph_copy.nodes()))\n",
    "        graph_copy.remove_node(selected_node)\n",
    "\n",
    "    diameter, avg_path_length = compute_network_statistics(graph_copy)\n",
    "    return compute_failure_robustness(graph_copy, diameter)\n",
    "\n",
    "def compute_targeted_failure_robustness(road_snapped_network_graph, num_removals):\n",
    "    graph_copy = road_snapped_network_graph.copy() # Make a copy\n",
    "    \n",
    "    for i in range(num_removals):\n",
    "        node_degrees = graph_copy.degree()\n",
    "        # Iterate over the DegreeView object to find the maximum degree\n",
    "        max_degree = max(degree for _, degree in node_degrees)\n",
    "        max_degree_node = get_node_with_degree(node_degrees, max_degree)\n",
    "        graph_copy.remove_node(max_degree_node)\n",
    "\n",
    "    diameter, avg_path_length = compute_network_statistics(graph_copy)\n",
    "    return compute_failure_robustness(graph_copy, diameter)\n",
    "\n",
    "def compute_failure_robustness(road_snapped_network_graph, max_path_length):\n",
    "    return float(max_path_length) / float(len(road_snapped_network_graph) - 1)\n",
    "\n",
    "def compute_network_statistics(road_snapped_network_graph):\n",
    "    path_lengths = get_path_lengths(road_snapped_network_graph) # Get the sum of all possible\n",
    "    avg_path_length = np.mean(path_lengths)\n",
    "    max_path_length = max(path_lengths)\n",
    "\n",
    "    #network_size = len(path_lengths)\n",
    "    #gcc = sorted(nx.connected_component_subgraphs(road_snapped_network_graph), key=len, reverse=True)\n",
    "    #giant_component_fraction = float(float(gcc[0].order()) / float(network_size))\n",
    "    #return max_path_length, avg_path_length, giant_component_fraction\n",
    "    return max_path_length, avg_path_length\n",
    "\n",
    "def get_node_with_degree(node_degrees, degree):\n",
    "    # Iterate over the DegreeView object to find the node with the specified degree\n",
    "    for node, _ in node_degrees:\n",
    "        if _ == degree:\n",
    "            return node\n",
    "    return None  # Return None if no node with the specified degree is found\n",
    "\n",
    "def get_path_lengths(snapped_road_network_graph):\n",
    "    return [sum(nx.single_source_shortest_path_length(snapped_road_network_graph, n).values())\n",
    "            for n in snapped_road_network_graph]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Error Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GA TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for network in list_of_networks_Manila:\n",
    "    check_duplicate_routes(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: DELETE FOR GA TESTING ONLY\n",
    "#Testing crossover and mutate\n",
    "\n",
    "network1= list_of_networks_Manila[0]\n",
    "network2= list_of_networks_Manila[1]\n",
    "\n",
    "test_graph_net1 = network1.graph.copy()\n",
    "test_routes_net1 = [copy.deepcopy(r) for r in network1.routes]\n",
    "test_stops_net1 = network1.stops.copy()\n",
    "copy_test_network1 = networkObj(test_routes_net1, test_stops_net1, test_graph_net1, list_of_networks_Manila[0].conn_type)\n",
    "\n",
    "test_graph_net2 = network2.graph.copy()\n",
    "test_routes_net2 = [copy.deepcopy(r) for r in network2.routes]\n",
    "test_stops_net2 = network2.stops.copy()\n",
    "copy_test_network2 = networkObj(test_routes_net2, test_stops_net2, test_graph_net2, list_of_networks_Manila[1].conn_type)\n",
    "\n",
    "child1, child2 = crossover_split_index(copy_test_network1,copy_test_network2)\n",
    "\n",
    "map_center = (14.599512, 120.984222)\n",
    "\n",
    "print(\"--------------- START\")\n",
    "if len(child1.graph) != len(child1.stops):\n",
    "        print(\"-----CHILD 1 STOPS AND GRAPH NOT EQUAL\")\n",
    "if len(child2.graph) != len(child2.stops):\n",
    "    print(\"-----CHILD 2 STOPS AND GRAPH NOT EQUAL\")\n",
    "print(\"--------------- END\")\n",
    "print()\n",
    "        \n",
    "# -----Child 1 Display -------------\n",
    "# m = folium.Map(location=map_center, zoom_start=1, tiles='openstreetmap')\n",
    "# add_markers(child1.stops, child1.graph)\n",
    "    \n",
    "# for route in child1.routes:\n",
    "#     for connection in route:\n",
    "#         ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "# m.save(f\"GA TEST (DELETE LATER)/child1_crossover.html\")\n",
    "\n",
    "# ------Child 2 Display ------------\n",
    "# m = folium.Map(location=map_center, zoom_start=1, tiles='openstreetmap')\n",
    "# add_markers(child2.stops, child2.graph)\n",
    "    \n",
    "# for route in child2.routes:\n",
    "#     for connection in route:\n",
    "#         ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "# m.save(f\"GA TEST (DELETE LATER)/child2_crossover.html\")\n",
    "\n",
    "\n",
    "# # ---------Graph test---------------\n",
    "# # TODO: Delete FOR TESTING ONLY\n",
    "# unique_nodes_G1 = set(child1.graph.nodes) - set(child2.graph.nodes)\n",
    "# unique_edges_G1 = set(child1.graph.edges) - set(child2.graph.edges)\n",
    "\n",
    "# unique_nodes_G2 = set(child2.graph.nodes) - set(child1.graph.nodes)\n",
    "# unique_edges_G2 = set(child2.graph.edges) - set(child1.graph.edges)\n",
    "# print(\"TESTING DIFFERENCES BETWEEN Child1 AND Child2\")\n",
    "\n",
    "# # Display unique nodes and edges for G1\n",
    "# print(\"Unique nodes in child1 (not in child2):\")\n",
    "# for node in unique_nodes_G1:\n",
    "#     print(node)\n",
    "\n",
    "# print(\"Unique edges in child1 (not in child2):\")\n",
    "# for edge in unique_edges_G1:\n",
    "#     print(edge)\n",
    "\n",
    "# # Display unique nodes and edges for G2\n",
    "# print(\"Unique nodes in child2 (not in child1):\")\n",
    "# for node in unique_nodes_G2:\n",
    "#     print(node)\n",
    "\n",
    "# print(\"Unique edges in child2 (not in child1):\")\n",
    "# for edge in unique_edges_G2:\n",
    "#     print(edge)\n",
    "\n",
    "# --------Mutate test --------------\n",
    "for i in range(50):\n",
    "    print(\"Child 1 ATTEMPT MUTATION\")\n",
    "    mutate(child1, graph_of_stops_Manila)\n",
    "    print(\"-------------------------\")\n",
    "    print()\n",
    "    \n",
    "    print(\"Child 2 ATTEMPT MUTATION\")\n",
    "    mutate(child2, graph_of_stops_Manila)\n",
    "    print(\"-------------------------\")\n",
    "    print()\n",
    "    \n",
    "    if len(child1.graph) != len(child1.stops):\n",
    "        print(\"-----CHILD 1 STOPS AND GRAPH NOT EQUAL\")\n",
    "    if len(child2.graph) != len(child2.stops):\n",
    "        print(\"-----CHILD 2 STOPS AND GRAPH NOT EQUAL\")\n",
    "\n",
    "    # # -----Child 1 Mutation Display -------------\n",
    "    # m = folium.Map(location=map_center, zoom_start=1, tiles='openstreetmap')\n",
    "    # add_markers(child1.stops, child1.graph)\n",
    "        \n",
    "    # for route in child1.routes:\n",
    "    #     for connection in route:\n",
    "    #         ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "    # m.save(f\"GA TEST (DELETE LATER)/child1_mutation{i}.html\")\n",
    "\n",
    "    # # ------Child 2 Mutation Display ------------\n",
    "    # m = folium.Map(location=map_center, zoom_start=1, tiles='openstreetmap')\n",
    "    # add_markers(child2.stops, child2.graph)\n",
    "        \n",
    "    # for route in child2.routes:\n",
    "    #     for connection in route:\n",
    "    #         ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "    # m.save(f\"GA TEST (DELETE LATER)/child2_mutation{i}.html\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Graph Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERROR CHECK - Checking if there are duplicate routes in the list of routes\n",
    "def check_duplicate_routes(network):\n",
    "    seen = set()\n",
    "    duplicates = []\n",
    "\n",
    "    for route in network.routes:\n",
    "        for lst in route:\n",
    "            tpl = tuple(lst)\n",
    "            if tpl in seen:\n",
    "                duplicates.append(lst)\n",
    "            else:\n",
    "                seen.add(tpl)\n",
    "\n",
    "    if duplicates:\n",
    "        print(\"----Duplicate lists found:\")\n",
    "        for duplicate in duplicates:\n",
    "            print(duplicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERROR Check - Checks if routes is consistent with its stops\n",
    "def check_stops_routes(network):\n",
    "    # Checks if each node in the route is in the list of stops\n",
    "    for route in network.routes:\n",
    "        for connection in route:\n",
    "            if connection[0] not in network.stops:\n",
    "                print(\"-- MISSING ROUTE ORIGIN STOP IN LIST OF STOPS \", connection[0])\n",
    "            if connection[-1] not in network.stops:\n",
    "                print(\"-- MISSING ROUTE DEST STOP IN LIST OF STOPS \", connection[-1])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: WORKING IN PROGRESS\n",
    "# # ERROR Check - Checks if there are no duplicate nodes in a route\n",
    "# def check_duplicate_stops_route(routes):\n",
    "#     for route in routes:\n",
    "#         for connection in route:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERROR Check - Checks if the routes are in correct order\n",
    "def check_order_route(routes):\n",
    "    for route in routes:\n",
    "        for connection in route:\n",
    "            if route.index(connection) > 0:\n",
    "                if connection[0] != prev_connection[-1]:\n",
    "                    print(\"-- WRONG ORDER DETECTED --\")\n",
    "                    print(prev_connection[0], \" - \", prev_connection[-1])\n",
    "                    print(connection[0], \" - \", connection[-1])\n",
    "                    print(\"--------------------------\")\n",
    "            prev_connection = connection\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERROR CHECK - Checks the consistency of the network with its routes\n",
    "def check_graph_with_route(_network):\n",
    "    for route in _network.routes:\n",
    "        for connection in route:\n",
    "            if not _network.graph.has_node(connection[0]):\n",
    "                print(\"-- MISSING NODE IN GRAPH: \", connection[0])\n",
    "            if not _network.graph.has_node(connection[-1]):\n",
    "                print(\"-- MISSING NODE IN GRAPH: \", connection[-1])\n",
    "            if not _network.graph.has_edge(connection[0], connection[-1]):\n",
    "                print(\"-- MISSING EDGE IN GRAPH: \", connection[0], \" - \", connection[-1])\n",
    "                \n",
    "            if _network.graph.get_edge_data(connection[0], connection[-1]) == None:\n",
    "                print(\"-- MISSING EDGE INFORMATION: \", connection[0], \" - \", connection[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERROR CHECK - Checks the consistency of the network with its list of stops\n",
    "def check_graph_with_stops(_network):\n",
    "    \n",
    "    # Checks if all stops in the list is in the graph\n",
    "    for stop in _network.stops:\n",
    "        if not _network.graph.has_node(stop):\n",
    "            print(\"-- MISSING LIST STOP IN GRAPH: \", stop)\n",
    "            \n",
    "    # Checks if all nodes in the graph are in the list\n",
    "    for node, node_data in _network.graph.nodes(data=True):\n",
    "        if node not in _network.stops:\n",
    "            print(\"-- MISSING GRAPH NODE IN LIST: \", node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: WORKING IN PROGRESS\n",
    "def simplicity_metric(network):\n",
    "    routes = network.routes\n",
    "    \n",
    "    for route in routes:\n",
    "        for i in range(len(route) - 1):\n",
    "            u, v = route[i], route[i + 1]\n",
    "            \n",
    "            if CITY_GRAPH.has_edge(u, v):\n",
    "                edge_data = CITY_GRAPH.get_edge_data(u, v)\n",
    "            else:\n",
    "                # Skip if there's no direct edge between u and v\n",
    "                continue\n",
    "            \n",
    "            # Edge data might have multiple edges with different keys\n",
    "            for key in edge_data:\n",
    "                road_name = edge_data[key].get('name', 'Unnamed Road')\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST PER CITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset of Manila Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ManilaSubset_pikl_filepath = \"Saved Networks/Manila Subset/\"\n",
    "ManilaSubset_map_filepath = \"Saved Maps/Manila Subset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING INITIAL NETWORK\n",
    "\n",
    "manila_amenities_network = create_network(manila_amenities_polygon_gdf, manila_amenities_point_gdf)\n",
    "\n",
    "# Make a before map\n",
    "before_map = plot_network_on_map(manila_amenities_network, initial_location=[0, 0], zoom_start=100)\n",
    "before_map.save(f'{ManilaSubset_map_filepath}before_map.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LEVEL 1 - CONNECTING POLYGONS OF SAME AMENITY\n",
    "\n",
    "combined_graph = combine_amenities_by_polygon(manila_amenities_network, max_distance=100, max_perimeter=10000)\n",
    "after_map = plot_network_on_map(combined_graph, initial_location=[0, 0], zoom_start=100)\n",
    "after_map.save(f'{ManilaSubset_map_filepath}after_map.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKING POPULATION DENSITY OF RESIDENTIAL AREAS\n",
    "pop_graph = check_residential_population_density(combined_graph, 100, manila_population_gdf)\n",
    "pop_map = plot_population_zones_map(pop_graph, initial_location=[0, 0], zoom_start=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 2 - CREATING NETWORKS OF AMENITIES\n",
    "\n",
    "graph_networks_of_polygons = create_zone_network(graph=combined_graph, max_distance=100)\n",
    "networks_map = plot_connected_zones_network_on_map(graph_networks_of_polygons, initial_location=[0, 0], zoom_start=100)\n",
    "networks_map.save(f'{ManilaSubset_map_filepath}networks_map.html') # Save the map to an HTML file\n",
    "\n",
    "feature_collection = graph_to_geojson(manila_amenities_network, 'output.geojson')\n",
    "with open('output.geojson', 'w', encoding='utf-8') as f:\n",
    "    f.write(geojson.dumps(feature_collection, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placing Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 3 - CREATING STOPS TO BE PLACED ON ZONES\n",
    "graph_of_stops = nx.Graph()\n",
    "add_points_to_graph(manila_amenities_network, graph_networks_of_polygons) # Add first all transportation stops\n",
    "list_of_stops = []\n",
    "place_stops_on_roads(graph_networks_of_polygons, graph_of_stops, list_of_stops) # Adds stops graph_of_stops\n",
    "\n",
    "# Visualize the stops\n",
    "stops_map = plot_stops_on_map(networks_map, list_of_stops, initial_location=[0, 0], zoom_start=100)\n",
    "stops_map.save(f'{ManilaSubset_map_filepath}stops_map.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export stops to pickle\n",
    "\n",
    "# Specify the file path where you want to save the pickle file\n",
    "file_path = f'{ManilaSubset_pikl_filepath}stop_objects.pkl'\n",
    "\n",
    "# Open the file in binary write mode\n",
    "with open(file_path, 'wb') as f:\n",
    "    # Dump the list of stop objects into the pickle file\n",
    "    pickle.dump(list_of_stops, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LEVEL 4 - CONNECTING STOPS INTO A NETWORK\n",
    "WALKING_DISTANCES = [300,550,800]\n",
    "MAX_DISTANCE = 10\n",
    "CONNECTION_TYPES = [\"Default\", \"Area\", \"Degree\"]\n",
    "\n",
    "# Configuration\n",
    "set_walk_distance = WALKING_DISTANCES[0]\n",
    "num_of_networks = 10\n",
    "conn_type = CONNECTION_TYPES[0]\n",
    "max_stops = 20\n",
    "max_routes = 10\n",
    "map_html_location = \"Generated Route Networks HTML/Manila Subset/\"\n",
    "        \n",
    "# Generate route network\n",
    "list_of_networks = []\n",
    "\n",
    "for _ in range(num_of_networks):\n",
    "    route_count = 0 # Route is the connection between list of stops\n",
    "    connection_count = 0 # Connection is the connection between two stops / nodes\n",
    "    route_network, route_graph = generate_route_network(list_of_stops, set_walk_distance, max_stops, max_routes, graph_of_stops, conn_type) # Default max walking distance is 300m\n",
    "    used_stops = add_stops_to_list(route_network)\n",
    "    new_network = networkObj(route_network, used_stops, route_graph, conn_type)\n",
    "    \n",
    "    # ERROR CHECKS----------\n",
    "    #print(\"Performing error checks...\")\n",
    "    #check_graph_with_route(new_network)\n",
    "    #check_graph_with_stops(new_network)\n",
    "    #check_order_route(new_network.routes)\n",
    "    \n",
    "    print()\n",
    "    # Append to list of networks\n",
    "    list_of_networks.append(new_network)\n",
    "\n",
    "\n",
    "#Export networks and graphs using pickl\n",
    "export_networks(list_of_networks, f\"{ManilaSubset_pikl_filepath}ManilaSubset_Route_networks.pkl\")\n",
    "\n",
    "\n",
    "i = 1\n",
    "# Creating Maps for visualization\n",
    "for route_network in list_of_networks:\n",
    "    map_center = (14.599512, 120.984222)\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "\n",
    "    # Plotting in the Map\n",
    "    add_markers(route_network.stops, route_network.graph)\n",
    "        \n",
    "    for route in route_network.routes:\n",
    "        for connection in route:\n",
    "            ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "    m.save(f\"{map_html_location}Route Map-{i}.html\")\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import networks into list_of_networks\n",
    "# import pickl\n",
    "list_of_networks = import_networks(f\"{ManilaSubset_pikl_filepath}ManilaSubset_Route_networks.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING GA ---------------------------------------------------------]\n",
    "# There should a pickle file already of the latest networks\n",
    "\n",
    "population_size = 10 # Default\n",
    "num_elites = 2\n",
    "num_generations = 5\n",
    "mutation_probability = 0.1\n",
    "num_mutations_probabilities = [0.1, 0.2, 0.3, 0.2, 0.2]\n",
    "num_crossovers_probabilities = [0.1, 0.2, 0.3, 0.2, 0.2]\n",
    "mutation_threshold_dist = 300\n",
    "with_elitism = False\n",
    "with_growing_population = False\n",
    "num_mutations_per_generation = 2\n",
    "\n",
    "#Weights and Fitness Function configuration\n",
    "num_failure_removal = 4\n",
    "weight_random_failure = 0.15\n",
    "weight_targeted_failure = 0.15\n",
    "weight_connectivity = 0.7\n",
    "\n",
    "population = perform_genetic_algorithm(list_of_networks, graph_of_stops, population_size, num_elites, num_generations, mutation_probability, \n",
    "                              num_mutations_probabilities, num_crossovers_probabilities, mutation_threshold_dist, num_failure_removal,\n",
    "                                      weight_random_failure, weight_targeted_failure, weight_connectivity,\n",
    "                              with_elitism, with_growing_population, num_mutations_per_generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Genetic Algorithm Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "map_html_location = \"GA Result Route Networks HTML/Manila Subset/\"\n",
    "\n",
    "i = 1\n",
    "for network in population:\n",
    "    map_center = (14.599512, 120.984222)\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "    add_markers(network.stops, network.graph)\n",
    "    \n",
    "    for route in network.routes:\n",
    "        for connection in route:\n",
    "            ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "    m.save(f\"{map_html_location}GA Map-{i}.html\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manila Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READING DATA (All Amenities in Manila)\n",
    "merged_amenities_points_gdf = gpd.read_file('./City Data/Manila City/Manila_point.geojson', crs='epsg:3123')\n",
    "merged_amenities_polygons_gdf= gpd.read_file('././City Data/Manila City/Manila_polygon.geojson', crs='epsg:3123')\n",
    "\n",
    "merged_amenities_polygons_gdf['amenity_points'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spatial index for points\n",
    "idx = rtree_index.Index()\n",
    "for j, point in merged_amenities_points_gdf.iterrows():\n",
    "    idx.insert(j, point['geometry'].bounds)\n",
    "\n",
    "# Iterate over polygons\n",
    "for i, polygon in merged_amenities_polygons_gdf.iterrows():\n",
    "    points_within_polygon = []\n",
    "    \n",
    "    # Iterate over points within the bounding box of the polygon\n",
    "    for j in idx.intersection(polygon['geometry'].bounds):\n",
    "        point = merged_amenities_points_gdf.loc[j]\n",
    "        if polygon['geometry'].intersects(point['geometry']):\n",
    "            points_within_polygon.append(j)\n",
    "    \n",
    "    merged_amenities_polygons_gdf.at[i, 'amenity_points'] = points_within_polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Manila_pikl_filepath = \"Saved Networks/Manila/\"\n",
    "Manila_map_filepath = \"Saved Maps/Manila/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING INITIAL NETWORK\n",
    "\n",
    "merged_amenities_network_Manila = create_network(merged_amenities_polygons_gdf, merged_amenities_points_gdf)\n",
    "\n",
    "# Make a before map\n",
    "merge_map_Manila = plot_network_on_map(merged_amenities_network_Manila, initial_location=[0, 0], zoom_start=100)\n",
    "merge_map_Manila.save(f'{Manila_map_filepath}merge_map.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 0.5 - FILTERING OUT RESIDENTIAL AREAS THAT HAVE LOW POPULATION DENSITY\n",
    "threshold = 120\n",
    "filter_residential_graph = check_residential_population_density(merged_amenities_network_Manila, threshold, manila_population_gdf)\n",
    "filtered_manila_amenities_network = filter_out_low_population_density_residentials(merged_amenities_network_Manila, filter_residential_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_is_zone = 0\n",
    "count_not_zone = 0\n",
    "\n",
    "for node, data in filter_residential_graph.nodes(data=True):\n",
    "    if data['is_a_zone']:\n",
    "        count_is_zone += 1\n",
    "    else:\n",
    "        count_not_zone += 1\n",
    "        \n",
    "print(f\"IS A ZONE: {count_is_zone}\")\n",
    "print(f\"IS NOT A ZONE: {count_not_zone}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an after map for the filtered manila amenities network (Filtered residential areas)\n",
    "after_residential_filter_map = plot_network_on_map(filtered_manila_amenities_network, initial_location=[0, 0], zoom_start=100)\n",
    "after_residential_filter_map.save(f'{Manila_map_filepath}residential_filter.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 1 - CONNECTING POLYGONS OF SAME AMENITY\n",
    "\n",
    "connected_lines = []\n",
    "combined_graph_Manila = combine_amenities_by_polygon(filtered_manila_amenities_network, max_distance=100, max_perimeter=10000)\n",
    "after_map = plot_network_on_map(combined_graph_Manila, initial_location=[0, 0], zoom_start=100)\n",
    "\n",
    "\n",
    "# The lines to show the networks\n",
    "for line in connected_lines:\n",
    "    line_coords = [[coord[1], coord[0]] for coord in line.coords]\n",
    "    folium.PolyLine(locations=line_coords, color='black').add_to(after_map)\n",
    "after_map.save(f'{Manila_map_filepath}after_map.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_graph = check_residential_population_density(combined_graph_Manila, 100, manila_population_gdf)\n",
    "pop_map = plot_population_zones_map(pop_graph, initial_location=[0, 0], zoom_start=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORTING THE LEVEL 1 GRAPH\n",
    "path = f'{Manila_pikl_filepath}Manila_Combined_Amenities_Network.pkl'\n",
    "export_networks(combined_graph_Manila, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 2 - CREATING NETWORKS OF AMENITIES\n",
    "\n",
    "graph_networks_of_polygons_Manila = create_zone_network(graph=combined_graph_Manila, max_distance=100)\n",
    "networks_map_Manila = plot_connected_zones_network_on_map(graph_networks_of_polygons_Manila, initial_location=[0, 0], zoom_start=100)\n",
    "networks_map_Manila.save(f'{Manila_map_filepath}networks_map.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORTING THE LEVEL 2 GRAPH\n",
    "path = f'{Manila_pikl_filepath}Manila_Zone_Network.pkl'\n",
    "export_networks(graph_networks_of_polygons_Manila, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data (After Zone Connection) - Run this for only importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Manila_pikl_filepath = \"Saved Networks/Manila/\"\n",
    "Manila_map_filepath = \"Saved Maps/Manila/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING INITIAL NETWORK\n",
    "merged_amenities_network_Manila = create_network(merged_amenities_polygons_gdf, merged_amenities_points_gdf)\n",
    "\n",
    "# LEVEL 0.5 - FILTERING OUT RESIDENTIAL AREAS THAT HAVE LOW POPULATION DENSITY\n",
    "threshold = 120\n",
    "filter_residential_graph = check_residential_population_density(merged_amenities_network_Manila, threshold, manila_population_gdf)\n",
    "filtered_manila_amenities_network = filter_out_low_population_density_residentials(merged_amenities_network_Manila, filter_residential_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_graph_Manila = import_networks(f\"{Manila_pikl_filepath}Manila_Combined_Amenities_Network.pkl\")\n",
    "pop_graph = check_residential_population_density(combined_graph_Manila, 100, manila_population_gdf)\n",
    "graph_networks_of_polygons_Manila = import_networks(f\"{Manila_pikl_filepath}Manila_Zone_Network.pkl\")\n",
    "\n",
    "networks_map_Manila = plot_connected_zones_network_on_map(graph_networks_of_polygons_Manila, initial_location=[0, 0], zoom_start=100)\n",
    "\n",
    "# networks_map_Manila.save(f'{Manila_map_filepath}Zone_networks_map.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 3 - CREATING STOPS TO BE PLACED ON ZONES\n",
    "graph_of_stops_Manila = nx.Graph()\n",
    "add_points_to_graph(merged_amenities_network_Manila, graph_networks_of_polygons_Manila) # Add first all transportation stops\n",
    "list_of_stops_Manila = []\n",
    "place_stops_on_roads(graph_networks_of_polygons_Manila, graph_of_stops_Manila, list_of_stops_Manila) # Adds stops graph_of_stops\n",
    "\n",
    "# Visualize the stops\n",
    "stops_map = plot_stops_on_map(networks_map_Manila, list_of_stops_Manila, initial_location=[0, 0], zoom_start=100)\n",
    "stops_map.save(f\"{Manila_map_filepath}stops_map.html\") # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export stops to pickle\n",
    "\n",
    "# Specify the file path where you want to save the pickle file\n",
    "file_path = f'{Manila_pikl_filepath}stop_list_Manila.pkl'\n",
    "\n",
    "# Open the file in binary write mode\n",
    "with open(file_path, 'wb') as f:\n",
    "    # Dump the list of stop objects into the pickle file\n",
    "    pickle.dump(list_of_stops_Manila, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_of_stops_Manila)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(graph_of_stops_Manila)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 4 - CONNECTING STOPS INTO A NETWORK\n",
    "WALKING_DISTANCES = [300,550,800]\n",
    "MAX_DISTANCE = 15\n",
    "CONNECTION_TYPES = [\"Default\", \"Area\", \"Degree\"]\n",
    "\n",
    "# Configuration\n",
    "set_walk_distance = WALKING_DISTANCES[0]\n",
    "num_of_networks = 10\n",
    "conn_type = CONNECTION_TYPES[0]\n",
    "max_stops = 20\n",
    "max_routes = 30\n",
    "map_html_location = \"Generated Route Networks HTML/Manila/\"\n",
    "        \n",
    "# Generate route network\n",
    "list_of_networks_Manila = []\n",
    "\n",
    "print(f\"CHOSEN CONNECTION TYPE: {conn_type}\")\n",
    "for _ in range(num_of_networks):\n",
    "    route_count = 0 # Route is the connection between list of stops\n",
    "    connection_count = 0 # Connection is the connection between two stops / nodes\n",
    "    route_network, route_graph = generate_route_network(list_of_stops_Manila, set_walk_distance, max_stops, max_routes, graph_of_stops_Manila, conn_type) # Default max walking distance is 300m\n",
    "    used_stops = add_stops_to_list(route_network)\n",
    "    new_network = networkObj(route_network, used_stops, route_graph, conn_type)\n",
    "    \n",
    "    # ERROR CHECKS----------\n",
    "    #print(\"Performing error checks...\")\n",
    "    #check_graph_with_route(new_network)\n",
    "    #check_graph_with_stops(new_network)\n",
    "    #check_order_route(new_network.routes)\n",
    "    \n",
    "    print()\n",
    "    # Append to list of networks\n",
    "    list_of_networks_Manila.append(new_network)\n",
    "\n",
    "\n",
    "#Export networks and graphs using pickl\n",
    "export_networks(list_of_networks_Manila, f\"{Manila_pikl_filepath}Manila_Route_networks.pkl\")\n",
    "\n",
    "\n",
    "i = 1\n",
    "# Creating Maps for visualization\n",
    "for route_network in list_of_networks_Manila:\n",
    "    map_center = (14.599512, 120.984222)\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "\n",
    "    # Plotting in the Map\n",
    "    add_markers(route_network.stops, route_network.graph)\n",
    "        \n",
    "    for route in route_network.routes:\n",
    "        for connection in route:\n",
    "            ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "    m.save(f\"{map_html_location}Route Map2-{i}.html\")\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import networks into list_of_networks\n",
    "# import pickl\n",
    "list_of_networks_Manila = import_networks(f\"{Manila_pikl_filepath}Manila_Route_networks.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING GA ---------------------------------------------------------]\n",
    "# There should a pickle file already of the latest networks\n",
    "\n",
    "population_size = 10 # Default\n",
    "num_elites = 2\n",
    "num_generations = 5\n",
    "mutation_probability = 0.1\n",
    "num_mutations_probabilities = [0.1, 0.2, 0.3, 0.2, 0.2]\n",
    "num_crossovers_probabilities = [0.1, 0.2, 0.3, 0.2, 0.2]\n",
    "mutation_threshold_dist = 300\n",
    "with_elitism = False\n",
    "with_growing_population = False\n",
    "num_mutations_per_generation = 2\n",
    "\n",
    "#Weights and Fitness Function configuration\n",
    "num_failure_removal = 4\n",
    "weight_random_failure = 0.15\n",
    "weight_targeted_failure = 0.15\n",
    "weight_connectivity = 0.7\n",
    "\n",
    "population = perform_genetic_algorithm(list_of_networks_Manila, graph_of_stops_Manila, population_size, num_elites, num_generations, mutation_probability, \n",
    "                              num_mutations_probabilities, num_crossovers_probabilities, mutation_threshold_dist, num_failure_removal,\n",
    "                                      weight_random_failure, weight_targeted_failure, weight_connectivity,\n",
    "                              with_elitism, with_growing_population, num_mutations_per_generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Genetic Algorithm Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "map_html_location = \"GA Result Route Networks HTML/Manila/\"\n",
    "\n",
    "i = 1\n",
    "for network in population:\n",
    "    map_center = (14.599512, 120.984222)\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "    add_markers(network.stops, network.graph)\n",
    "    \n",
    "    for route in network.routes:\n",
    "        for connection in route:\n",
    "            ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "    m.save(f\"{map_html_location}GA Map-{i}.html\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Makati Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READING DATA (All Amenities in Makati)\n",
    "Makati_amenities_points_gdf = gpd.read_file('./City Data/Makati City/Makati_point.geojson', crs='epsg:3123')\n",
    "Makati_amenities_polygons_gdf = gpd.read_file('././City Data/Makati City/Makati_polygon.geojson', crs='epsg:3123')\n",
    "\n",
    "Makati_amenities_polygons_gdf['amenity_points'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spatial index for points\n",
    "idx = rtree_index.Index()\n",
    "for j, point in Makati_amenities_points_gdf.iterrows():\n",
    "    idx.insert(j, point['geometry'].bounds)\n",
    "\n",
    "# Iterate over polygons\n",
    "for i, polygon in Makati_amenities_polygons_gdf.iterrows():\n",
    "    points_within_polygon = []\n",
    "    \n",
    "    # Iterate over points within the bounding box of the polygon\n",
    "    for j in idx.intersection(polygon['geometry'].bounds):\n",
    "        point = Makati_amenities_points_gdf.loc[j]\n",
    "        if polygon['geometry'].intersects(point['geometry']):\n",
    "            points_within_polygon.append(j)\n",
    "    \n",
    "    Makati_amenities_polygons_gdf.at[i, 'amenity_points'] = points_within_polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Makati_pikl_filepath = \"Saved Networks/Makati/\"\n",
    "Makati_map_filepath = \"Saved Maps/Makati/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING INITIAL NETWORK\n",
    "\n",
    "merged_amenities_network_Makati = create_network(Makati_amenities_polygons_gdf, Makati_amenities_points_gdf)\n",
    "\n",
    "# Make a before map\n",
    "merge_map_Makati = plot_network_on_map(merged_amenities_network_Makati, initial_location=[0, 0], zoom_start=100)\n",
    "merge_map_Makati.save(f'{Makati_map_filepath}merge_map.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 1 - CONNECTING POLYGONS OF SAME AMENITY\n",
    "\n",
    "connected_lines = []\n",
    "combined_graph_Makati = combine_amenities_by_polygon(merged_amenities_network_Makati, max_distance=100, max_perimeter=10000)\n",
    "after_map = plot_network_on_map(combined_graph_Makati, initial_location=[0, 0], zoom_start=100)\n",
    "\n",
    "\n",
    "# The lines to show the networks\n",
    "for line in connected_lines:\n",
    "    line_coords = [[coord[1], coord[0]] for coord in line.coords]\n",
    "    folium.PolyLine(locations=line_coords, color='black').add_to(after_map)\n",
    "after_map.save(f'{Makati_map_filepath}after_map.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_graph = check_residential_population_density(combined_graph_Makati, 100, makati_population_gdf)\n",
    "pop_map = plot_population_zones_map(pop_graph, initial_location=[0, 0], zoom_start=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORTING THE LEVEL 1 GRAPH\n",
    "path = f'{Makati_pikl_filepath}Makati_Combined_Amenities_Network.pkl'\n",
    "export_networks(combined_graph_Makati, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 2 - CREATING NETWORKS OF AMENITIES\n",
    "\n",
    "graph_networks_of_polygons_Makati= create_zone_network(graph=combined_graph_Makati, max_distance=100)\n",
    "networks_map_Makati = plot_connected_zones_network_on_map(graph_networks_of_polygons_Makati, initial_location=[0, 0], zoom_start=100)\n",
    "networks_map_Makati.save(f'{Makati_map_filepath}networks_map.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORTING THE LEVEL 2 GRAPH\n",
    "path = f'{Makati_pikl_filepath}Makati_Zone_Network.pkl'\n",
    "export_networks(graph_networks_of_polygons_Makati, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data (After Zone Connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_graph_Makati = import_networks(f\"{Makati_pikl_filepath}Makati_Combined_Amenities_Network.pkl\")\n",
    "graph_networks_of_polygons_Makati = import_networks(f\"{Makati_pikl_filepath}Makati_Zone_Network.pkl\")\n",
    "\n",
    "# networks_map_Makati = plot_connected_zones_network_on_map(graph_networks_of_polygons_Makati, initial_location=[0, 0], zoom_start=100)\n",
    "\n",
    "# networks_map_Makati.save(f'{Makati_map_filepath}Zone_networks_map.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 3 - CREATING STOPS TO BE PLACED ON ZONES\n",
    "graph_of_stops_Makati = nx.Graph()\n",
    "add_points_to_graph(merged_amenities_network_Makati, graph_networks_of_polygons_Makati) # Add first all transportation stops\n",
    "list_of_stops_Makati = []\n",
    "place_stops_on_roads(graph_networks_of_polygons_Makati, graph_of_stops_Makati, list_of_stops_Makati) # Adds stops graph_of_stops\n",
    "\n",
    "# Visualize the stops\n",
    "stops_map = plot_stops_on_map(networks_map_Makati, list_of_stops_Makati, initial_location=[0, 0], zoom_start=100)\n",
    "stops_map.save(f\"{Makati_map_filepath}stops_map.html\") # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export stops to pickle\n",
    "\n",
    "# Specify the file path where you want to save the pickle file\n",
    "file_path = f'{Makati_pikl_filepath}stop_list_Makati.pkl'\n",
    "\n",
    "# Open the file in binary write mode\n",
    "with open(file_path, 'wb') as f:\n",
    "    # Dump the list of stop objects into the pickle file\n",
    "    pickle.dump(list_of_stops_Makati, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 4 - CONNECTING STOPS INTO A NETWORK\n",
    "WALKING_DISTANCES = [300,550,800]\n",
    "MAX_DISTANCE = 15\n",
    "CONNECTION_TYPES = [\"Default\", \"Area\", \"Degree\"]\n",
    "\n",
    "# Configuration\n",
    "set_walk_distance = WALKING_DISTANCES[0]\n",
    "num_of_networks = 10\n",
    "conn_type = CONNECTION_TYPES[0]\n",
    "max_stops = 20 # Per route\n",
    "max_routes = 10 # Per network\n",
    "map_html_location = \"Generated Route Networks HTML/Makati/\"\n",
    "        \n",
    "# Generate route network\n",
    "list_of_networks_Makati = []\n",
    "\n",
    "for _ in range(num_of_networks):\n",
    "    route_count = 0 # Route is the connection between list of stops\n",
    "    connection_count = 0 # Connection is the connection between two stops / nodes\n",
    "    route_network, route_graph = generate_route_network(list_of_stops_Makati, set_walk_distance, max_stops, max_routes, graph_of_stops_Makati, conn_type) # Default max walking distance is 300m\n",
    "    used_stops = add_stops_to_list(route_network)\n",
    "    new_network = networkObj(route_network, used_stops, route_graph, conn_type)\n",
    "    \n",
    "    # ERROR CHECKS----------\n",
    "    #print(\"Performing error checks...\")\n",
    "    #check_graph_with_route(new_network)\n",
    "    #check_graph_with_stops(new_network)\n",
    "    #check_order_route(new_network.routes)\n",
    "    \n",
    "    print()\n",
    "    # Append to list of networks\n",
    "    list_of_networks_Makati.append(new_network)\n",
    "\n",
    "\n",
    "#Export networks and graphs using pickl\n",
    "export_networks(list_of_networks_Makati, f\"{Makati_pikl_filepath}Makati_Route_networks.pkl\")\n",
    "\n",
    "\n",
    "i = 1\n",
    "# Creating Maps for visualization\n",
    "for route_network in list_of_networks_Makati:\n",
    "    map_center = (14.599512, 120.984222)\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "\n",
    "    # Plotting in the Map\n",
    "    add_markers(route_network.stops, route_network.graph)\n",
    "        \n",
    "    for route in route_network.routes:\n",
    "        for connection in route:\n",
    "            ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "    m.save(f\"{map_html_location}Route Map-{i}.html\")\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import networks into list_of_networks\n",
    "# import pickl\n",
    "list_of_networks_Makati = import_networks(f\"{Makati_pikl_filepath}Makati_Route_networks.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING GA ---------------------------------------------------------]\n",
    "# There should a pickle file already of the latest networks\n",
    "\n",
    "population_size = 10 # Default\n",
    "num_elites = 2\n",
    "num_generations = 5\n",
    "mutation_probability = 0.1\n",
    "num_mutations_probabilities = [0.1, 0.2, 0.3, 0.2, 0.2]\n",
    "num_crossovers_probabilities = [0.1, 0.2, 0.3, 0.2, 0.2]\n",
    "mutation_threshold_dist = 300\n",
    "with_elitism = False\n",
    "with_growing_population = False\n",
    "num_mutations_per_generation = 2\n",
    "\n",
    "#Weights and Fitness Function configuration\n",
    "num_failure_removal = 4\n",
    "weight_random_failure = 0.15\n",
    "weight_targeted_failure = 0.15\n",
    "weight_connectivity = 0.7\n",
    "\n",
    "population = perform_genetic_algorithm(list_of_networks_Makati, graph_of_stops_Makati, population_size, num_elites, num_generations, mutation_probability, \n",
    "                              num_mutations_probabilities, num_crossovers_probabilities, mutation_threshold_dist, num_failure_removal,\n",
    "                                      weight_random_failure, weight_targeted_failure, weight_connectivity,\n",
    "                              with_elitism, with_growing_population, num_mutations_per_generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Genetic Algorithm Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "map_html_location = \"GA Result Route Networks HTML/Makati/\"\n",
    "\n",
    "i = 1\n",
    "for network in population:\n",
    "    map_center = (14.599512, 120.984222)\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "    add_markers(network.stops, network.graph)\n",
    "    \n",
    "    for route in network.routes:\n",
    "        for connection in route:\n",
    "            ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "    m.save(f\"{map_html_location}GA Map-{i}.html\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mandaluyong Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READING DATA (All Amenities in Mandaluyong)\n",
    "Mandaluyong_amenities_points_gdf = gpd.read_file('./City Data/Mandaluyong City/Mandaluyong_point.geojson', crs='epsg:3123')\n",
    "Mandaluyong_amenities_polygons_gdf = gpd.read_file('././City Data/Mandaluyong City/Mandaluyong_polygon.geojson', crs='epsg:3123')\n",
    "\n",
    "Mandaluyong_amenities_polygons_gdf['amenity_points'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spatial index for points\n",
    "idx = rtree_index.Index()\n",
    "for j, point in Mandaluyong_amenities_points_gdf.iterrows():\n",
    "    idx.insert(j, point['geometry'].bounds)\n",
    "\n",
    "# Iterate over polygons\n",
    "for i, polygon in Mandaluyong_amenities_polygons_gdf.iterrows():\n",
    "    points_within_polygon = []\n",
    "    \n",
    "    # Iterate over points within the bounding box of the polygon\n",
    "    for j in idx.intersection(polygon['geometry'].bounds):\n",
    "        point = Mandaluyong_amenities_points_gdf.loc[j]\n",
    "        if polygon['geometry'].intersects(point['geometry']):\n",
    "            points_within_polygon.append(j)\n",
    "    \n",
    "    Mandaluyong_amenities_polygons_gdf.at[i, 'amenity_points'] = points_within_polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mandaluyong_pikl_filepath = \"Saved Networks/Mandaluyong/\"\n",
    "Mandaluyong_map_filepath = \"Saved Maps/Mandaluyong/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING INITIAL NETWORK\n",
    "\n",
    "merged_amenities_network_Mandaluyong = create_network(Mandaluyong_amenities_polygons_gdf, Mandaluyong_amenities_points_gdf)\n",
    "\n",
    "# Make a before map\n",
    "merge_map_Mandaluyong = plot_network_on_map(merged_amenities_network_Mandaluyong, initial_location=[0, 0], zoom_start=100)\n",
    "merge_map_Mandaluyong.save(f'{Mandaluyong_map_filepath}merge_map.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 1 - CONNECTING POLYGONS OF SAME AMENITY\n",
    "\n",
    "connected_lines = []\n",
    "combined_graph_Mandaluyong = combine_amenities_by_polygon(merged_amenities_network_Mandaluyong, max_distance=100, max_perimeter=10000)\n",
    "after_map = plot_network_on_map(combined_graph_Mandaluyong, initial_location=[0, 0], zoom_start=100)\n",
    "\n",
    "\n",
    "# The lines to show the networks\n",
    "for line in connected_lines:\n",
    "    line_coords = [[coord[1], coord[0]] for coord in line.coords]\n",
    "    folium.PolyLine(locations=line_coords, color='black').add_to(after_map)\n",
    "after_map.save(f'{Mandaluyong_map_filepath}after_map.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_graph = check_residential_population_density(combined_graph_Mandaluyong, 100, mandaluyong_population_gdf)\n",
    "pop_map = plot_population_zones_map(pop_graph, initial_location=[0, 0], zoom_start=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORTING THE LEVEL 1 GRAPH\n",
    "path = f'{Mandaluyong_pikl_filepath}Mandaluyong_Combined_Amenities_Network.pkl'\n",
    "export_networks(combined_graph_Mandaluyong, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 2 - CREATING NETWORKS OF AMENITIES\n",
    "\n",
    "graph_networks_of_polygons_Mandaluyong= create_zone_network(graph=combined_graph_Mandaluyong, max_distance=100)\n",
    "networks_map_Mandaluyong = plot_connected_zones_network_on_map(graph_networks_of_polygons_Mandaluyong, initial_location=[0, 0], zoom_start=100)\n",
    "networks_map_Mandaluyong.save(f'{Mandaluyong_map_filepath}networks_map.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORTING THE LEVEL 2 GRAPH\n",
    "path = f'{Mandaluyong_pikl_filepath}Mandaluyong_Zone_Network.pkl'\n",
    "export_networks(graph_networks_of_polygons_Mandaluyong, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 3 - CREATING STOPS TO BE PLACED ON ZONES\n",
    "graph_of_stops_Mandaluyong = nx.Graph()\n",
    "add_points_to_graph(merged_amenities_network_Mandaluyong, graph_networks_of_polygons_Mandaluyong) # Add first all transportation stops\n",
    "list_of_stops_Mandaluyong = []\n",
    "place_stops_on_roads(graph_networks_of_polygons_Mandaluyong, graph_of_stops_Mandaluyong, list_of_stops_Mandaluyong) # Adds stops graph_of_stops\n",
    "\n",
    "# Visualize the stops\n",
    "stops_map = plot_stops_on_map(networks_map_Mandaluyong, list_of_stops_Mandaluyong, initial_location=[0, 0], zoom_start=100)\n",
    "stops_map.save(f\"{Mandaluyong_map_filepath}stops_map.html\") # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export stops to pickle\n",
    "\n",
    "# Specify the file path where you want to save the pickle file\n",
    "file_path = f'{Mandaluyong_pikl_filepath}stop_list_Mandaluyong.pkl'\n",
    "\n",
    "# Open the file in binary write mode\n",
    "with open(file_path, 'wb') as f:\n",
    "    # Dump the list of stop objects into the pickle file\n",
    "    pickle.dump(list_of_stops_Mandaluyong, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 4 - CONNECTING STOPS INTO A NETWORK\n",
    "WALKING_DISTANCES = [300,550,800]\n",
    "MAX_DISTANCE = 15\n",
    "CONNECTION_TYPES = [\"Default\", \"Area\", \"Degree\"]\n",
    "\n",
    "# Configuration\n",
    "set_walk_distance = WALKING_DISTANCES[0]\n",
    "num_of_networks = 10\n",
    "conn_type = CONNECTION_TYPES[0]\n",
    "max_stops = 20\n",
    "max_routes = 10\n",
    "map_html_location = \"Generated Route Networks HTML/Mandaluyong/\"\n",
    "        \n",
    "# Generate route network\n",
    "list_of_networks_Mandaluyong = []\n",
    "\n",
    "for _ in range(num_of_networks):\n",
    "    route_count = 0 # Route is the connection between list of stops\n",
    "    connection_count = 0 # Connection is the connection between two stops / nodes\n",
    "    route_network, route_graph = generate_route_network(list_of_stops_Mandaluyong, set_walk_distance, max_stops, max_routes, graph_of_stops_Mandaluyong, conn_type) # Default max walking distance is 300m\n",
    "    used_stops = add_stops_to_list(route_network)\n",
    "    new_network = networkObj(route_network, used_stops, route_graph, conn_type)\n",
    "    \n",
    "    # ERROR CHECKS----------\n",
    "    #print(\"Performing error checks...\")\n",
    "    #check_graph_with_route(new_network)\n",
    "    #check_graph_with_stops(new_network)\n",
    "    #check_order_route(new_network.routes)\n",
    "    \n",
    "    print()\n",
    "    # Append to list of networks\n",
    "    list_of_networks_Mandaluyong.append(new_network)\n",
    "\n",
    "\n",
    "#Export networks and graphs using pickl\n",
    "export_networks(list_of_networks_Mandaluyong, f\"{Mandaluyong_pikl_filepath}Mandaluyong_Route_networks.pkl\")\n",
    "\n",
    "\n",
    "i = 1\n",
    "# Creating Maps for visualization\n",
    "for route_network in list_of_networks_Mandaluyong:\n",
    "    map_center = (14.599512, 120.984222)\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "\n",
    "    # Plotting in the Map\n",
    "    add_markers(route_network.stops, route_network.graph)\n",
    "        \n",
    "    for route in route_network.routes:\n",
    "        for connection in route:\n",
    "            ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "    m.save(f\"{map_html_location}Route Map-{i}.html\")\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import networks into list_of_networks\n",
    "# import pickl\n",
    "list_of_networks_Mandaluyong = import_networks(f\"{Mandaluyong_pikl_filepath}Mandaluyong_Route_networks.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING GA ---------------------------------------------------------]\n",
    "# There should a pickle file already of the latest networks\n",
    "\n",
    "population_size = 10 # Default\n",
    "num_elites = 2\n",
    "num_generations = 5\n",
    "mutation_probability = 0.1\n",
    "num_mutations_probabilities = [0.1, 0.2, 0.3, 0.2, 0.2]\n",
    "num_crossovers_probabilities = [0.1, 0.2, 0.3, 0.2, 0.2]\n",
    "mutation_threshold_dist = 300\n",
    "with_elitism = False\n",
    "with_growing_population = False\n",
    "num_mutations_per_generation = 2\n",
    "\n",
    "#Weights and Fitness Function configuration\n",
    "num_failure_removal = 4\n",
    "weight_random_failure = 0.15\n",
    "weight_targeted_failure = 0.15\n",
    "weight_connectivity = 0.7\n",
    "\n",
    "population = perform_genetic_algorithm(list_of_networks_Mandaluyong, graph_of_stops_Mandaluyong, population_size, num_elites, num_generations, mutation_probability, \n",
    "                              num_mutations_probabilities, num_crossovers_probabilities, mutation_threshold_dist, num_failure_removal,\n",
    "                                      weight_random_failure, weight_targeted_failure, weight_connectivity,\n",
    "                              with_elitism, with_growing_population, num_mutations_per_generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Genetic Algorithm Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "map_html_location = \"GA Result Route Networks HTML/Mandaluyong/\"\n",
    "\n",
    "i = 1\n",
    "for network in population:\n",
    "    map_center = (14.599512, 120.984222)\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "    add_markers(network.stops, network.graph)\n",
    "    \n",
    "    for route in network.routes:\n",
    "        for connection in route:\n",
    "            ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "    m.save(f\"{map_html_location}GA Map-{i}.html\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MISC (VISUALIZATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR VISUALIZATION ONLY\n",
    "all_roads_map = plot_all_roads()\n",
    "all_roads_map.save('all_roads.html')\n",
    "\n",
    "filtered_road_map = plot_all_filtered_roads()\n",
    "filtered_road_map.save('filtered_road_map.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_amenities_points_gdf['amenity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_center = (14.599512, 120.984222) # TEMPORARY WILL ZOOM TO MANILA\n",
    "m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "\n",
    "for j, point in merged_amenities_points_gdf.iterrows():\n",
    "    if point['amenity'] == 'grocery':\n",
    "        folium.Marker(location=[point['y'], point['x']], popup=f\"{point['name']}\").add_to(m)\n",
    "        \n",
    "m.save('test.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_amenity_test(amenities_network, amenity, initial_location=[0, 0], zoom_start=10):\n",
    "    # Create a map centered at the initial location\n",
    "    map_center = (14.599512, 120.984222) # TEMPORARY WILL ZOOM TO MANILA\n",
    "    m = folium.Map(location=map_center, zoom_start=zoom_start, tiles='openstreetmap')\n",
    "    \n",
    "    #Colours for Visualization\n",
    "    amenity_colors = {\n",
    "        'education': 'green',\n",
    "        'finance': 'blue',\n",
    "        'government offices': 'red',\n",
    "        'grocery': 'orange',\n",
    "        'health': 'magenta',\n",
    "        'malls': 'yellow',\n",
    "        'residential areas': 'brown',\n",
    "        'security': 'gray',\n",
    "        'transportation': 'lightblue',\n",
    "        'others': 'black'\n",
    "    }\n",
    "\n",
    "    # Iterate over the nodes in the network\n",
    "    for node, data in amenities_network.nodes(data=True):\n",
    "        if data['amenity'] == amenity:\n",
    "            # Check if the node has a geometry attribute\n",
    "            if 'geometry' in data:\n",
    "                # Get the geometry of the node\n",
    "                geometry = data['geometry']\n",
    "\n",
    "                # Check the geometry type and plot accordingly\n",
    "                if geometry.geom_type == 'Point':\n",
    "                    # Plot a marker for points    \n",
    "                    #folium.Marker(location=[geometry.y, geometry.x], popup=f\"{data['name']}\").add_to(m)\n",
    "                    continue\n",
    "                elif geometry.geom_type in ['Polygon', 'MultiPolygon']:\n",
    "                    # Plot polygons or multipolygons\n",
    "                    color = amenity_colors[data.get('amenity')]\n",
    "                    if geometry.geom_type == 'Polygon':\n",
    "                        polygons = [geometry]\n",
    "                    else:\n",
    "                        polygons = geometry.geoms\n",
    "\n",
    "                    for polygon in polygons:\n",
    "                        coordinates = []\n",
    "                        for point in polygon.exterior.coords:\n",
    "                            coordinates.append([point[1], point[0]])\n",
    "                        folium.Polygon(locations=coordinates, fill=True, color=color, fill_opacity=0.4).add_to(m)\n",
    "\n",
    "    # Return the map\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longest route, shortest route, average route length, network diamater"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness Function Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Weights and Fitness Function configuration\n",
    "num_failure_removal = 4\n",
    "weight_random_failure = 0.15\n",
    "weight_targeted_failure = 0.15\n",
    "weight_connectivity = 0.7\n",
    "\n",
    "i = 0\n",
    "for network in list_of_networks_Manila:\n",
    "    print(f\"NETWORK {i}\")\n",
    "    road_snapped_network_graph = network.graph\n",
    "    score = compute_fitness_score(road_snapped_network_graph, num_failure_removal, weight_random_failure, weight_targeted_failure, weight_connectivity)\n",
    "    print(f\"Network {i} score: {score}\")\n",
    "    print()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_degrees = dict(list_of_networks_Makati[0].graph.degree())\n",
    "for node, degree in node_degrees.items():\n",
    "    print(f\"Node {node} has degree {degree}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for network in list_of_networks_Makati:\n",
    "    for node, data in network.graph.nodes(data=True):\n",
    "        if data[\"isTranspo\"] == True:\n",
    "            print(\"TRANSPO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for node, data in list_of_networks_Makati[0].graph.nodes(data=True):\n",
    "    if data[\"isTranspo\"] == True:\n",
    "        print(\"TRANSPO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node, data in graph_of_stops_Makati.nodes(data=True):\n",
    "        if data[\"isTranspo\"] == True:\n",
    "            print(\"TRANSPO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node_key, node_data in graph_networks_of_polygons_Makati.nodes(data=True):\n",
    "    if node_data[\"amenity\"] == \"transportation\":\n",
    "            print(\"TRANSPO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node_key, node_data in merged_amenities_network_Makati.nodes(data=True):\n",
    "    if node_data[\"amenity\"] == \"transportation\":\n",
    "            print(\"TRANSPO\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
