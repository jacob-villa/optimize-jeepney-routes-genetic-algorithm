{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing the Connectivity, Robustness, and Vulnerability of Jeepney Route Networks Using Genetic Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import shapely\n",
    "import folium\n",
    "import geojson\n",
    "import math\n",
    "import osmnx as ox\n",
    "from rtree import index as rtree_index\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "from shapely.ops import unary_union\n",
    "from shapely.geometry import Polygon, MultiPolygon, LineString, Point\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "from __future__ import absolute_import, division\n",
    "from math import radians, sin, cos, sqrt, atan2, exp, log\n",
    "import webbrowser\n",
    "import random\n",
    "from scipy.spatial import KDTree\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "ox.settings.log_console=True\n",
    "ox.settings.use_cache=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining classes for the dataframes\n",
    "class AmenityPoint:\n",
    "    def __init__(self, geometry, lat, lon, amenity, name, addr_city):\n",
    "        self.geometry = geometry\n",
    "        self.lat = lat\n",
    "        self.lon = lon\n",
    "        self.amenity = amenity\n",
    "        self.name = name\n",
    "        self.addr_city = addr_city\n",
    "\n",
    "class AmenityPolygon:\n",
    "    def __init__(self, geometry, lat, lon, amenity, name, addr_city):\n",
    "        self.geometry = geometry\n",
    "        self.lat = lat\n",
    "        self.lon = lon\n",
    "        self.amenity = amenity\n",
    "        self.name = name\n",
    "        self.addr_city = addr_city\n",
    "        \n",
    "class stopCandidate:\n",
    "    def __init__(self, lat, long, isTranspo, id, area):\n",
    "        self.lat = lat\n",
    "        self.long = long\n",
    "        self.isTranspo = isTranspo\n",
    "        self.enabled = False\n",
    "        self.id = id #node ID\n",
    "        self.area = area\n",
    "        self.degree = 0\n",
    "        \n",
    "    def enable(self):\n",
    "        self.enabled = True\n",
    "        \n",
    "    def disable(self):\n",
    "        self.enabled = False\n",
    "        \n",
    "    def getLat(self):\n",
    "        return self.lat\n",
    "    \n",
    "    def getLong(self):\n",
    "        return self.long\n",
    "    \n",
    "    def getArea(self):\n",
    "        return self.area\n",
    "    \n",
    "    def getDegree(self):\n",
    "        return self.degree\n",
    "    \n",
    "class networkObj():\n",
    "    def __init__(self, routes, stops, graph):\n",
    "        self.routes = routes\n",
    "        self.stops = stops\n",
    "        self.fitness_score = 0\n",
    "        self.graph = graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For units\n",
    "def degrees_to_meters(angle_degrees):\n",
    "    return angle_degrees * 6371000 * math.pi / 180\n",
    "\n",
    "def meters_to_degrees(distance_meters):\n",
    "    return distance_meters / 6371000 * 180 / math.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and Export networks or graphs to pickle\n",
    "def export_networks(networks, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(networks, f)\n",
    "\n",
    "def import_networks(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        routes = pickle.load(f)\n",
    "    return routes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph loaded successfully\n",
      "NUMBER OF EDGES:  2374\n",
      "NUMBER OF NODES:  989\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NOTE: SELECT THE CITY HERE, COMMENT OUT THE REMAINING CITIES\n",
    "# select_city = \"Manila, Philippines\"\n",
    "# city_file = 'map/Manila.graphml'\n",
    "\n",
    "# select_city = \"Makati, Philippines\"\n",
    "# city_file = 'map/Makati.graphml'\n",
    "\n",
    "select_city = \"Mandaluyong, Philippines\"\n",
    "city_file = 'map/Mandaluyong.graphml'\n",
    "\n",
    "\n",
    "# GENERATION OF MAIN CITY GRAPH\n",
    "# IF FIRST TIME RUNNING, RUN THIS CODE TO GENERATE THE GRAPH\n",
    "def generate_graph():\n",
    "    mode = 'drive'\n",
    "    graph = ox.graph_from_place(select_city, network_type = mode) # Generate graph of Metro manila\n",
    "    ox.save_graphml(graph, city_file) # Save it as a file\n",
    "\n",
    "def load_graph():\n",
    "    graph = ox.load_graphml(city_file)\n",
    "    \n",
    "    print(\"Graph loaded successfully\")\n",
    "    print(\"NUMBER OF EDGES: \", graph.number_of_edges())\n",
    "    print(\"NUMBER OF NODES: \", graph.number_of_nodes())\n",
    "    print('\\n')\n",
    "    return graph\n",
    "\n",
    "# NOTE: Only run this if you do not have the graph\n",
    "generate_graph()\n",
    "\n",
    "# THIS IS THE MAIN GRAPH FOR THE CITY TO BE USED FOR ALL FUNCTIONS\n",
    "CITY_GRAPH = load_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For Filtering the roads and other features\n",
    "# GETTING ROADS AND WATERWAYS\n",
    "\n",
    "# Get all the roads in Manila\n",
    "road = ox.graph_to_gdfs(CITY_GRAPH,nodes=False, edges=True)\n",
    "\n",
    "\n",
    "# Get all the roads that are not junctions (ex. Roundabouts, intersection, etc.)\n",
    "filtered_roads = road[road['junction'].isna()]\n",
    "\n",
    "# Separate roads whose widths are only one value and those that are more than 1 (lists)\n",
    "rows_with_lists = filtered_roads[filtered_roads['highway'].apply(lambda x: isinstance(x, list))]\n",
    "rows_with_strings = filtered_roads[filtered_roads['highway'].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "filter_options = ['primary', 'secondary', 'tertiary', 'trunk', 'unclassified']\n",
    "separation_options = ['primary', 'secondary', 'tertiary', 'unclassified']\n",
    "\n",
    "# Get the roads whose widths are above the threshold\n",
    "def check_list(lst):\n",
    "    return any(x in filter_options for x in lst)\n",
    "\n",
    "# Download OpenStreetMap data for the area of interest\n",
    "waterways = ox.features_from_place(select_city, tags={'waterway': True})\n",
    "filtered_rivers = waterways[waterways['waterway'].isin(['river'])]\n",
    "filtered_streams = waterways[waterways['waterway'].isin(['stream'])]\n",
    "\n",
    "# Get all the roads with the allowed road types\n",
    "filtered_roads_strings = rows_with_strings.loc[rows_with_strings['highway'].isin(filter_options)] \n",
    "filtered_roads_lists = rows_with_lists[rows_with_lists['highway'].apply(check_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will find which road or river intersects between amenities\n",
    "# Create spatial index\n",
    "filtered_roads_strings_sindex = filtered_roads_strings.sindex\n",
    "filtered_roads_lists_sindex = filtered_roads_lists.sindex\n",
    "filtered_rivers_sindex = filtered_rivers.sindex\n",
    "filtered_streams_sindex = filtered_streams.sindex\n",
    "\n",
    "def find_intersecting_features(line):\n",
    "    # Check intersection with filtered roads\n",
    "    possible_matches_roads = filtered_roads_strings.iloc[list(filtered_roads_strings_sindex.intersection(line.bounds))]\n",
    "    for index, row in possible_matches_roads.iterrows():\n",
    "        if line.intersects(row['geometry']) and row['highway'] in separation_options:\n",
    "            return True\n",
    "\n",
    "    possible_matches_lists = filtered_roads_lists.iloc[list(filtered_roads_lists_sindex.intersection(line.bounds))]\n",
    "    for index, row in possible_matches_lists.iterrows():\n",
    "        if line.intersects(row['geometry']):\n",
    "            list_highway = row['highway']\n",
    "            if any(x in separation_options for x in list_highway):\n",
    "                return True\n",
    "    \n",
    "    # Check intersection with filtered rivers\n",
    "    possible_matches_rivers = filtered_rivers.iloc[list(filtered_rivers_sindex.intersection(line.bounds))]\n",
    "    for index, row in possible_matches_rivers.iterrows():\n",
    "        if line.intersects(row['geometry']):\n",
    "            return True\n",
    "\n",
    "    # Check intersection with filtered streams\n",
    "    possible_matches_streams = filtered_streams.iloc[list(filtered_streams_sindex.intersection(line.bounds))]\n",
    "    for index, row in possible_matches_streams.iterrows():\n",
    "        if line.intersects(row['geometry']):\n",
    "            return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the building footprints data\n",
    "\n",
    "#buildingfootprints_gdf = gpd.read_file('manila_building_footprints.geojson')\n",
    "\n",
    "#buildingfootprints_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD DATA (FOR FAST TESTING)\n",
    "# Load the Manila amenities data into a Geopandas dataframe\n",
    "from shapely import wkt\n",
    "\n",
    "manila_amenities_df = pd.read_csv('manila_amenities.csv')\n",
    "manila_amenities_df['geometry'] = manila_amenities_df['geometry'].apply(wkt.loads)\n",
    "manila_amenities_gdf = gpd.GeoDataFrame(manila_amenities_df, crs='epsg:3123')\n",
    "\n",
    "# Separate into point and polygon dataframes\n",
    "manila_amenities_polygon_gdf = manila_amenities_gdf[manila_amenities_gdf['geometry'].geom_type == 'Polygon']\n",
    "manila_amenities_point_gdf = manila_amenities_gdf[manila_amenities_gdf['geometry'].geom_type == 'Point']\n",
    "manila_amenities_multipoly_gdf = manila_amenities_gdf[manila_amenities_gdf['geometry'].geom_type == 'MultiPolygon']\n",
    "\n",
    "# Append multipolygons to the polygon dataframe\n",
    "manila_amenities_polygon_gdf = gpd.GeoDataFrame(pd.concat([manila_amenities_polygon_gdf, manila_amenities_multipoly_gdf], ignore_index=True))\n",
    "\n",
    "# Reset point dataframe index\n",
    "manila_amenities_point_gdf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Add a column to the polygon dataframe to store a list of Amenity Points within the polygon\n",
    "manila_amenities_polygon_gdf['amenity_points'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For each polygon in the polygon dataframe, find all the points from the point dataframe lying inside that polygon\n",
    "# Store the list of points in the 'amenity_points' column of the polygon dataframe as a list of point indices\n",
    "\n",
    "# Create spatial index for points\n",
    "idx = rtree_index.Index()\n",
    "for j, point in manila_amenities_point_gdf.iterrows():\n",
    "    idx.insert(j, point['geometry'].bounds)\n",
    "\n",
    "# Iterate over polygons\n",
    "for i, polygon in manila_amenities_polygon_gdf.iterrows():\n",
    "    points_within_polygon = []\n",
    "    \n",
    "    # Iterate over points within the bounding box of the polygon\n",
    "    for j in idx.intersection(polygon['geometry'].bounds):\n",
    "        point = manila_amenities_point_gdf.loc[j]\n",
    "        if polygon['geometry'].intersects(point['geometry']):\n",
    "            points_within_polygon.append(j)\n",
    "    \n",
    "    manila_amenities_polygon_gdf.at[i, 'amenity_points'] = points_within_polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['education', 'finance', 'government offices', 'grocery', 'health',\n",
       "       'malls', 'residential areas', 'security'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manila_amenities_polygon_gdf['amenity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['education', 'finance', 'government offices', nan, 'public_market',\n",
       "       'health', 'malls', 'residential areas', 'security',\n",
       "       'transportation'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manila_amenities_point_gdf['amenity'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Population data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading population data\n",
    "manila_population_df = pd.read_csv('manila-population-polygon.csv')\n",
    "manila_population_df['geometry'] = manila_population_df['geometry'].apply(wkt.loads)\n",
    "manila_population_gdf = gpd.GeoDataFrame(manila_population_df, crs='epsg:3123')\n",
    "\n",
    "# Create a base map centered around Manila\n",
    "map_center = (14.599512, 120.984222) # TEMPORARY WILL ZOOM TO MANILA\n",
    "m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "\n",
    "# Add points to the map\n",
    "for index, row in manila_population_gdf.iterrows():\n",
    "    folium.CircleMarker(location=[row['latitude'], row['longitude']],\n",
    "                        radius=1,  # Adjust the radius as needed for population density representation\n",
    "                        color='blue',  # Change color as needed\n",
    "                        fill=True,\n",
    "                        fill_color='blue'  # Change fill color as needed\n",
    "                        ).add_to(m)\n",
    "    \n",
    "m.save('population.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial City Network Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buckle up. We're trying to create a network out of this monstrosity of a dataframe\n",
    "# Create a networkx graph\n",
    "\n",
    "def create_network(amenities_polygon_gdf, amenities_point_gdf):\n",
    "    amenities_network = nx.Graph()\n",
    "\n",
    "   # Add polygon nodes\n",
    "    for index, row in amenities_polygon_gdf.iterrows():\n",
    "        # Check if essential columns exist in the row\n",
    "        if 'geometry' in row and 'amenity' in row and 'name' in row and 'addr_city' in row and 'amenity_points' in row:\n",
    "            # Generate a unique node identifier for polygons\n",
    "            node_id = f\"polygon_{index}\"\n",
    "            amenities_network.add_node(node_id, polygon_index=index, geometry=row['geometry'], lat=row['geometry'].centroid.y, lon=row['geometry'].centroid.x, amenity=row['amenity'], name=row.get('name', ''), addr_city=row['addr_city'], amenity_points=row['amenity_points'])\n",
    "        else:\n",
    "            print(f\"Skipping row {index} in amenities_polygon_gdf due to missing data.\")\n",
    "\n",
    "    # Add point nodes\n",
    "    for index, row in amenities_point_gdf.iterrows():\n",
    "        # Check if essential columns exist in the row\n",
    "        if 'geometry' in row and 'amenity' in row and 'name' in row and 'addr_city' in row:\n",
    "            # Generate a unique node identifier for points\n",
    "            node_id = f\"point_{index}\"\n",
    "            \n",
    "            # This part checks whether the point is a transportation or not \n",
    "            if row['amenity'] == 'transportation':\n",
    "                isTranspo = True\n",
    "            else:\n",
    "                isTranspo = False\n",
    "            amenities_network.add_node(node_id, point_index=index, geometry=row['geometry'], lat=row['y'], lon=row['x'], amenity=row['amenity'], name=row.get('name', ''), addr_city=row['addr_city'], is_in_polygon=False, isTranspo = isTranspo)\n",
    "        else:\n",
    "            print(f\"Skipping row {index} in amenities_point_gdf due to missing data.\")\n",
    "            \n",
    "    return amenities_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of Roads and Rivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting filtered roads FOR VISUALIZATION ONLY\n",
    "def plot_all_filtered_roads():\n",
    "    map_center = (14.599512, 120.984222) # TEMPORARY WILL ZOOM TO MANILA\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "\n",
    "    # Iterate through each road\n",
    "    for index, road in filtered_roads_strings.iterrows():\n",
    "        line_coords = list(road['geometry'].coords)\n",
    "\n",
    "        if road['highway'] == 'primary':\n",
    "            folium.PolyLine(locations=[(y, x) for x, y in line_coords], color='blue').add_to(m)\n",
    "\n",
    "        if road['highway'] == 'secondary':\n",
    "            folium.PolyLine(locations=[(y, x) for x, y in line_coords], color='red').add_to(m)\n",
    "\n",
    "        if road['highway'] == 'tertiary':\n",
    "            folium.PolyLine(locations=[(y, x) for x, y in line_coords], color='green').add_to(m)\n",
    "\n",
    "        if road['highway'] == 'unclassified':\n",
    "            folium.PolyLine(locations=[(y, x) for x, y in line_coords], color='orange').add_to(m)\n",
    "\n",
    "    for index, road in filtered_roads_lists.iterrows():\n",
    "        line_coords = list(road['geometry'].coords)\n",
    "        folium.PolyLine(locations=[(y, x) for x, y in line_coords], color='purple').add_to(m)\n",
    "\n",
    "    # Return the map\n",
    "    return m\n",
    "\n",
    "def plot_all_roads():\n",
    "    map_center = (14.599512, 120.984222) # TEMPORARY WILL ZOOM TO MANILA\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "\n",
    "    # Iterate through each road\n",
    "    for index, road in manila_road.iterrows():\n",
    "        line_coords = list(road['geometry'].coords)\n",
    "        folium.PolyLine(locations=[(y, x) for x, y in line_coords], color='blue').add_to(m)\n",
    "\n",
    "    # Return the map\n",
    "    return m\n",
    "\n",
    "# TEMPORARY TO BE REMOVED\n",
    "def plot_private_roads():\n",
    "    map_center = (14.599512, 120.984222) # TEMPORARY WILL ZOOM TO MANILA\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "\n",
    "    # Iterate through each road\n",
    "    for index, road in manila_private.iterrows():\n",
    "        line_coords = list(road['geometry'].coords)\n",
    "        folium.PolyLine(locations=[(y, x) for x, y in line_coords], color='blue').add_to(m)\n",
    "\n",
    "    # Return the map\n",
    "    return m\n",
    "\n",
    "# TEMPORARY TO BE REMOVED\n",
    "def plot_walk():\n",
    "    map_center = (14.599512, 120.984222) # TEMPORARY WILL ZOOM TO MANILA\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "\n",
    "    # Iterate through each road\n",
    "    for index, road in manila_walk.iterrows():\n",
    "        line_coords = list(road['geometry'].coords)\n",
    "        folium.PolyLine(locations=[(y, x) for x, y in line_coords], color='blue').add_to(m)\n",
    "\n",
    "    # Return the map\n",
    "    return m\n",
    "    \n",
    "# TEMPORARY TO BE REMOVED\n",
    "def plot_bike():\n",
    "    map_center = (14.599512, 120.984222) # TEMPORARY WILL ZOOM TO MANILA\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "\n",
    "    # Iterate through each road\n",
    "    for index, road in manila_bike.iterrows():\n",
    "        line_coords = list(road['geometry'].coords)\n",
    "        folium.PolyLine(locations=[(y, x) for x, y in line_coords], color='blue').add_to(m)\n",
    "\n",
    "    # Return the map\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Amenity and Zone Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD POINTS TO NX GRAPH\n",
    "# Function to add only points to the networkX graph\n",
    "# The other functions focuses on adding polygons, this function just iterates and adds points\n",
    "\n",
    "def add_points_to_graph(graph, graph_to_add):\n",
    "    for node_key, node_data in graph.nodes.items():\n",
    "        if 'geometry' in node_data and node_data['geometry'].geom_type in ['Point']:   \n",
    "            graph_to_add.add_node(node_key, geometry=node_data['geometry'], name=node_data['name'], lat=node_data['lat'], amenity=node_data['amenity'],\n",
    "                                lon=node_data['lon'])\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 1 - COMBINE AMENITIES BY POLYGON\n",
    "# Creates a copy of a graph and connects non-contiguous and non-overlapping shapes instead of merging\n",
    "\n",
    "def combine_amenities_by_polygon(graph, max_distance, max_perimeter):\n",
    "    combined_graph = nx.Graph()\n",
    "    list_to_merge = []\n",
    "    idx = rtree_index.Index()\n",
    "    \n",
    "    # Iterates through each polygon and then enlarges and gets the intersecting ones for easier iteration later\n",
    "    for node_key, node_data in graph.nodes.items():\n",
    "        # Ensure that the bounding box coordinates are passed as a tuple\n",
    "        if 'geometry' in node_data and node_data['geometry'].geom_type in ['Polygon', 'MultiPolygon']:\n",
    "            enlarged_polygon = node_data['geometry'].buffer(meters_to_degrees(max_distance))\n",
    "            bounds = enlarged_polygon.bounds\n",
    "            bounds_float = tuple(float(coord) for coord in bounds)\n",
    "            numeric_key = int(node_key.split('_')[1])\n",
    "            idx.insert(numeric_key, bounds_float)\n",
    "    \n",
    "    #Iterating through each polygon\n",
    "    for node_key, node_data in list(graph.nodes.items()):\n",
    "        if 'geometry' in node_data and node_data['geometry'].geom_type in ['Polygon', 'MultiPolygon']:\n",
    "            nodes_to_merge = []\n",
    "            \n",
    "            #Check first if it is already in a list of polygons to be merged\n",
    "            for merge_list in list_to_merge:\n",
    "                if node_key in merge_list:\n",
    "                    nodes_to_merge = merge_list\n",
    "                    break\n",
    "            \n",
    "            # If this is a new node that is not part of any list, add itself to the list for merging later\n",
    "            if not nodes_to_merge:\n",
    "                nodes_to_merge.append(node_key)\n",
    "            \n",
    "            # Distance \n",
    "            total_distance = 0 # This is to calculate the total distance\n",
    "            combined_node = graph.nodes[node_key]['geometry']\n",
    "            \n",
    "            # Then iterate through other polygons that intersect that polygon based on bounds\n",
    "            for other_node_key in idx.intersection(node_data['geometry'].bounds):\n",
    "                formatted_key = f\"polygon_{other_node_key}\"\n",
    "                other_node_data = graph.nodes[formatted_key]\n",
    "                if 'geometry' in other_node_data and other_node_data['geometry'].geom_type in ['Polygon', 'MultiPolygon']:\n",
    "                    # Check if its not the same node, it is the same amenity, and is not already in the list to merge\n",
    "                    if node_key != formatted_key and node_data['amenity'] == other_node_data['amenity']:\n",
    "                        distance = degrees_to_meters(node_data['geometry'].distance(other_node_data['geometry']))\n",
    "\n",
    "                        if distance <= max_distance:\n",
    "                            line_between_centroids = LineString([node_data['geometry'].centroid, other_node_data['geometry'].centroid])\n",
    "                            amenities_intersecting = any(graph.nodes[amenity_key]['geometry'].intersects(line_between_centroids) for amenity_key in graph.nodes if amenity_key != node_key and amenity_key != formatted_key and graph.nodes[amenity_key]['amenity'] != node_data['amenity'])\n",
    "                            \n",
    "                            # Check if it does not exceed the max perimeter\n",
    "                            combined_node = shapely.ops.unary_union([combined_node, graph.nodes[formatted_key]['geometry']])\n",
    "                            total_distance += degrees_to_meters(combined_node.length)\n",
    "                            \n",
    "                            if not amenities_intersecting and total_distance < max_perimeter and not find_intersecting_features(line_between_centroids):\n",
    "                                nodes_to_merge.append(formatted_key)\n",
    "            \n",
    "            if nodes_to_merge not in list_to_merge:\n",
    "                list_to_merge.append(nodes_to_merge) # Add to the list to merge the polygons later\n",
    "                \n",
    "            \n",
    "                \n",
    "    temp_graph = to_graph(list_to_merge)\n",
    "    lists = graph_to_list(temp_graph)\n",
    "\n",
    "\n",
    "    # Now we will finally connect all polygons in the list\n",
    "    for merge_list in lists:\n",
    "        first = True\n",
    "        for node_key in merge_list:\n",
    "            if first:\n",
    "                combined_node = graph.nodes[node_key]['geometry']\n",
    "                combined_node_amenity = graph.nodes[node_key]['amenity']\n",
    "                combined_node_key = node_key\n",
    "                combined_node_geometry = graph.nodes[node_key]['geometry']\n",
    "                combined_node_name = graph.nodes[node_key]['name']\n",
    "                combined_node_lat = graph.nodes[node_key]['lat']\n",
    "                combined_node_lon = graph.nodes[node_key]['lon']\n",
    "                combined_node_points = graph.nodes[node_key]['amenity_points']\n",
    "                first = False\n",
    "            else:\n",
    "                combined_node = shapely.ops.unary_union([combined_node_geometry, graph.nodes[node_key]['geometry']])\n",
    "                combined_node_geometry = combined_node\n",
    "                combined_node_name = combine_names(combined_node_name, graph.nodes[node_key].get('name'))\n",
    "                combined_node_lat = combined_node_geometry.centroid.x\n",
    "                combined_node_lon = combined_node_geometry.centroid.x\n",
    "                combined_node_points += graph.nodes[node_key].get('amenity_points', 0)\n",
    "                \n",
    "        combined_graph.add_node(combined_node_key, geometry=combined_node_geometry, name=combined_node_name, lat=combined_node_lat, amenity=combined_node_amenity,\n",
    "                                lon=combined_node_lon, amenity_points=combined_node_points)\n",
    "\n",
    "    return combined_graph\n",
    "\n",
    "# TEMPORARY SOLUTION FOR NULL NAMES\n",
    "def combine_names(name1, name2):\n",
    "    # Combine names ensuring that no null values are included\n",
    "    if isinstance(name1, str) and isinstance(name2, str):\n",
    "        return f\"{name1}, {name2}\"\n",
    "    elif isinstance(name1, str):\n",
    "        return name1\n",
    "    elif isinstance(name2, str):\n",
    "        return name2\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPORARY\n",
    "\n",
    "def combine_residential(graph, max_distance, max_perimeter):\n",
    "    combined_graph = nx.Graph()\n",
    "    list_to_merge = []\n",
    "    idx = rtree_index.Index()\n",
    "    \n",
    "    for node_key, node_data in graph.nodes.items():\n",
    "        if 'amenity' in node_data and node_data['amenity'] == 'residential areas':\n",
    "            if 'geometry' in node_data and node_data['geometry'].geom_type in ['Polygon', 'MultiPolygon']:\n",
    "                enlarged_polygon = node_data['geometry'].buffer(meters_to_degrees(max_distance))\n",
    "                bounds = enlarged_polygon.bounds\n",
    "                bounds_float = tuple(float(coord) for coord in bounds)\n",
    "                numeric_key = int(node_key.split('_')[1])\n",
    "                idx.insert(numeric_key, bounds_float)\n",
    "\n",
    "    loop_count = 1\n",
    "    for node_key, node_data in graph.nodes.items():\n",
    "        print(\"Polgon Count: \", loop_count, \" / \", total_residential)\n",
    "        \n",
    "        if 'amenity' in node_data and node_data['amenity'] == 'residential areas':\n",
    "            if 'geometry' in node_data and node_data['geometry'].geom_type in ['Polygon', 'MultiPolygon']:\n",
    "                nodes_to_merge = []\n",
    "            \n",
    "                #Check first if it is already in a list of polygons to be merged\n",
    "                for merge_list in list_to_merge:\n",
    "                    if node_key in merge_list:\n",
    "                        nodes_to_merge = merge_list\n",
    "                        break\n",
    "            \n",
    "                # If this is a new node that is not part of any list, add itself to the list for merging later\n",
    "                if not nodes_to_merge:\n",
    "                    nodes_to_merge.append(node_key)\n",
    "            \n",
    "                # Distance \n",
    "                total_distance = 0 # This is to calculate the total distance\n",
    "                combined_node = graph.nodes[node_key]['geometry']\n",
    "\n",
    "                sub_poly_count = 1\n",
    "                for other_node_key in idx.intersection(node_data['geometry'].bounds):\n",
    "                    print(f\"Currently checking {sub_poly_count}\")\n",
    "                    \n",
    "                    formatted_key = f\"polygon_{other_node_key}\"\n",
    "                    other_node_data = graph.nodes[formatted_key]\n",
    "                    if 'amenity' in other_node_data and other_node_data['amenity'] == 'residential areas':\n",
    "                        if 'geometry' in other_node_data and other_node_data['geometry'].geom_type in ['Polygon', 'MultiPolygon']:\n",
    "                            # Check if its not the same node, it is the same amenity, and is not already in the list to merge\n",
    "                            if node_key != formatted_key and node_data['amenity'] == other_node_data['amenity']:\n",
    "                                distance = degrees_to_meters(node_data['geometry'].distance(other_node_data['geometry']))\n",
    "                                line_between_centroids = LineString([node_data['geometry'].centroid, other_node_data['geometry'].centroid])\n",
    "                                amenities_intersecting = any(graph.nodes[amenity_key]['geometry'].intersects(line_between_centroids) for amenity_key in graph.nodes if amenity_key != node_key and amenity_key != formatted_key and graph.nodes[amenity_key]['amenity'] != node_data['amenity'])\n",
    "                        \n",
    "                                # Check if it does not exceed the max perimeter\n",
    "                                combined_node = shapely.ops.unary_union([combined_node, graph.nodes[formatted_key]['geometry']])\n",
    "                                total_distance += degrees_to_meters(combined_node.length)\n",
    "                        \n",
    "                                if not amenities_intersecting and total_distance < max_perimeter and not find_intersecting_features(line_between_centroids):\n",
    "                                    nodes_to_merge.append(formatted_key)\n",
    "                    sub_poly_count += 1\n",
    "            \n",
    "                if nodes_to_merge not in list_to_merge:\n",
    "                    list_to_merge.append(nodes_to_merge) # Add to the list to merge the polygons later\n",
    "                    \n",
    "        loop_count += 1\n",
    "    temp_graph = to_graph(list_to_merge)\n",
    "    lists = graph_to_list(temp_graph)\n",
    "\n",
    "\n",
    "    # Now we will finally connect all polygons in the list\n",
    "    for merge_list in lists:\n",
    "        first = True\n",
    "        for node_key in merge_list:\n",
    "            if first:\n",
    "                combined_node = graph.nodes[node_key]['geometry']\n",
    "                combined_node_amenity = graph.nodes[node_key]['amenity']\n",
    "                combined_node_key = node_key\n",
    "                combined_node_geometry = graph.nodes[node_key]['geometry']\n",
    "                combined_node_name = graph.nodes[node_key]['name']\n",
    "                combined_node_lat = graph.nodes[node_key]['lat']\n",
    "                combined_node_lon = graph.nodes[node_key]['lon']\n",
    "                combined_node_points = graph.nodes[node_key]['amenity_points']\n",
    "                first = False\n",
    "            else:\n",
    "                combined_node = shapely.ops.unary_union([combined_node_geometry, graph.nodes[node_key]['geometry']])\n",
    "                combined_node_geometry = combined_node\n",
    "                combined_node_name = combine_names(combined_node_name, graph.nodes[node_key].get('name'))\n",
    "                combined_node_lat = combined_node_geometry.centroid.x\n",
    "                combined_node_lon = combined_node_geometry.centroid.x\n",
    "                combined_node_points += graph.nodes[node_key].get('amenity_points', 0)\n",
    "        \n",
    "        combined_graph.add_node(combined_node_key, geometry=combined_node_geometry, name=combined_node_name, lat=combined_node_lat, amenity=combined_node_amenity,\n",
    "                                lon=combined_node_lon, amenity_points=combined_node_points)\n",
    "\n",
    "    return combined_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMPORARY\n",
    "def combine_small_residential(graph, max_distance, max_perimeter):\n",
    "    combined_graph = nx.Graph()\n",
    "    list_to_merge = []\n",
    "    idx = rtree_index.Index()\n",
    "    \n",
    "    for node_key, node_data in graph.nodes.items():\n",
    "        if 'amenity' in node_data and node_data['amenity'] == 'residential areas':\n",
    "            if 'geometry' in node_data and node_data['geometry'].geom_type in ['Polygon', 'MultiPolygon']:\n",
    "                enlarged_polygon = node_data['geometry'].buffer(meters_to_degrees(20))\n",
    "                bounds = enlarged_polygon.bounds\n",
    "                bounds_float = tuple(float(coord) for coord in bounds)\n",
    "                numeric_key = int(node_key.split('_')[1])\n",
    "                idx.insert(numeric_key, bounds_float)\n",
    "\n",
    "    loop_count = 1\n",
    "    for node_key, node_data in graph.nodes.items():\n",
    "        print(\"Polgon Count: \", loop_count, \" / \", total_residential)\n",
    "        \n",
    "        if 'amenity' in node_data and node_data['amenity'] == 'residential areas':\n",
    "            if 'geometry' in node_data and node_data['geometry'].geom_type in ['Polygon', 'MultiPolygon']:\n",
    "                nodes_to_merge = []\n",
    "            \n",
    "                #Check first if it is already in a list of polygons to be merged\n",
    "                for merge_list in list_to_merge:\n",
    "                    if node_key in merge_list:\n",
    "                        nodes_to_merge = merge_list\n",
    "                        break\n",
    "            \n",
    "                # If this is a new node that is not part of any list, add itself to the list for merging later\n",
    "                if not nodes_to_merge:\n",
    "                    nodes_to_merge.append(node_key)\n",
    "            \n",
    "                # Distance \n",
    "                total_distance = 0 # This is to calculate the total distance\n",
    "                combined_node = graph.nodes[node_key]['geometry']\n",
    "\n",
    "                sub_poly_count = 1\n",
    "                for other_node_key in idx.intersection(node_data['geometry'].bounds):\n",
    "                    print(f\"Polygon {loop_count}: Currently checking {sub_poly_count}\")\n",
    "                    \n",
    "                    formatted_key = f\"polygon_{other_node_key}\"\n",
    "                    other_node_data = graph.nodes[formatted_key]\n",
    "                    if 'amenity' in other_node_data and other_node_data['amenity'] == 'residential areas':\n",
    "                        if 'geometry' in other_node_data and other_node_data['geometry'].geom_type in ['Polygon', 'MultiPolygon']:\n",
    "                            # Check if its not the same node, it is the same amenity, and is not already in the list to merge\n",
    "                            if node_key != formatted_key and node_data['amenity'] == other_node_data['amenity']:\n",
    "                                distance = degrees_to_meters(node_data['geometry'].distance(other_node_data['geometry']))\n",
    "                                line_between_centroids = LineString([node_data['geometry'].centroid, other_node_data['geometry'].centroid])\n",
    "                                amenities_intersecting = any(graph.nodes[amenity_key]['geometry'].intersects(line_between_centroids) for amenity_key in graph.nodes if amenity_key != node_key and amenity_key != formatted_key and graph.nodes[amenity_key]['amenity'] != node_data['amenity'])\n",
    "                        \n",
    "                                # Check if it does not exceed the max perimeter\n",
    "                                combined_node = shapely.ops.unary_union([combined_node, graph.nodes[formatted_key]['geometry']])\n",
    "                                total_distance += degrees_to_meters(combined_node.length)\n",
    "                        \n",
    "                                if not amenities_intersecting and total_distance < max_perimeter and not find_intersecting_features(line_between_centroids):\n",
    "                                    nodes_to_merge.append(formatted_key)\n",
    "                    sub_poly_count += 1\n",
    "            \n",
    "                if nodes_to_merge not in list_to_merge:\n",
    "                    list_to_merge.append(nodes_to_merge) # Add to the list to merge the polygons later\n",
    "                    \n",
    "        loop_count += 1\n",
    "        \n",
    "    temp_graph = to_graph(list_to_merge)\n",
    "    lists = graph_to_list(temp_graph)\n",
    "\n",
    "\n",
    "    # Now we will finally connect all polygons in the list\n",
    "    for merge_list in lists:\n",
    "        first = True\n",
    "        for node_key in merge_list:\n",
    "            if first:\n",
    "                combined_node = graph.nodes[node_key]['geometry']\n",
    "                combined_node_amenity = graph.nodes[node_key]['amenity']\n",
    "                combined_node_key = node_key\n",
    "                combined_node_geometry = graph.nodes[node_key]['geometry']\n",
    "                combined_node_name = graph.nodes[node_key]['name']\n",
    "                combined_node_lat = graph.nodes[node_key]['lat']\n",
    "                combined_node_lon = graph.nodes[node_key]['lon']\n",
    "                combined_node_points = graph.nodes[node_key]['amenity_points']\n",
    "                first = False\n",
    "            else:\n",
    "                combined_node = shapely.ops.unary_union([combined_node_geometry, graph.nodes[node_key]['geometry']])\n",
    "                combined_node_geometry = combined_node\n",
    "                combined_node_name = combine_names(combined_node_name, graph.nodes[node_key].get('name'))\n",
    "                combined_node_lat = combined_node_geometry.centroid.x\n",
    "                combined_node_lon = combined_node_geometry.centroid.x\n",
    "                combined_node_points += graph.nodes[node_key].get('amenity_points', 0)\n",
    "        \n",
    "        print(\"Added\")\n",
    "        combined_graph.add_node(combined_node_key, geometry=combined_node_geometry, name=combined_node_name, lat=combined_node_lat, amenity=combined_node_amenity,\n",
    "                                lon=combined_node_lon, amenity_points=combined_node_points)\n",
    "\n",
    "    return combined_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To merge duplicates in lists\n",
    "def to_graph(nodes):\n",
    "    G = nx.Graph()\n",
    "    for part in nodes:\n",
    "        G.add_nodes_from(part)\n",
    "        G.add_edges_from(to_edges(part))\n",
    "    return G\n",
    "\n",
    "def to_edges(nodes):\n",
    "    it = iter(nodes)\n",
    "    last = next(it)\n",
    "\n",
    "    for current in it:\n",
    "        yield last, current\n",
    "        last = current\n",
    "        \n",
    "def graph_to_list(G):\n",
    "    connected_components = nx.connected_components(G)\n",
    "    lists = [list(component) for component in connected_components]\n",
    "    return lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Function to plot/visualize main graph network on the map\n",
    "def plot_network_on_map(amenities_network, initial_location=[0, 0], zoom_start=10):\n",
    "    # Create a map centered at the initial location\n",
    "    map_center = (14.599512, 120.984222) # TEMPORARY WILL ZOOM TO MANILA\n",
    "    m = folium.Map(location=map_center, zoom_start=zoom_start, tiles='openstreetmap')\n",
    "    \n",
    "    #Colours for Visualization\n",
    "    amenity_colors = {\n",
    "        'education': 'green',\n",
    "        'finance': 'blue',\n",
    "        'government offices': 'red',\n",
    "        'grocery': 'orange',\n",
    "        'health': 'magenta',\n",
    "        'malls': 'yellow',\n",
    "        'residential areas': 'brown',\n",
    "        'security': 'gray',\n",
    "        'transportation': 'lightblue',\n",
    "        'others': 'black'\n",
    "    }\n",
    "\n",
    "    # Iterate over the nodes in the network\n",
    "    for node, data in amenities_network.nodes(data=True):\n",
    "        # Check if the node has a geometry attribute\n",
    "        if 'geometry' in data:\n",
    "            # Get the geometry of the node\n",
    "            geometry = data['geometry']\n",
    "\n",
    "            # Check the geometry type and plot accordingly\n",
    "            if geometry.geom_type == 'Point':\n",
    "                # Plot a marker for points    \n",
    "                #folium.Marker(location=[geometry.y, geometry.x], popup=f\"{data['name']}\").add_to(m)\n",
    "                continue\n",
    "            elif geometry.geom_type in ['Polygon', 'MultiPolygon']:\n",
    "                # Plot polygons or multipolygons\n",
    "                color = amenity_colors[data.get('amenity')]\n",
    "                if geometry.geom_type == 'Polygon':\n",
    "                    polygons = [geometry]\n",
    "                else:\n",
    "                    polygons = geometry.geoms\n",
    "\n",
    "                for polygon in polygons:\n",
    "                    coordinates = []\n",
    "                    for point in polygon.exterior.coords:\n",
    "                        coordinates.append([point[1], point[0]])\n",
    "                    folium.Polygon(locations=coordinates, fill=True, color=color, fill_opacity=0.4).add_to(m)\n",
    "\n",
    "    # Return the map\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 2 - Function to connect zones in a network\n",
    "def create_zone_network(graph, max_distance):\n",
    "    connect_graph = nx.Graph()\n",
    "    network_id = 1\n",
    "    list_to_connect = []\n",
    "    idx = rtree_index.Index()\n",
    "    \n",
    "    for node_key, node_data in graph.nodes.items():\n",
    "        enlarged_polygon = node_data['geometry'].buffer(meters_to_degrees(max_distance))\n",
    "        bounds = enlarged_polygon.bounds\n",
    "        bounds_float = tuple(float(coord) for coord in bounds)\n",
    "        numeric_key = int(node_key.split('_')[1])\n",
    "        idx.insert(numeric_key, bounds_float)\n",
    "    \n",
    "    for node_key, node_data in list(graph.nodes.items()):\n",
    "        if 'geometry' in node_data and node_data['geometry'].geom_type in ['Polygon', 'MultiPolygon']:\n",
    "            connect_nodes = []\n",
    "            \n",
    "            #Check first if it is already in a list of polygons to be connected\n",
    "            for connect_list in list_to_connect:\n",
    "                if node_key in connect_list:\n",
    "                    connect_nodes = connect_list\n",
    "                    break\n",
    "            \n",
    "            # If this is a new node that is not part of any list, add itself to the list for merging later\n",
    "            if not connect_nodes:\n",
    "                connect_nodes.append(node_key)\n",
    "                \n",
    "            # If this is not a residential area that is its own zone\n",
    "            if node_key not in pop_graph or not pop_graph.nodes[node_key]['is_a_zone']:\n",
    "                for other_node_key in idx.intersection(node_data['geometry'].bounds):\n",
    "                    formatted_key = f\"polygon_{other_node_key}\"\n",
    "                    other_node_data = graph.nodes[formatted_key]\n",
    "                    if 'geometry' in other_node_data and other_node_data['geometry'].geom_type in ['Polygon', 'MultiPolygon']:\n",
    "                        if node_key != formatted_key:\n",
    "\n",
    "                            distance = degrees_to_meters(node_data['geometry'].distance(other_node_data['geometry']))\n",
    "\n",
    "                            # Check if they are within distance of each other\n",
    "                            if distance <= max_distance:\n",
    "                                line_between_centroids = LineString([node_data['geometry'].centroid, other_node_data['geometry'].centroid])\n",
    "                                if not find_intersecting_features(line_between_centroids):\n",
    "                                    if formatted_key not in pop_graph or not pop_graph.nodes[formatted_key]['is_a_zone']:\n",
    "                                        connect_nodes.append(formatted_key)\n",
    "                                \n",
    "            if connect_nodes not in list_to_connect:\n",
    "                list_to_connect.append(connect_nodes) # Add to the list to merge the polygons later\n",
    "                \n",
    "    temp_graph = to_graph(list_to_connect)\n",
    "    lists = graph_to_list(temp_graph)\n",
    "\n",
    "    # Now we will finally connect all polygons in the list\n",
    "    for merge_list in lists:\n",
    "        first = True\n",
    "        for node_key in merge_list:\n",
    "            if first:\n",
    "                combined_node = graph.nodes[node_key]['geometry']\n",
    "                combined_node_amenity = graph.nodes[node_key]['amenity']\n",
    "                combined_node_key = node_key\n",
    "                combined_node_geometry = graph.nodes[node_key]['geometry']\n",
    "                combined_node_name = graph.nodes[node_key]['name']\n",
    "                combined_node_lat = graph.nodes[node_key]['lat']\n",
    "                combined_node_lon = graph.nodes[node_key]['lon']\n",
    "                combined_node_points = graph.nodes[node_key]['amenity_points']\n",
    "                first = False\n",
    "            else:\n",
    "                combined_node = shapely.ops.unary_union([combined_node_geometry, graph.nodes[node_key]['geometry']])\n",
    "                combined_node_geometry = combined_node\n",
    "                combined_node_name = combine_names(combined_node_name, graph.nodes[node_key].get('name'))\n",
    "                combined_node_lat = combined_node_geometry.centroid.x\n",
    "                combined_node_lon = combined_node_geometry.centroid.x\n",
    "                combined_node_points += graph.nodes[node_key].get('amenity_points', 0)\n",
    "                \n",
    "        network_id += 1\n",
    "        connect_graph.add_node(combined_node_key, geometry=combined_node_geometry, name=combined_node_name, lat=combined_node_lat, amenity=combined_node_amenity,\n",
    "                                lon=combined_node_lon, amenity_points=combined_node_points, network_id=network_id)\n",
    "\n",
    "    return connect_graph\n",
    "\n",
    "# TEMPORARY SOLUTION FOR NULL NAMES\n",
    "def combine_names(name1, name2):\n",
    "    # Combine names ensuring that no null values are included\n",
    "    if isinstance(name1, str) and isinstance(name2, str):\n",
    "        return f\"{name1}, {name2}\"\n",
    "    elif isinstance(name1, str):\n",
    "        return name1\n",
    "    elif isinstance(name2, str):\n",
    "        return name2\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Function to plot/visualize connected zones on the map\n",
    "import random\n",
    "\n",
    "# This is to better visualize the networks\n",
    "def plot_connected_zones_network_on_map(graph, initial_location=[0, 0], zoom_start=10):\n",
    "    # Create a map centered at the initial location\n",
    "    map_center = (14.599512, 120.984222) # TEMPORARY WILL ZOOM TO MANILA\n",
    "    m = folium.Map(location=map_center, zoom_start=zoom_start, tiles='openstreetmap')\n",
    "    \n",
    "    #Colours for Visualization\n",
    "    colors = [\n",
    "    \"Red\", \"Green\", \"Blue\", \"Yellow\", \"Orange\", \"Purple\", \"Cyan\", \"Magenta\", \"Maroon\",\n",
    "    \"Olive\", \"Lime\", \"Teal\", \"Navy\", \"Aqua\", \"Fuchsia\", \"Coral\", \"Indigo\", \"Violet\"]\n",
    "    \n",
    "    color_map = {}\n",
    "\n",
    "    # Iterate over the nodes in the network\n",
    "    for node, data in graph.nodes(data=True):\n",
    "        # Check if the node has a geometry attribute\n",
    "        if 'geometry' in data:\n",
    "            # Get the geometry of the node\n",
    "            geometry = data['geometry']\n",
    "\n",
    "            # Check the geometry type and plot accordingly\n",
    "            if geometry.geom_type == 'Point':\n",
    "                # Plot a marker for points    \n",
    "                #folium.Marker(location=[geometry.y, geometry.x], popup=f\"{data['name']}\").add_to(m)\n",
    "                continue\n",
    "            elif geometry.geom_type in ['Polygon', 'MultiPolygon']:\n",
    "                \n",
    "                network_id = data[\"network_id\"]\n",
    "                \n",
    "                if network_id not in color_map:\n",
    "                    color = random.choice(colors)\n",
    "                    color_map[network_id] = color\n",
    "                else:\n",
    "                    color = color_map[network_id]\n",
    "                \n",
    "                if geometry.geom_type == 'Polygon':\n",
    "                    polygons = [geometry]\n",
    "                else:\n",
    "                    polygons = geometry.geoms\n",
    "\n",
    "                for polygon in polygons:\n",
    "                    coordinates = []\n",
    "                    for point in polygon.exterior.coords:\n",
    "                        coordinates.append([point[1], point[0]])\n",
    "                    folium.Polygon(locations=coordinates, fill=True, color=color, fill_opacity=0.4).add_to(m)\n",
    "\n",
    "    # Return the map\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to visualize the stops\n",
    "def plot_stops_on_map(network_map, stops, initial_location=[0, 0], zoom_start=10):\n",
    "    # Iterate over the nodes in the network\n",
    "    for stop in stops:\n",
    "        folium.Marker(location=[stop.lat, stop.long], popup=f\"{stop.isTranspo}\").add_to(network_map)\n",
    "        \n",
    "    return network_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check population density - To be used for the zone connection\n",
    "# Uses the combined graph\n",
    "# Formula: Population Density = Total Population / Total Area\n",
    "\n",
    "def check_residential_population_density(graph, threshold):\n",
    "    # Create an R-tree index for efficient spatial querying\n",
    "    idx = rtree_index.Index()\n",
    "    \n",
    "    # Populate the R-tree index with points\n",
    "    for index, row in manila_population_gdf.iterrows():\n",
    "        idx.insert(index, (row['longitude'], row['latitude'], row['longitude'], row['latitude']))\n",
    "    \n",
    "    pop_graph = nx.Graph()\n",
    "    \n",
    "    for node_key, node_data in graph.nodes.items():\n",
    "        # Check if its a polygon and is a residential area\n",
    "        if 'geometry' in node_data and node_data['geometry'].geom_type in ['Polygon', 'MultiPolygon'] and node_data['amenity'] == \"residential areas\":\n",
    "            total_pop = 0\n",
    "            \n",
    "            # Query the R-tree index to find points within the polygon\n",
    "            for point_idx in idx.intersection(node_data['geometry'].bounds):\n",
    "                point = manila_population_gdf.loc[point_idx]\n",
    "                if Point(point['longitude'], point['latitude']).within(node_data['geometry']):\n",
    "                    total_pop += point['phl_general_2020']  # Add the density\n",
    "            \n",
    "            density = total_pop / node_data['geometry'].area\n",
    "            \n",
    "            if density > threshold:\n",
    "                node_data[\"is_a_zone\"] = True\n",
    "            else:\n",
    "                node_data[\"is_a_zone\"] = False\n",
    "            \n",
    "            pop_graph.add_node(node_key, density=density, **node_data)\n",
    "    return pop_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5 - Function to plot/visualize residential areas based on population density on the map\n",
    "# This is to better visualize which residential areas can become zones\n",
    "def plot_population_zones_map(graph, initial_location=[0, 0], zoom_start=10):\n",
    "    # Create a map centered at the initial location\n",
    "    map_center = (14.599512, 120.984222) # TEMPORARY WILL ZOOM TO MANILA\n",
    "    m = folium.Map(location=map_center, zoom_start=zoom_start, tiles='openstreetmap')\n",
    "\n",
    "    # Iterate over the nodes in the network\n",
    "    for node, data in graph.nodes(data=True):\n",
    "        # Check if the node has a geometry attribute\n",
    "        if 'geometry' in data:\n",
    "            # Get the geometry of the node\n",
    "            geometry = data['geometry']\n",
    "\n",
    "            # Check the geometry type and plot accordingly\n",
    "            if geometry.geom_type == 'Point':\n",
    "                # Plot a marker for points    \n",
    "                #folium.Marker(location=[geometry.y, geometry.x], popup=f\"{data['name']}\").add_to(m)\n",
    "                continue\n",
    "            elif geometry.geom_type in ['Polygon', 'MultiPolygon']:\n",
    "                if geometry.geom_type == 'Polygon':\n",
    "                    polygons = [geometry]\n",
    "                else:\n",
    "                    polygons = geometry.geoms\n",
    "\n",
    "                for polygon in polygons:\n",
    "                    coordinates = []\n",
    "                    for point in polygon.exterior.coords:\n",
    "                        coordinates.append([point[1], point[0]])\n",
    "                    \n",
    "                    if (data['is_a_zone']):\n",
    "                        folium.Polygon(locations=coordinates, fill=True, color=\"green\", fill_opacity=0.4).add_to(m)\n",
    "                    else:\n",
    "                        folium.Polygon(locations=coordinates, fill=True, color=\"red\", fill_opacity=0.4).add_to(m)\n",
    "\n",
    "    # Return the map\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CREATING STOPS\n",
    "# It should return a list of coordinates/nodes for stop and a graph of stops\n",
    "# if residential area, check if the population density\n",
    "\n",
    "# Global Variables used:\n",
    "# list_of_stops - List of stops\n",
    "# graph_of_stops - graph of all stops placed\n",
    "# CITY_GRAPH - graph of the city road networks\n",
    "import random\n",
    "\n",
    "def place_stops_on_roads(amenity_graph, graph_of_stops, list_of_stops):\n",
    "    global CITY_GRAPH  \n",
    "    for node_key, node_data in amenity_graph.nodes(data=True):\n",
    "        # All tranportation points are automatically stops\n",
    "        if node_data['geometry'].geom_type in ['Point']:\n",
    "            if node_data['amenity'] == 'transportation':\n",
    "                nearest_node = ox.distance.nearest_nodes(CITY_GRAPH, node_data['lon'], node_data['lat'])\n",
    "                \n",
    "                # If there is an existing node in the main graph, then add it to the list and the stop graph\n",
    "                if nearest_node is not None:\n",
    "                    lon = CITY_GRAPH.nodes[nearest_node]['x']\n",
    "                    lat = CITY_GRAPH.nodes[nearest_node]['y']\n",
    "                    isTranspo = True\n",
    "                    graph_of_stops.add_node(nearest_node, lon=lon, lat=lat, isTranspo=isTranspo)\n",
    "                    list_of_stops.append(stopCandidate(CITY_GRAPH.nodes[nearest_node]['y'], CITY_GRAPH.nodes[nearest_node]['x'], True, nearest_node, 0))\n",
    "        \n",
    "        else:\n",
    "            # Calculate the number of stops based on node size and population density\n",
    "            num_stops, node_size = calculate_num_stops(node_key, node_data)\n",
    "            \n",
    "            buffer_poly = node_data['geometry'].buffer(meters_to_degrees(30))\n",
    "            # Get the roads surrounding and inside the node polygons\n",
    "            relevant_edges = get_relevant_edges(buffer_poly)\n",
    "            \n",
    "            # Place stops randomly on these roads\n",
    "            place_stops_along_edges(relevant_edges, buffer_poly, num_stops, node_size, graph_of_stops, list_of_stops)\n",
    "\n",
    "def calculate_num_stops(node_key, node_data):\n",
    "    # Example calculation based on node size and population density\n",
    "    node_size = degrees_to_meters(node_data['geometry'].area) # Size of the node polygon\n",
    "    # Adjust factors and formula as needed\n",
    "    num_stops = 0\n",
    "    \n",
    "    if node_key in pop_graph:\n",
    "        pop_density = pop_graph.nodes[node_key]['density']\n",
    "        num_stops = node_size * pop_density / 10000000  # Adjust this factor as needed\n",
    "        \n",
    "        if num_stops < 1:\n",
    "            num_stops = 1\n",
    "        elif num_stops > 3:\n",
    "            num_stops = 3\n",
    "    else:\n",
    "        list_sum = len(node_data['amenity_points'])\n",
    "\n",
    "        if list_sum > 0:\n",
    "            num_stops = 1\n",
    "        \n",
    "    return int(num_stops), node_size\n",
    "\n",
    "\n",
    "# Create spatial index\n",
    "filtered_roads_strings_sindex = filtered_roads_strings.sindex\n",
    "filtered_roads_lists_sindex = filtered_roads_lists.sindex\n",
    "def get_relevant_edges(polygon):\n",
    "    relevant_edges = []\n",
    "    \n",
    "    # Check intersection with filtered roads\n",
    "    possible_matches_roads = filtered_roads_strings.iloc[list(filtered_roads_strings_sindex.intersection(polygon.bounds))]\n",
    "    for index, row in possible_matches_roads.iterrows():\n",
    "        if polygon.intersects(row['geometry']) and row['highway'] in ['primary', 'secondary', 'tertiary', 'residential']:\n",
    "            relevant_edges.append(row)\n",
    "\n",
    "    possible_matches_lists = filtered_roads_lists.iloc[list(filtered_roads_lists_sindex.intersection(polygon.bounds))]\n",
    "    for index, row in possible_matches_lists.iterrows():\n",
    "        if polygon.intersects(row['geometry']):\n",
    "            list_highway = row['highway']\n",
    "            if any(x in ['primary', 'secondary', 'tertiary', 'residential'] for x in list_highway):\n",
    "                relevant_edges.append(row)\n",
    "    return relevant_edges\n",
    "\n",
    "def place_stops_along_edges(edges, polygon, num_stops, node_size, graph_of_stops, list_of_stops):\n",
    "    # Place stops randomly along the edges within the polygon\n",
    "    \n",
    "    if len(edges) > 0:\n",
    "        for _ in range(num_stops):\n",
    "            edge = random.choice(edges)\n",
    "            # Calculate the intersection between the edge and the polygon\n",
    "            intersecting_line = edge['geometry'].intersection(polygon)\n",
    "            if intersecting_line.is_empty:\n",
    "                continue\n",
    "\n",
    "            # Calculate the length of the intersecting part of the edge\n",
    "            intersecting_length = intersecting_line.length\n",
    "\n",
    "            # Generate a random position along the intersecting part of the edge\n",
    "            random_position = random.uniform(0, intersecting_length)\n",
    "\n",
    "            # Calculate the coordinate along the edge at the random position\n",
    "            stop_location = calculate_coordinate_along_edge(intersecting_line, random_position)\n",
    "            #print(\"Stop placed at:\", stop_location)\n",
    "            \n",
    "            nearest_node = ox.distance.nearest_nodes(CITY_GRAPH, stop_location[0], stop_location[1])\n",
    "            \n",
    "            # If there is an existing node in the main graph, then add it to the list and the stop graph\n",
    "            if nearest_node is not None:\n",
    "                lon = CITY_GRAPH.nodes[nearest_node]['x']\n",
    "                lat = CITY_GRAPH.nodes[nearest_node]['y']\n",
    "                isTranspo = False\n",
    "                graph_of_stops.add_node(nearest_node, lon=lon, lat=lat, isTranspo=isTranspo)\n",
    "                list_of_stops.append(stopCandidate(CITY_GRAPH.nodes[nearest_node]['y'], CITY_GRAPH.nodes[nearest_node]['x'], False,  nearest_node, node_size))\n",
    "        \n",
    "            \n",
    "\n",
    "def calculate_coordinate_along_edge(edge, position):\n",
    "    # Calculate the coordinate along the edge at the given position\n",
    "    point = edge.interpolate(position)\n",
    "    return point.x, point.y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the graph into a geojson for loading into QGIS\n",
    "\n",
    "def graph_to_geojson(graph, filename):\n",
    "    # Initialize an empty list to hold GeoJSON features\n",
    "    features = []\n",
    "\n",
    "    # Iterate over the nodes in the graph\n",
    "    for node, data in graph.nodes(data=True):\n",
    "        # Check if the node has a geometry attribute\n",
    "        if 'geometry' in data:\n",
    "            # Convert the geometry to a GeoJSON-compatible format\n",
    "            geometry = shapely.geometry.shape(data['geometry'])\n",
    "            # Create a copy of the properties to check for NaN values\n",
    "            properties = data.copy()\n",
    "            # Remove the geometry from the properties\n",
    "            properties.pop('geometry', None)\n",
    "            # Check for NaN values in the properties\n",
    "            if all(not (isinstance(value, float) and np.isnan(value)) for value in properties.values()):\n",
    "                # Create a GeoJSON feature for the node\n",
    "                feature = geojson.Feature(geometry=geometry, properties=properties)\n",
    "                # Add the feature to the list\n",
    "                features.append(feature)\n",
    "\n",
    "    # Create a GeoJSON FeatureCollection\n",
    "    feature_collection = geojson.FeatureCollection(features)\n",
    "\n",
    "    # Return the GeoJSON FeatureCollection\n",
    "    return feature_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Route Network Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V2 - Graph with the snapping function\n",
    "# Generate Route Network from connected routes\n",
    "\n",
    "# Global Variables used:\n",
    "# graph_of_stops - Graph of stops that will be used to create routes\n",
    "def generate_route_network(stop_nodes, max_walking_dist, max_stops, max_routes, graph_of_stops, connection_type=\"Default\"):\n",
    "    global route_count\n",
    "    overall_graph = nx.Graph()\n",
    "    \n",
    "    stop_node_coordinates = [[n.lat, n.long] for n in stop_nodes]\n",
    "    stop_nodes_kd_tree = KDTree(stop_node_coordinates)\n",
    "    next_nodes = [n for n in stop_nodes]\n",
    "    enable_stop_nodes(next_nodes)\n",
    "    route_network = []\n",
    "    num_routes = 0 # Count number of routes\n",
    "\n",
    "    while num_routes < max_routes:\n",
    "        next_nodes = [n for n in stop_nodes] # Resets the list of nodes so that nodes can be reused in a different\n",
    "        selected_node = random.choice(next_nodes) # For the first node\n",
    "        next_nodes.remove(selected_node)\n",
    "        route_gen = generate_route(selected_node, next_nodes, stop_nodes_kd_tree, max_walking_dist, connection_type, max_stops, overall_graph)\n",
    "        \n",
    "        if len(route_gen) > 1:\n",
    "            # A route is a list of connections between two nodes\n",
    "            snap_route_to_road(route_gen, overall_graph, graph_of_stops)\n",
    "            route_count += 1\n",
    "            \n",
    "            #snapped_edges = list(snapped_route.edges(data='road_path', default=1))\n",
    "            #snapped_route = connect_snapped_edges(snapped_edges)\n",
    "            route_network.append(route_gen)   \n",
    "            num_routes += 1\n",
    "               \n",
    "    return route_network, overall_graph\n",
    "\n",
    "def snap_route_to_road(route, overall_graph, graph_of_stops):\n",
    "    global connection_count\n",
    "    \n",
    "    # Directly add nodes based on node identifiers\n",
    "    for connection in route:\n",
    "        overall_graph.add_node(connection[0], **graph_of_stops.nodes[connection[0]]) # The origin\n",
    "        overall_graph.add_node(connection[-1], **graph_of_stops.nodes[connection[-1]]) # The destination\n",
    "        \n",
    "        name = f\"{connection[0]}_{connection[-1]}\" # \"node1_node2\" as name\n",
    "        \n",
    "        distance_travelled = 0\n",
    "        # Get the total distance from point A to point B\n",
    "        for i in range(len(connection)-1):\n",
    "            node_data = CITY_GRAPH.nodes[connection[i]]\n",
    "            next_node_data = CITY_GRAPH.nodes[connection[i+1]]\n",
    "            distance_travelled += haversine(node_data['y'], node_data['x'], next_node_data['y'], next_node_data['x'])\n",
    "        \n",
    "        overall_graph.add_edge(connection[0], connection[-1], road_path=connection, edge_name=name, edge_id = connection_count, route_id = route_count, distance = distance_travelled) # Add edge\n",
    "        connection_count += 1 # Global variable - increment the number of connections\n",
    "        \n",
    "        \n",
    "        if not overall_graph.has_node(connection[0]):\n",
    "                print(\"missing \", connection[0], \" in route\")\n",
    "        \n",
    "        if not overall_graph.has_node(connection[-1]):\n",
    "                print(\"missing \", connection[-1], \" in route \")\n",
    "\n",
    "\n",
    "# Generate route from stop nodes\n",
    "def generate_route(source, next_nodes, stop_nodes_kd_tree, max_walking_dist, connection_type, max_stops, network_graph):\n",
    "    short_route_list = [] # List of nx.shortest_path results\n",
    "    totalDistance = 0\n",
    "    orig_node = source\n",
    "    num_stops = 0 # Count number of stops\n",
    "    \n",
    "    # CONFIGURATION\n",
    "    max_tries = 3 # This is the max number of tries before breaking the loop || To avoid longer runtimes\n",
    "    current_tries = 0\n",
    "\n",
    "    while totalDistance < MAX_DISTANCE and num_stops < max_stops:\n",
    "        \n",
    "        #print(f\"Selected node is {selected_node.getLat()}, {selected_node.getLong()}\")\n",
    "        disable_surrounding_nodes(next_nodes, stop_nodes_kd_tree, orig_node, max_walking_dist)\n",
    "        enabled_nodes = [n for n in next_nodes if n.enabled]\n",
    "        dest_node = get_enabled_node_with_highest_edge_probability(orig_node, enabled_nodes, connection_type) # Getting the destination node\n",
    "        \n",
    "        if (dest_node == None or dest_node.id == orig_node.id):\n",
    "            break\n",
    "        \n",
    "        next_nodes.remove(dest_node) # Remove it as a candidate\n",
    "        \n",
    "        connection_edge = network_graph.has_edge(orig_node.id, dest_node.id) # This is to check if there is already an existing edge. If true, then it should not connect\n",
    "        \n",
    "        if not nx.has_path(CITY_GRAPH, orig_node.id, dest_node.id) or connection_edge:\n",
    "            current_tries += 1\n",
    "            if current_tries == max_tries:\n",
    "                break\n",
    "        else:\n",
    "            shortest_route = nx.shortest_path(CITY_GRAPH, orig_node.id, dest_node.id)\n",
    "            distance_travelled = 0\n",
    "            # Get the total distance from point A to point B\n",
    "            for i in range(len(shortest_route)-1):\n",
    "                node_data = CITY_GRAPH.nodes[shortest_route[i]]\n",
    "                next_node_data = CITY_GRAPH.nodes[shortest_route[i+1]]\n",
    "                \n",
    "                distance_travelled += haversine(node_data['y'], node_data['x'], next_node_data['y'], next_node_data['x'])\n",
    "\n",
    "            # Checks if it does not exceed the max distance\n",
    "            if totalDistance + distance_travelled <= MAX_DISTANCE:\n",
    "                \n",
    "                # Updating local degree count used for connection probability\n",
    "                orig_node.degree += 1\n",
    "                dest_node.degree += 1\n",
    "                \n",
    "                totalDistance += distance_travelled\n",
    "                short_route_list.append(shortest_route)\n",
    "                num_stops += 1\n",
    "                \n",
    "                orig_node = dest_node # Now change the origin to the destination\n",
    "            else:\n",
    "                break\n",
    "    if len(short_route_list) > 2 and totalDistance > 7:\n",
    "        print(f\"# OF CONNECTIONS AND TOTAL DISTANCE: {len(short_route_list)} - {totalDistance}\")\n",
    "        return short_route_list\n",
    "    \n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Disable surrounding nodes\n",
    "def disable_surrounding_nodes(next_nodes, stop_nodes_kd_tree, source_node, max_distance):\n",
    "    source = (source_node.getLat(), source_node.getLong())\n",
    "    \n",
    "    for node in next_nodes:\n",
    "        point = (node.getLat(), node.getLong())\n",
    "        distance = geodesic(source, point).meters\n",
    "        if distance <= max_distance:\n",
    "            node.disable()\n",
    "        \n",
    "def get_enabled_node_with_highest_edge_probability(source_node, enabled_nodes, connection_type):\n",
    "    highest_edge_prob = 0\n",
    "    highest_edge_prob_node = None\n",
    "\n",
    "    for n in enabled_nodes:\n",
    "        edge_prob = get_edge_probability(source_node, n, len(enabled_nodes), connection_type)\n",
    "        if edge_prob > highest_edge_prob:\n",
    "            highest_edge_prob = edge_prob\n",
    "            highest_edge_prob_node = n\n",
    "\n",
    "    return highest_edge_prob_node\n",
    "\n",
    "# Probabilities of candidate nodes based on distance, area, node degree, and if transpo stop\n",
    "def get_edge_probability(source, destination, normalization_factor, connection_type):\n",
    "    source_coord = [source.getLat(), source.getLong()]\n",
    "    dest_coord = [destination.getLat(), destination.getLong()]\n",
    "\n",
    "    base_prob = exp(-(euclidean(source_coord, dest_coord))) / float(normalization_factor)\n",
    "\n",
    "    if connection_type == \"Default\":\n",
    "        if destination.isTranspo:\n",
    "            return base_prob * 2\n",
    "        return base_prob\n",
    "    elif connection_type == \"Area\":\n",
    "        if destination.isTranspo:\n",
    "            return base_prob * 2\n",
    "        # need to fine tune based on values of area\n",
    "        # getting the distribution of all areas would be computationally costly\n",
    "        return base_prob * (1 + (log(destination.getArea()) / destination.getArea()))\n",
    "    elif connection_type == \"Degree\":\n",
    "        if destination.isTranspo:\n",
    "            return base_prob * 2 * (1 + (destination.getDegree() / 10))\n",
    "        return base_prob * (1 + (destination.getDegree() / 10))\n",
    "\n",
    "def radius(stops):\n",
    "    circles = []\n",
    "    for stop in stops:\n",
    "        stop_point = Point(stop[1], stop[0])  # Create a Point object from [lat, lon] coordinates\n",
    "        circle = stop_point.buffer(radius / 111000)  # Buffer the Point to create a circle (assuming 1 degree is approximately 111000 meters)\n",
    "        circles.append(circle)\n",
    "    return circles\n",
    "\n",
    "def enable_stop_nodes(stop_nodes):\n",
    "    for n in stop_nodes:\n",
    "        n.enable()\n",
    "\n",
    "def all_nodes_disabled(stop_nodes):\n",
    "    return get_num_disabled(stop_nodes) == len(stop_nodes)\n",
    "\n",
    "def get_num_disabled(stop_nodes):\n",
    "    return sum(1 for n in stop_nodes if not n.enabled)\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Use geopy's geodesic function to calculate the distance\n",
    "    distance = geodesic((lat1, lon1), (lat2, lon2)).kilometers\n",
    "    return distance\n",
    "\n",
    "# Markers for visualization purposes\n",
    "def add_markers(used_stops, network_graph):\n",
    "    for stop in used_stops:\n",
    "        #popup_text = f\"Name: {stop.name}<br>Type: {stop.a_type}<br>Coordinates: {stop.getLat()}, {stop.getLong()}\"\n",
    "        lat = network_graph.nodes[stop]['lat']\n",
    "        long = network_graph.nodes[stop]['lon']\n",
    "        folium.Marker(location=[lat, long]).add_to(m)\n",
    "        \n",
    "def add_stops_to_list(routes):\n",
    "    used_stops = []\n",
    "    for route in routes:\n",
    "        for conn in route:\n",
    "            if conn[0] not in used_stops:\n",
    "                used_stops.append(conn[0])\n",
    "            if conn[-1] not in used_stops:\n",
    "                used_stops.append(conn[-1])\n",
    "    return used_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: CONNECT THE ROUTE REVERSAL\n",
    "# Reverse route traversal\n",
    "def get_reverse_route(network):\n",
    "    reverse_route_network = []\n",
    "    \n",
    "    for route in network.routes:\n",
    "        index = len(route)-1\n",
    "        \n",
    "        reverse_route = []\n",
    "        totalDistance = 0\n",
    "        while index >= 0:\n",
    "            connection = route[index] # Get the connection\n",
    "            rev_origin = connection[-1]\n",
    "            rev_dest = connection[0]\n",
    "            \n",
    "            if nx.has_path(CITY_GRAPH, rev_origin, rev_dest):\n",
    "                rev_path = nx.shortest_path(CITY_GRAPH, rev_origin, rev_dest) # Get the path\n",
    "                \n",
    "                distance_travelled = 0\n",
    "                # Get the total distance from point A to point B\n",
    "                for i in range(len(rev_path)-1):\n",
    "                    node_data = CITY_GRAPH.nodes[rev_path[i]]\n",
    "                    next_node_data = CITY_GRAPH.nodes[rev_path[i+1]]\n",
    "                    distance_travelled += haversine(node_data['y'], node_data['x'], next_node_data['y'], next_node_data['x'])\n",
    "                    \n",
    "                totalDistance += distance_travelled\n",
    "                \n",
    "                reverse_route.append(rev_path)\n",
    "                index -= 1\n",
    "            else:\n",
    "                # there is no reverse route for this so append nothing to the \n",
    "                reverse_route_network.append([])\n",
    "                break\n",
    "    \n",
    "        # Checks if it does not exceed the max distance\n",
    "        if totalDistance <= MAX_DISTANCE:\n",
    "            reverse_route_network.append(reverse_route)\n",
    "        else:\n",
    "            reverse_route_network.append([])\n",
    "            \n",
    "    return reverse_route_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TODO: DELETE FOR TESTING ONLY\n",
    "# #Testing crossover and mutate\n",
    "\n",
    "# network1= list_of_networks[0]\n",
    "# network2= list_of_networks[1]\n",
    "\n",
    "# test_graph_net1 = network1.graph.copy()\n",
    "# test_routes_net1 = [copy.deepcopy(r) for r in network1.routes]\n",
    "# test_stops_net1 = network1.stops.copy()\n",
    "# copy_test_network1 = networkObj(test_routes_net1, test_stops_net1, test_graph_net1)\n",
    "\n",
    "# test_graph_net2 = network2.graph.copy()\n",
    "# test_routes_net2 = [copy.deepcopy(r) for r in network2.routes]\n",
    "# test_stops_net2 = network2.stops.copy()\n",
    "# copy_test_network2 = networkObj(test_routes_net2, test_stops_net2, test_graph_net2)\n",
    "\n",
    "# child1, child2 = crossover_split_index(copy_test_network1,copy_test_network2)\n",
    "\n",
    "# map_center = (14.599512, 120.984222)\n",
    "\n",
    "# # -----Child 1 Display -------------\n",
    "# m = folium.Map(location=map_center, zoom_start=1, tiles='openstreetmap')\n",
    "# add_markers(child1.stops, child1.graph)\n",
    "    \n",
    "# for route in child1.routes:\n",
    "#     for connection in route:\n",
    "#         ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "# m.save(f\"GA TEST/child1_crossover.html\")\n",
    "\n",
    "# # ------Child 2 Display ------------\n",
    "# m = folium.Map(location=map_center, zoom_start=1, tiles='openstreetmap')\n",
    "# add_markers(child2.stops, child2.graph)\n",
    "    \n",
    "# for route in child2.routes:\n",
    "#     for connection in route:\n",
    "#         ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "# m.save(f\"GA TEST/child2_crossover.html\")\n",
    "\n",
    "\n",
    "# # ---------Graph test---------------\n",
    "# # TODO: Delete FOR TESTING ONLY\n",
    "# unique_nodes_G1 = set(child1.graph.nodes) - set(child2.graph.nodes)\n",
    "# unique_edges_G1 = set(child1.graph.edges) - set(child2.graph.edges)\n",
    "\n",
    "# unique_nodes_G2 = set(child2.graph.nodes) - set(child1.graph.nodes)\n",
    "# unique_edges_G2 = set(child2.graph.edges) - set(child1.graph.edges)\n",
    "# print(\"TESTING DIFFERENCES BETWEEN Child1 AND Child2\")\n",
    "\n",
    "# # Display unique nodes and edges for G1\n",
    "# print(\"Unique nodes in child1 (not in child2):\")\n",
    "# for node in unique_nodes_G1:\n",
    "#     print(node)\n",
    "\n",
    "# print(\"Unique edges in child1 (not in child2):\")\n",
    "# for edge in unique_edges_G1:\n",
    "#     print(edge)\n",
    "\n",
    "# # Display unique nodes and edges for G2\n",
    "# print(\"Unique nodes in child2 (not in child1):\")\n",
    "# for node in unique_nodes_G2:\n",
    "#     print(node)\n",
    "\n",
    "# print(\"Unique edges in child2 (not in child1):\")\n",
    "# for edge in unique_edges_G2:\n",
    "#     print(edge)\n",
    "\n",
    "# # --------Mutate test --------------\n",
    "# for i in range(5):\n",
    "#     mutate(child1)\n",
    "#     mutate(child2)\n",
    "\n",
    "#     # -----Child 1 Mutation Display -------------\n",
    "#     m = folium.Map(location=map_center, zoom_start=1, tiles='openstreetmap')\n",
    "#     add_markers(child1.stops, child1.graph)\n",
    "        \n",
    "#     for route in child1.routes:\n",
    "#         for connection in route:\n",
    "#             ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "#     m.save(f\"GA TEST/child1_mutation{i}.html\")\n",
    "\n",
    "#     # ------Child 2 Mutation Display ------------\n",
    "#     m = folium.Map(location=map_center, zoom_start=1, tiles='openstreetmap')\n",
    "#     add_markers(child2.stops, child2.graph)\n",
    "        \n",
    "#     for route in child2.routes:\n",
    "#         for connection in route:\n",
    "#             ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "#     m.save(f\"GA TEST/child2_mutation{i}.html\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This implementation takes only 2 parents from the whole generation and generates the population from them\n",
    "# Instead of the what's in the paper that says the whole population will go through crossovers and mutations\n",
    "# Cite Nayeem et al for GA with elitism and growing population size\n",
    "def perform_genetic_algorithm(network_population, population_size, num_elites, num_generations, mutation_probability, \n",
    "                              num_mutations_probabilities, num_crossovers_probabilities, mutation_threshold_dist, num_failure_removal,\n",
    "                                      weight_random_failure, weight_targeted_failure, weight_connectivity,\n",
    "                              with_elitism=False, with_growing_population=False, num_mutations_per_generation=1):\n",
    "    \n",
    "    \n",
    "    # Do this for the assigned number of generations for the GA\n",
    "    for i in range(num_generations):\n",
    "        print(\"NEW NETWORK POPULATION\", flush=True)\n",
    "        new_network_population = []\n",
    "\n",
    "        # Evaluate the fitness of each network in the population\n",
    "        for network in network_population:\n",
    "            road_snapped_network_graph = network.graph\n",
    "            network.fitness_score = compute_fitness_score(road_snapped_network_graph, num_failure_removal,\n",
    "                          weight_random_failure, weight_targeted_failure, weight_connectivity)\n",
    "            print(\"Network score: \", network.fitness_score, flush=True)\n",
    "        sorted_network_population = sorted(network_population, key=lambda x: x.fitness_score, reverse=True)\n",
    "        \n",
    "        # Most naive selection approach: get top two scoring networks as parents\n",
    "        # But should be random with weighted probabilities so that elites are not always parents\n",
    "        \"\"\"\n",
    "        parent1 = sorted_network_population[0]\n",
    "        parent2 = sorted_network_population[1]\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"Choosing parents: \", flush=True)\n",
    "        # Roulette Wheel Selection \n",
    "        # Chromosomes with higher fitness have a bigger \"slice of the pie\", but are not \n",
    "        # guaranteed to be selected as parents\n",
    "        # This is to prevent premature convergence and ensure that the best networks are not always selected as parents\n",
    "        \n",
    "        fitness_scores = [network.fitness_score for network in sorted_network_population]\n",
    "        min_score = min(fitness_scores)\n",
    "        if min_score < 0: # Shift the scores to ensure all are positive\n",
    "            fitness_scores = [score - min_score for score in fitness_scores]\n",
    "        max = sum(fitness_scores)\n",
    "        selection_p = [score / max for score in fitness_scores]\n",
    "        \n",
    "        parent1 = np.random.choice(sorted_network_population, 1, p=selection_p)[0]\n",
    "        print(\"parent1 score, \", parent1.fitness_score, flush=True)\n",
    "        sorted_network_population.remove(parent1)\n",
    "        \n",
    "        fitness_scores = [network.fitness_score for network in sorted_network_population]\n",
    "        min_score = min(fitness_scores)\n",
    "        if min_score < 0: # Shift the scores to ensure all are positive\n",
    "            fitness_scores = [score - min_score for score in fitness_scores]\n",
    "        max = sum(fitness_scores)\n",
    "        selection_p = [score / max for score in fitness_scores]\n",
    "        \n",
    "        parent2 = np.random.choice(sorted_network_population, 1, p=selection_p)[0]\n",
    "        print(\"parent2 score, \", parent2.fitness_score, flush=True)\n",
    "        sorted_network_population.append(parent1)\n",
    "        sorted_network_population = sorted(network_population, key=lambda x: x.fitness_score, reverse=True)\n",
    "\n",
    "\n",
    "        # Take num_elites number of the best networks and automatically add them to the next generation\n",
    "        if (with_elitism):\n",
    "            for i in range(num_elites):\n",
    "                new_network_population.append(sorted_network_population[i])\n",
    "\n",
    "        # Ex: population_size = 20 and num_elites = 2\n",
    "        # If no elitism and no growing population, then we will have 10 iterations to produce 20 in the next generation\n",
    "        # Also, if elitism and growing population, then we will have 10 iterations to produce 22 in the next generation\n",
    "        if (not with_elitism and not with_growing_population or with_elitism and with_growing_population):\n",
    "            num_iterations = int(population_size / 2)\n",
    "\n",
    "        # If with elitism only, maintain the population size and account for the already added elites\n",
    "        elif (with_elitism):  \n",
    "            num_iterations = int((population_size - num_elites) / 2)\n",
    "            \n",
    "        \n",
    "\n",
    "        print(\"GETTING CHILDREN\", flush=True)\n",
    "        # Generate the population\n",
    "        for i in range(num_iterations):\n",
    "            \n",
    "            # Get 2 children from crossovers between the two parents\n",
    "            child1, child2 = crossover_split_index(parent1, parent2)\n",
    "            #child1, child2 = crossover_swap_routes(parent1, parent2, num_crossovers_probabilities)\n",
    "            print(\"FINISHED CROSSOVER\", flush=True)\n",
    "            \n",
    "            index_array = list(range(len(num_mutations_probabilities)))\n",
    "            num_mutations = np.random.choice(index_array, 1, p=num_mutations_probabilities)[0]\n",
    "\n",
    "            for j in range(num_mutations):\n",
    "                # Apply mutations to the children based on mutation probability hyperparameter\n",
    "                if np.random.rand() < mutation_probability:\n",
    "                    mutate(child1)\n",
    "                    print(\"MUTATION 1 DONE\", flush=True)\n",
    "                    \n",
    "                if np.random.rand() < mutation_probability:\n",
    "                    mutate(child2)\n",
    "                    print(\"MUTATION 2 DONE\", flush=True)\n",
    "            \n",
    "            # Add the children to the new population\n",
    "            new_network_population.append(child1)\n",
    "            new_network_population.append(child2)\n",
    "            print(\"ADDED CHILDREN\", flush=True)\n",
    "        # Assign to next generation\n",
    "        network_population = new_network_population\n",
    "        print()\n",
    "\n",
    "    return network_population\n",
    "\n",
    "# This crossover implementation splits both networks at an index and exchanges halves\n",
    "# Assumes that ideally both networks have the same number of routes (same length)\n",
    "def crossover_split_index(network1, network2):\n",
    "    # Split both networks at a random index\n",
    "    # network.routes is a list of routes or list of lists of shortest_path\n",
    "    if len(network1.routes) < len(network2.routes):\n",
    "        split_index = random.randint(0, len(network2.routes)-1)\n",
    "    else:\n",
    "        split_index = random.randint(0, len(network1.routes)-1)\n",
    "        \n",
    "    # Create new graphs for the left and right sides\n",
    "    route_graph1 = nx.Graph()\n",
    "    route_graph2 = nx.Graph()\n",
    "    \n",
    "    route_network1 = []\n",
    "    route_network2 = []\n",
    "    \n",
    "    used_stops1 = []\n",
    "    used_stops2 = []\n",
    "    \n",
    "    count = 0\n",
    "    for route in network1.routes:\n",
    "        if count < split_index: # if 0-split_index -> child1 graph\n",
    "            for connection in route:\n",
    "                route_graph1.add_node(connection[0], **network1.graph.nodes[connection[0]])\n",
    "                if connection[0] not in used_stops1:\n",
    "                    used_stops1.append(connection[0])\n",
    "                    \n",
    "                route_graph1.add_node(connection[-1], **network1.graph.nodes[connection[-1]])\n",
    "                if connection[-1] not in used_stops1:\n",
    "                    used_stops1.append(connection[-1])\n",
    "                \n",
    "                route_graph1.add_edge(connection[0], connection[-1], **network1.graph.get_edge_data(connection[0], connection[-1]))\n",
    "            route_network1.append(route.copy())\n",
    "            \n",
    "                \n",
    "        else: # else its for child2 graph\n",
    "            for connection in route:\n",
    "                route_graph2.add_node(connection[0], **network1.graph.nodes[connection[0]])\n",
    "                if connection[0] not in used_stops2:\n",
    "                    used_stops2.append(connection[0])\n",
    "                    \n",
    "                route_graph2.add_node(connection[-1], **network1.graph.nodes[connection[-1]])\n",
    "                if connection[-1] not in used_stops2:\n",
    "                    used_stops2.append(connection[-1])\n",
    "                \n",
    "                route_graph2.add_edge(connection[0], connection[-1], **network1.graph.get_edge_data(connection[0], connection[-1]))\n",
    "            route_network2.append(route.copy())\n",
    "        count += 1\n",
    "        \n",
    "    count = 0\n",
    "    for route in network2.routes:\n",
    "        if count >= split_index: # if split_index-end -> child1 graph\n",
    "            for connection in route:\n",
    "                route_graph1.add_node(connection[0], **network2.graph.nodes[connection[0]])\n",
    "                if connection[0] not in used_stops1:\n",
    "                    used_stops1.append(connection[0])\n",
    "                    \n",
    "                route_graph1.add_node(connection[-1], **network2.graph.nodes[connection[-1]])\n",
    "                if connection[-1] not in used_stops1:\n",
    "                    used_stops1.append(connection[-1])\n",
    "                \n",
    "                route_graph1.add_edge(connection[0], connection[-1], **network2.graph.get_edge_data(connection[0], connection[-1]))\n",
    "            route_network1.append(route.copy())\n",
    "                \n",
    "                \n",
    "        else: # else its for child2 graph\n",
    "            for connection in route:\n",
    "                route_graph2.add_node(connection[0], **network2.graph.nodes[connection[0]])\n",
    "                if connection[0] not in used_stops2:\n",
    "                    used_stops2.append(connection[0])\n",
    "                    \n",
    "                route_graph2.add_node(connection[-1], **network2.graph.nodes[connection[-1]])\n",
    "                if connection[-1] not in used_stops2:\n",
    "                    used_stops2.append(connection[-1])\n",
    "                \n",
    "                route_graph2.add_edge(connection[0], connection[-1], **network2.graph.get_edge_data(connection[0], connection[-1]))\n",
    "            route_network2.append(route.copy())\n",
    "        count += 1\n",
    "    \n",
    "    child1 = networkObj(route_network1, used_stops1, route_graph1)\n",
    "    child2 = networkObj(route_network2, used_stops2, route_graph2)\n",
    "    \n",
    "    print(\"* Checking Child 1 for errors:\", flush=True)\n",
    "    # TODO: DELETE FOR TESTING IF GRAPH IS CONSISTENT WITH ITS LIST OF ROUTES\n",
    "    print(\"Checking for graph and route consistency...\", flush=True)\n",
    "    check_graph_with_route(child1)\n",
    "    print(\"Checking for graph and list of stops consistency...\", flush=True)\n",
    "    check_graph_with_stops(child1)\n",
    "    print(\"Checking if order of routes is correct...\", flush=True)\n",
    "    check_order_route(child1.routes)\n",
    "    print(\"Checking for list of stops and route consistency...\", flush=True)\n",
    "    check_stops_routes(child1)\n",
    "    print()\n",
    "    \n",
    "    print(\"* Checking Child 2 for errors:\", flush=True)\n",
    "    # TODO: DELETE FOR TESTING IF GRAPH IS CONSISTENT WITH ITS LIST OF ROUTES\n",
    "    print(\"Checking for graph and route consistency...\", flush=True)\n",
    "    check_graph_with_route(child2)\n",
    "    print(\"Checking for graph and list of stops consistency...\", flush=True)\n",
    "    check_graph_with_stops(child2)\n",
    "    print(\"Checking if order of routes is correct...\", flush=True)\n",
    "    check_order_route(child2.routes)\n",
    "    print(\"Checking for list of stops and route consistency...\", flush=True)\n",
    "    check_stops_routes(child2)\n",
    "\n",
    "    return child1, child2\n",
    "\n",
    "\n",
    "# Modify the stop connections of a random route in the network\n",
    "# Randomly select a route and randomly select a stop in that route\n",
    "# Then randomly select another stop that is a not too far from the selected stop based on threshold\n",
    "# Swap connections with that stop\n",
    "def mutate(network_to_mutate):\n",
    "    global set_walk_distance, MAX_DISTANCE\n",
    "    \n",
    "    # This is to copy the original network to be compared later\n",
    "    test_graph_net2 = network_to_mutate.graph.copy()\n",
    "    test_routes_net2 = [copy.deepcopy(r) for r in network_to_mutate.routes]\n",
    "    test_stops_net2 = network_to_mutate.stops.copy()\n",
    "    copy_test_network = networkObj(test_routes_net2, test_stops_net2, test_graph_net2)\n",
    "    \n",
    "    # Randomly select a route\n",
    "    random_route = random.choice(network_to_mutate.routes)\n",
    "\n",
    "    \n",
    "    # TODO: This is a temporary solution, it chooses either of the connections within the route except for the first and last connection\n",
    "    # Randomly select a stop in the route\n",
    "    # random_node_connection = random.choice(random_route) # Choose a random connection in the route\n",
    "    index_array = list(range(1, len(random_route)-1))\n",
    "    connection_index = random.choice(index_array)\n",
    "    random_node_connection = random_route[connection_index]\n",
    "    \n",
    "    connection_stop_index = random.choice([0, -1]) # Choose whether the origin or destination node\n",
    "    random_stop = random_node_connection[connection_stop_index] # The random stop to be swapped\n",
    "    \n",
    "    print(\"PICKED NODE TO SWAP - \", random_stop)\n",
    "    \n",
    "    # Get the old total distance\n",
    "    old_total_distance = 0\n",
    "    for connection in random_route:\n",
    "        edge_data = network_to_mutate.graph.get_edge_data(connection[0], connection[-1])\n",
    "        \n",
    "        if edge_data == None:\n",
    "            print(\"-- ERROR MISSING EDGE INFORMATION: \", connection[0], \" - \", connection[-1])\n",
    "        else:\n",
    "            old_total_distance += edge_data['distance']\n",
    "    \n",
    "    \n",
    "    # This is to get the subset distance (Distance without the connection with chosen random stop)\n",
    "    if connection_stop_index == 0: # If it is the origin node in that connection (A, B, C and B is the chosen. Get B-C and A-B)\n",
    "        prev_connection = random_route[connection_index-1] # Get the previous connection\n",
    "        prev_node = prev_connection[0] # Get the origin node for that connection\n",
    "        distance1 = network_to_mutate.graph.get_edge_data(prev_node, random_stop)['distance'] # Get the distance of the previous connection\n",
    "        distance2 = network_to_mutate.graph.get_edge_data(random_stop, random_node_connection[-1])['distance'] # Get the distance of the current connection\n",
    "        distance_to_subtract = distance1 + distance2\n",
    "        \n",
    "        # Previous connection: node1 - random_node\n",
    "        # Current connection: random_node - node2\n",
    "        node1 = prev_node # Setting the partner nodes\n",
    "        node2 = random_node_connection[-1]\n",
    "        \n",
    "    else: #If it is the dest node in that connection\n",
    "        distance1 = network_to_mutate.graph.get_edge_data(random_node_connection[0], random_stop)['distance'] # Get the distance of the current connection\n",
    "        next_connection = random_route[connection_index+1] # Get the next route\n",
    "        next_node = next_connection[-1] # Get the destination node for the next connection\n",
    "        distance2 = network_to_mutate.graph.get_edge_data(random_stop, next_node)['distance']\n",
    "        distance_to_subtract = distance1 + distance2\n",
    "        \n",
    "        # Previous connection: node1 - random_node\n",
    "        # Current connection: random_node - node2\n",
    "        node2 = next_node\n",
    "        node1 = random_node_connection[0]\n",
    "        \n",
    "    subset_distance = old_total_distance - distance_to_subtract\n",
    "    # Get the route id\n",
    "    random_route_id = network_to_mutate.graph.get_edge_data(random_node_connection[0], random_node_connection[-1])['route_id']\n",
    "    \n",
    "    # Will try searching for a random stop 50 times (arbitrary)\n",
    "    for i in range(50):\n",
    "        # Get a random stop\n",
    "        new_random_stop, new_random_stop_data = random.choice(list(graph_of_stops.nodes(data=True)))\n",
    "        \n",
    "        # Check if the new random stop is not within walking distance with the other stop in the route\n",
    "        # Walking distance between node1 in route and stop to be swapped with\n",
    "        source = (new_random_stop_data['lat'], new_random_stop_data['lon'])\n",
    "        point = (graph_of_stops.nodes[node1]['lat'], graph_of_stops.nodes[node1]['lon'])\n",
    "        walking_distance1 = geodesic(source, point).meters\n",
    "        \n",
    "        # Walking distance between node2 in route and stop to be swapped with\n",
    "        source = (new_random_stop_data['lat'], new_random_stop_data['lon'])\n",
    "        point = (graph_of_stops.nodes[node2]['lat'], graph_of_stops.nodes[node2]['lon'])\n",
    "        walking_distance2 = geodesic(source, point).meters\n",
    "        \n",
    "        # Check if it already has been used in the route\n",
    "        isCandidate = True\n",
    "        for connection in random_route:\n",
    "            if new_random_stop == connection[0] or new_random_stop == connection[-1]:\n",
    "                isCandidate = False\n",
    "                print(\"NEW NODE WAS ALREADY USED\", flush=True)\n",
    "                break\n",
    "        \n",
    "        # If it is not within walking distances, has not been used in the route, and has a path\n",
    "        if walking_distance1 >= set_walk_distance and walking_distance2 >= set_walk_distance and isCandidate and nx.has_path(CITY_GRAPH, node1, new_random_stop) and nx.has_path(CITY_GRAPH, new_random_stop, node2):\n",
    "            # DISTANCE 1: Get the total distance from point A to point B\n",
    "            shortest_route1 = nx.shortest_path(CITY_GRAPH, node1, new_random_stop)\n",
    "            distance_travelled1 = 0\n",
    "            for i in range(len(shortest_route1)-1):\n",
    "                node_data = CITY_GRAPH.nodes[shortest_route1[i]]\n",
    "                next_node_data = CITY_GRAPH.nodes[shortest_route1[i+1]]\n",
    "                distance_travelled1 += haversine(node_data['y'], node_data['x'], next_node_data['y'], next_node_data['x'])\n",
    "            \n",
    "            # DISTANCE 2: Get the total distance from point A to point B\n",
    "            shortest_route2 = nx.shortest_path(CITY_GRAPH, new_random_stop, node2)\n",
    "            distance_travelled2 = 0\n",
    "            for i in range(len(shortest_route2)-1):\n",
    "                node_data = CITY_GRAPH.nodes[shortest_route2[i]]\n",
    "                next_node_data = CITY_GRAPH.nodes[shortest_route2[i+1]]\n",
    "                distance_travelled2 += haversine(node_data['y'], node_data['x'], next_node_data['y'], next_node_data['x'])\n",
    "                \n",
    "            \n",
    "            # If its within the 15km distance, then this new stop can be used\n",
    "            if subset_distance + distance_travelled1 + distance_travelled2 <= MAX_DISTANCE:\n",
    "                # Add the new stop to the used stops\n",
    "                network_to_mutate.stops.append(new_random_stop)\n",
    "                \n",
    "                # Modify the graph by adding the new node\n",
    "                network_to_mutate.graph.add_node(new_random_stop, **graph_of_stops.nodes[new_random_stop])\n",
    "                print(\"MUTATION: ADDED NEW NODE TO GRAPH \", new_random_stop)\n",
    "                \n",
    "                # Connect the new stop to the edges\n",
    "                name1 = f\"{shortest_route1[0]}_{shortest_route1[-1]}\"\n",
    "                name2 = f\"{shortest_route2[0]}_{shortest_route2[-1]}\"\n",
    "                connection_count1 = network_to_mutate.graph.get_edge_data(node1, random_stop)['edge_id']\n",
    "                connection_count2 = network_to_mutate.graph.get_edge_data(random_stop, node2)['edge_id']\n",
    "                network_to_mutate.graph.add_edge(shortest_route1[0], shortest_route1[-1], road_path=shortest_route1, edge_name=name1, edge_id = connection_count1, route_id = random_route_id, distance = distance_travelled1) # Add edge\n",
    "                network_to_mutate.graph.add_edge(shortest_route2[0], shortest_route2[-1], road_path=shortest_route2, edge_name=name2, edge_id = connection_count2, route_id = random_route_id, distance = distance_travelled2) # Add edge \n",
    "                \n",
    "                #TODO: DELETE PRINT FOR TESTING\n",
    "                print(\"MUTATION: CONNECTED NEW STOP TO EDGES\")  \n",
    "                \n",
    "                # Remove the old connections and node if it has no other connections\n",
    "                network_to_mutate.graph.remove_edge(node1, random_stop)\n",
    "                network_to_mutate.graph.remove_edge(random_stop, node2)\n",
    "                print(\"MUTATION: REMOVED OLD CONNECTIONS TO NODE\")\n",
    "                if (network_to_mutate.graph.degree(random_stop) == 0):\n",
    "                    network_to_mutate.graph.remove_node(random_stop)                \n",
    "                    network_to_mutate.stops.remove(random_stop)\n",
    "                    \n",
    "                    print(\"MUTATION: REMOVED OLD NODE \", random_stop)\n",
    "                else:\n",
    "                    print(\"MUTATION: DIDNT REMOVED OLD NODE \", random_stop)\n",
    "                \n",
    "                # TODO: Delete FOR TESTING ONLY\n",
    "                unique_nodes_G1 = set(copy_test_network.graph.nodes) - set(network_to_mutate.graph.nodes)\n",
    "                unique_edges_G1 = set(copy_test_network.graph.edges) - set(network_to_mutate.graph.edges)\n",
    "\n",
    "                unique_nodes_G2 = set(network_to_mutate.graph.nodes) - set(copy_test_network.graph.nodes)\n",
    "                unique_edges_G2 = set(network_to_mutate.graph.edges) - set(copy_test_network.graph.edges)\n",
    "                print(\"TESTING DIFFERENCES BETWEEN ORIGINAL AND OLD GRAPH\")\n",
    "                \n",
    "                # Display unique nodes and edges for G1\n",
    "                print(\"Unique nodes in original (not in new):\")\n",
    "                for node in unique_nodes_G1:\n",
    "                    print(node)\n",
    "\n",
    "                print(\"Unique edges in original (not in new):\")\n",
    "                for edge in unique_edges_G1:\n",
    "                    print(edge)\n",
    "\n",
    "                # Display unique nodes and edges for G2\n",
    "                print(\"Unique nodes in new (not in original):\")\n",
    "                for node in unique_nodes_G2:\n",
    "                    print(node)\n",
    "\n",
    "                print(\"Unique edges in new (not in original):\")\n",
    "                for edge in unique_edges_G2:\n",
    "                    print(edge)\n",
    "                \n",
    "                # Modify the route\n",
    "                if connection_stop_index == 0: #If its the origin node\n",
    "                    random_route[connection_index-1] = shortest_route1 # Change the previous connection\n",
    "                    random_route[connection_index] = shortest_route2 # Change the current connection\n",
    "                    \n",
    "                    #TODO: DELETE FOR TESTING\n",
    "                    random_route2 = copy_test_network.routes[network_to_mutate.routes.index(random_route)]\n",
    "                    print(\"ORIGINAL: \", random_route2[connection_index-1][0], \" - \", random_route2[connection_index-1][-1])\n",
    "                    print(\"ORIGINAL: \", random_route2[connection_index][0], \" - \", random_route2[connection_index][-1])\n",
    "                    print(\"MODIFIED: \", random_route[connection_index-1][0], \" - \", random_route[connection_index-1][-1])\n",
    "                    print(\"MODIFIED: \", random_route[connection_index][0], \" - \", random_route[connection_index][-1])\n",
    "                    \n",
    "                else: #else If its the dest node\n",
    "                    random_route[connection_index] = shortest_route1 # Change the current connection\n",
    "                    random_route[connection_index+1] = shortest_route2 # Change the next connection\n",
    "                    \n",
    "                    #TODO: DELETE FOR TESTING\n",
    "                    random_route2 = copy_test_network.routes[network_to_mutate.routes.index(random_route)]\n",
    "                    print(\"ORIGINAL: \", random_route2[connection_index][0], \" - \", random_route2[connection_index][-1])\n",
    "                    print(\"ORIGINAL: \", random_route2[connection_index+1][0], \" - \", random_route2[connection_index+1][-1])\n",
    "                    print(\"MODIFIED: \", random_route[connection_index][0], \" - \", random_route[connection_index][-1])\n",
    "                    print(\"MODIFIED: \", random_route[connection_index+1][0], \" - \", random_route[connection_index+1][-1])\n",
    "                    \n",
    "                print(\"MUTATION: MODIFIED THE NETWORK OBJECT'S ROUTE\")\n",
    "                \n",
    "                        \n",
    "                # TODO: DELETE FOR TESTING IF GRAPH IS CONSISTENT WITH ITS LIST OF ROUTES\n",
    "                print(\"Checking for graph and route consistency...\")\n",
    "                check_graph_with_route(network_to_mutate)\n",
    "                print(\"Checking for graph and list of stops consistency...\")\n",
    "                check_graph_with_stops(network_to_mutate)\n",
    "                print(\"Checking if order of routes is correct...\")\n",
    "                check_order_route(network_to_mutate.routes)\n",
    "                print(\"Checking for list of stops and route consistency...\")\n",
    "                check_stops_routes(network_to_mutate)\n",
    "                \n",
    "                \n",
    "                # Break the loop once we swap\n",
    "                print()\n",
    "                break  \n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitness Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitness function\n",
    "\n",
    "def select_highest_scoring_mutation(candidate_road_snapped_networks, num_failure_removal,\n",
    "                                    weight_random_failure, weight_targeted_failure, weight_radius_of_gyration):\n",
    "    max_fitness_score = -np.inf\n",
    "    max_candidate_route_snapped_network = None\n",
    "\n",
    "    for n in candidate_road_snapped_networks:\n",
    "        fitness_score = compute_fitness_score(n, num_failure_removal,\n",
    "                                              weight_random_failure, weight_targeted_failure, weight_radius_of_gyration)\n",
    "        if fitness_score > max_fitness_score:\n",
    "            max_fitness_score = fitness_score\n",
    "            max_candidate_route_snapped_network = n\n",
    "\n",
    "    return max_candidate_route_snapped_network\n",
    "\n",
    "def compute_fitness_score(road_snapped_network_graph, num_failure_removal,\n",
    "                          weight_random_failure, weight_targeted_failure, weight_connectivity):\n",
    "\n",
    "    random_failure_robustness = compute_random_failure_robustness(road_snapped_network_graph, num_failure_removal)\n",
    "    weighted_random_failure_robustness = weight_random_failure * random_failure_robustness\n",
    "\n",
    "    targeted_failure_robustness = compute_targeted_failure_robustness(road_snapped_network_graph, num_failure_removal)\n",
    "    weighted_targeted_failure_robustness = weight_targeted_failure * targeted_failure_robustness\n",
    "\n",
    "    connectivity_score = compute_connectivity(road_snapped_network_graph)\n",
    "    weighted_connectivity = weight_connectivity * connectivity_score\n",
    "    \n",
    "    #print(\"Random Failure Score: \", weighted_random_failure_robustness)\n",
    "    #print(\"Target Failure Score: \", weighted_targeted_failure_robustness)\n",
    "    #print(\"Connectivity: \", weighted_radius_of_gyration)\n",
    "\n",
    "    # Will use this return for now to utilize target and random failure nodes \n",
    "    return weighted_connectivity - weighted_random_failure_robustness - weighted_targeted_failure_robustness\n",
    "    # return weighted_radius_of_gyration\n",
    "\n",
    "\n",
    "### WRITTEN IN PSEUDOCODE\n",
    "def compute_connectivity(network):\n",
    "    # External connectivity - measure how connected is the jeepney route network with other modes of transpo\n",
    "    \n",
    "    # Get the ratio of transportation stops to total stops in the network\n",
    "    transpo_stops = [node for node, node_data in network.nodes(data=True) if node_data['isTranspo'] == True]\n",
    "    total_stops = len(network.nodes(data=True))\n",
    "    transpo_stop_ratio = len(transpo_stops) / total_stops\n",
    "\n",
    "    # Get the average degree of all transportation stops in the network\n",
    "    if len(transpo_stops) > 0:\n",
    "        avg_transpo_degree = sum(network.degree(stop) for stop in transpo_stops) / len(transpo_stops)\n",
    "    else:\n",
    "        avg_transpo_degree = 1\n",
    "\n",
    "    # Find a way to normalize the two values and combine them \n",
    "\n",
    "    # Internal connectivity - measure how connected is each jeepney route to other jeepney routes\n",
    "                    \n",
    "    # This counts how many nodes have intersections (Meaning node is connected to more than one route by route ID)\n",
    "    num_intersections = 0\n",
    "    for node, node_data in network.nodes(data=True):\n",
    "        connected_edges = network.edges(node)\n",
    "        unique_route_id = []\n",
    "        \n",
    "        for edge in connected_edges:\n",
    "            route_id = network[edge[0]][edge[1]]['route_id']\n",
    "            \n",
    "            if route_id not in unique_route_id:\n",
    "                unique_route_id.append(route_id)\n",
    "                \n",
    "        if len(unique_route_id) > 1:\n",
    "            num_intersections += 1\n",
    "\n",
    "    \n",
    "    # Change these weights based on what the expected values for \n",
    "    # the transpo_stop_ratio, avg_transpo_degree, and num_intersections will be\n",
    "    external_weight = 0.5\n",
    "    internal_weight = 0.5\n",
    "    \n",
    "    # TODO: Delete this\n",
    "    #print(\"Transpo stop ratio: \", transpo_stop_ratio)\n",
    "    #print(\"Num intersections: \", num_intersections)\n",
    "    #print(\"Average degree: \", avg_transpo_degree)\n",
    "\n",
    "    # Formula subject to change\n",
    "    return external_weight * (transpo_stop_ratio * avg_transpo_degree) + internal_weight * num_intersections\n",
    "\n",
    "\n",
    "def compute_random_failure_robustness(road_snapped_network_graph, num_removals):\n",
    "    graph_copy = road_snapped_network_graph.copy() # Make a copy\n",
    "    \n",
    "    for i in range(num_removals):\n",
    "        selected_node = random.choice(list(graph_copy.nodes()))\n",
    "        graph_copy.remove_node(selected_node)\n",
    "\n",
    "    diameter, avg_path_length = compute_network_statistics(graph_copy)\n",
    "    return compute_failure_robustness(graph_copy, diameter)\n",
    "\n",
    "def compute_targeted_failure_robustness(road_snapped_network_graph, num_removals):\n",
    "    graph_copy = road_snapped_network_graph.copy() # Make a copy\n",
    "    \n",
    "    for i in range(num_removals):\n",
    "        node_degrees = graph_copy.degree()\n",
    "        # Iterate over the DegreeView object to find the maximum degree\n",
    "        max_degree = max(degree for _, degree in node_degrees)\n",
    "        max_degree_node = get_node_with_degree(node_degrees, max_degree)\n",
    "        graph_copy.remove_node(max_degree_node)\n",
    "\n",
    "    diameter, avg_path_length = compute_network_statistics(graph_copy)\n",
    "    return compute_failure_robustness(graph_copy, diameter)\n",
    "\n",
    "def compute_failure_robustness(road_snapped_network_graph, max_path_length):\n",
    "    return float(max_path_length) / float(len(road_snapped_network_graph) - 1)\n",
    "\n",
    "def compute_network_statistics(road_snapped_network_graph):\n",
    "    path_lengths = get_path_lengths(road_snapped_network_graph) # Get the sum of all possible\n",
    "    avg_path_length = np.mean(path_lengths)\n",
    "    max_path_length = max(path_lengths)\n",
    "\n",
    "    #network_size = len(path_lengths)\n",
    "    #gcc = sorted(nx.connected_component_subgraphs(road_snapped_network_graph), key=len, reverse=True)\n",
    "    #giant_component_fraction = float(float(gcc[0].order()) / float(network_size))\n",
    "    #return max_path_length, avg_path_length, giant_component_fraction\n",
    "    return max_path_length, avg_path_length\n",
    "\n",
    "def get_node_with_degree(node_degrees, degree):\n",
    "    # Iterate over the DegreeView object to find the node with the specified degree\n",
    "    for node, _ in node_degrees:\n",
    "        if _ == degree:\n",
    "            return node\n",
    "    return None  # Return None if no node with the specified degree is found\n",
    "\n",
    "def get_path_lengths(snapped_road_network_graph):\n",
    "    return [sum(nx.single_source_shortest_path_length(snapped_road_network_graph, n).values())\n",
    "            for n in snapped_road_network_graph]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Error Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERROR Check - Checks if routes is consistent with its stops\n",
    "def check_stops_routes(network):\n",
    "    # Checks if each node in the route is in the list of stops\n",
    "    for route in network.routes:\n",
    "        for connection in route:\n",
    "            if connection[0] not in network.stops:\n",
    "                print(\"-- MISSING ROUTE ORIGIN STOP IN LIST OF STOPS \", connection[0])\n",
    "            if connection[-1] not in network.stops:\n",
    "                print(\"-- MISSING ROUTE DEST STOP IN LIST OF STOPS \", connection[-1])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: WORKING IN PROGRESS\n",
    "# # ERROR Check - Checks if there are no duplicate nodes in a route\n",
    "# def check_duplicate_stops_route(routes):\n",
    "#     for route in routes:\n",
    "#         for connection in route:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERROR Check - Checks if the routes are in correct order\n",
    "def check_order_route(routes):\n",
    "    for route in routes:\n",
    "        for connection in route:\n",
    "            if route.index(connection) > 0:\n",
    "                if connection[0] != prev_connection[-1]:\n",
    "                    print(\"-- WRONG ORDER DETECTED --\")\n",
    "                    print(prev_connection[0], \" - \", prev_connection[-1])\n",
    "                    print(connection[0], \" - \", connection[-1])\n",
    "                    print(\"--------------------------\")\n",
    "            prev_connection = connection\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERROR CHECK - Checks the consistency of the network with its routes\n",
    "def check_graph_with_route(_network):\n",
    "    for route in _network.routes:\n",
    "        for connection in route:\n",
    "            if not _network.graph.has_node(connection[0]):\n",
    "                print(\"-- MISSING NODE IN GRAPH: \", connection[0])\n",
    "            if not _network.graph.has_node(connection[-1]):\n",
    "                print(\"-- MISSING NODE IN GRAPH: \", connection[-1])\n",
    "            if not _network.graph.has_edge(connection[0], connection[-1]):\n",
    "                print(\"-- MISSING EDGE IN GRAPH: \", connection[0], \" - \", connection[-1])\n",
    "                \n",
    "            if _network.graph.get_edge_data(connection[0], connection[-1]) == None:\n",
    "                print(\"-- MISSING EDGE INFORMATION: \", connection[0], \" - \", connection[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERROR CHECK - Checks the consistency of the network with its list of stops\n",
    "def check_graph_with_stops(_network):\n",
    "    \n",
    "    # Checks if all stops in the list is in the graph\n",
    "    for stop in _network.stops:\n",
    "        if not _network.graph.has_node(stop):\n",
    "            print(\"-- MISSING LIST STOP IN GRAPH: \", stop)\n",
    "            \n",
    "    # Checks if all nodes in the graph are in the list\n",
    "    for node, node_data in _network.graph.nodes(data=True):\n",
    "        if node not in _network.stops:\n",
    "            print(\"-- MISSING GRAPH NODE IN LIST: \", node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Code Just in Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_radius_of_gyration(road_snapped_network_graph, num_random_values, weight):\n",
    "#     return _get_efficiency_sum(road_snapped_network_graph, num_random_values, weight)\n",
    "\n",
    "# def _get_efficiency_sum(graph, no_of_random_values, weight):\n",
    "#     efficiency_sum = 0.0\n",
    "#     weighted_list = _get_yweighted_list(graph, weight)\n",
    "#     efficiency_sum_list = random.sample(weighted_list.keys(), no_of_random_values)\n",
    "\n",
    "#     for k_x, k_y in efficiency_sum_list:\n",
    "#          temp = weighted_list[(str(k_x), str(k_y))]\n",
    "#          efficiency_sum = float(temp) + float(efficiency_sum)\n",
    "\n",
    "#     return efficiency_sum\n",
    "\n",
    "# def _get_yweighted_list(graph, weight):\n",
    "#     dp = _get_distance_individual(graph)\n",
    "#     dw = _get_total_weighted_distance(graph, weight)\n",
    "#     Y = {}\n",
    "\n",
    "#     for k_x, v_x in graph.nodes(data=True):\n",
    "#         for k_y, v_y in graph.nodes(data=True):\n",
    "#             if nx.has_path(CITY_GRAPH, k_x, k_y):\n",
    "#                 Y[(k_x, k_y)] = float(dp[(k_x, k_y)])/float(dw)\n",
    "#             else:\n",
    "#                 Y[(k_x, k_y)] = 0.0\n",
    "\n",
    "#     return Y\n",
    "\n",
    "# def _get_distance_individual(graph):\n",
    "#     T = {}\n",
    "\n",
    "#     for k_x, v_x in graph.nodes(data=True):\n",
    "#         for k_y, v_y in graph.nodes(data=True):\n",
    "#             if nx.has_path(CITY_GRAPH, k_x, k_y):\n",
    "#                 shortest_path_nodes = nx.shortest_path(CITY_GRAPH, k_x, k_y)\n",
    "#                 accumulated_distance = 0.0\n",
    "#                 if len(shortest_path_nodes) > 1:\n",
    "#                     for i in range(0, len(shortest_path_nodes) - 1):\n",
    "#                         edge = CITY_GRAPH.get_edge_data(shortest_path_nodes[i], shortest_path_nodes[i + 1]).get('dist', 0)\n",
    "#                         print(edge)\n",
    "#                         accumulated_distance += float(edge)\n",
    "#                     T[(k_x, k_y)] = accumulated_distance\n",
    "#                 else:\n",
    "#                     T[(k_x, k_y)] = 0\n",
    "#             else:\n",
    "#                 T[(k_x, k_y)] = 0\n",
    "\n",
    "#     return T\n",
    "\n",
    "# # new gettwd does not use weighted adjacency matrix\n",
    "# def _get_total_weighted_distance(graph, weight):\n",
    "#     # A = _create_weighted_adjacency_matrix(graph)\n",
    "#     dp = _get_distance_individual(graph)\n",
    "#     w = weight\n",
    "#     total_weighted_distance = 0.0\n",
    "#     T = {}\n",
    "#     for k_x, v_x in graph.nodes(data=True):\n",
    "#         for k_y, v_y in graph.nodes(data=True):\n",
    "#             if nx.has_path(CITY_GRAPH, k_x, k_y):\n",
    "#                 shortest_path_nodes = nx.shortest_path(CITY_GRAPH, k_x, k_y)\n",
    "#                 g = get_nodes_shortest_path(shortest_path_nodes, graph)\n",
    "#                 T = _get_no_of_transfers(g)\n",
    "#                 a = 1.0\n",
    "#             elif not nx.has_path(CITY_GRAPH, k_x, k_y):\n",
    "#                 a = 10.0\n",
    "\n",
    "#             b = float(dp[(k_x, k_y)])\n",
    "#             weighted_distance = a * b + (w * T)\n",
    "#             total_weighted_distance = float(total_weighted_distance) + float(weighted_distance)\n",
    "\n",
    "#     return total_weighted_distance\n",
    "\n",
    "\n",
    "\n",
    "# def get_nodes_shortest_path(shortest_path_nodes):\n",
    "#     new_graph = nx.Graph()\n",
    "\n",
    "#     for k_y, v_y in CITY_GRAPH.nodes(data=True):\n",
    "#         for elem in shortest_path_nodes:\n",
    "#             if elem == k_y:\n",
    "#                 new_graph.add_node(k_y, lat=v_y.get('lat'), lon=v_y.get('lon'), route_id = v_y.get('route_id'))\n",
    "\n",
    "#     return new_graph\n",
    "\n",
    "\n",
    "# def _get_no_of_transfers(graph):\n",
    "#     temp = []\n",
    "#     p = graph.copy()\n",
    "#     no_of_tranfer = 0\n",
    "\n",
    "#     for k_y, v_y in p.nodes(data=True):\n",
    "#         if (len(p.nodes()) > 1):\n",
    "#             if str(v_y.get(\"route_id\")) not in temp:\n",
    "#                 temp.append(str(v_y.get(\"route_id\")))\n",
    "#             no_of_transfer = len(temp)-1\n",
    "#         else:\n",
    "#             no_of_tranfer = 0\n",
    "\n",
    "#     return no_of_tranfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SNAPPING ROUTE NETWORK TO GRAPH\n",
    "# # NO UUID V1\n",
    "\n",
    "# def snap_route_network_to_road(route_network):\n",
    "#     location_road_nodes = [node for node, data in graph.nodes(data=True)]\n",
    "#     snapped_route_network = []\n",
    "#     snapped_route_network_graph = []\n",
    "    \n",
    "#     overall_graph = nx.Graph()\n",
    "\n",
    "#     route_id = 0\n",
    "#     for route in route_network:\n",
    "#         snapped_route = snap_route_to_road(location_road_nodes, route)\n",
    "#         snapped_route_network_graph.append(snapped_route)\n",
    "#         nx.set_edge_attributes(snapped_route, 'route_id', route_id)\n",
    "#         route_id += 1\n",
    "#         overall_graph = nx.compose(overall_graph, snapped_route)\n",
    "\n",
    "#         snapped_edges = list(snapped_route.edges(data='road_path', default=1))\n",
    "#         snapped_route = connect_snapped_edges(snapped_edges)\n",
    "#         snapped_route_network.append(snapped_route)\n",
    "        \n",
    "#     snapped_route_graph = nx.union_all(snapped_route_network_graph)\n",
    "\n",
    "#     return snapped_route_network, snapped_route_graph\n",
    "\n",
    "\n",
    "\n",
    "# def connect_snapped_edges(snapped_edges):\n",
    "#     connected_edge = []\n",
    "\n",
    "#     while len(snapped_edges) > 0:\n",
    "#         curr_edge = consecutive_connect([], snapped_edges.pop(0))\n",
    "\n",
    "#         for e in snapped_edges:\n",
    "#             consecutive_edge = consecutive_connect(curr_edge, e)\n",
    "#             if consecutive_edge is not None:\n",
    "#                 curr_edge = consecutive_edge\n",
    "#                 snapped_edges.remove(e)\n",
    "\n",
    "#         new_connected_edge = consecutive_connect(connected_edge, curr_edge)\n",
    "#         connected_edge = new_connected_edge if new_connected_edge is not None else connected_edge\n",
    "\n",
    "#     return connected_edge\n",
    "\n",
    "# def consecutive_connect(e1, e2):\n",
    "#     if len(e1) == 0:\n",
    "#         return e2\n",
    "#     elif len(e2) == 0:\n",
    "#         return e1\n",
    "\n",
    "#     if e1[-1] == e2[0]:\n",
    "#         return e1 + e2\n",
    "#     elif e2[-1] == e1[0]:\n",
    "#         return e2 + e1\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "# def snap_route_to_road(location_road_nodes, route_stop_nodes):\n",
    "#     snapped_route = nx.Graph()\n",
    "#     route_stops = [] # We need to store the list of stops as route_stop_nodes is only a list of ox.shortest_path results\n",
    "    \n",
    "    \n",
    "#     # Directly add nodes based on node identifiers\n",
    "#     for n in route_stop_nodes:\n",
    "#         snapped_route.add_node(n[0], **graph.nodes[n[0]])\n",
    "#         route_stops.append(n[0])\n",
    "#         last_path = n # For the sake of getting the last stop of the last stop connection\n",
    "        \n",
    "#     snapped_route.add_node(n[len(last_path)-1], **graph.nodes[n[len(last_path)-1]])\n",
    "#     route_stops.append(n[len(last_path)-1])\n",
    "\n",
    "#     # Add the shortest path for each consecutive node as an edge in the graph\n",
    "#     for i in range(len(route_stops) - 1):\n",
    "#         source_node = route_stops[i]\n",
    "#         dest_node = route_stops[i + 1]\n",
    "#         shortest_road_path = get_shortest_road_path(location_road_nodes, source_node, dest_node)\n",
    "#         snapped_route.add_edge(source_node, dest_node, road_path=shortest_road_path)\n",
    "#     return snapped_route\n",
    "\n",
    "# def get_shortest_road_path(location_road_nodes, source_stop_node, dest_stop_node):\n",
    "#     # Find the nearest nodes in the graph to the source and destination GeoPoints\n",
    "#     closest_road_node_to_source = ox.distance.nearest_nodes(graph, graph.nodes[source_stop_node]['x'], graph.nodes[source_stop_node]['y'])\n",
    "#     closest_road_node_to_dest = ox.distance.nearest_nodes(graph,  graph.nodes[dest_stop_node]['x'], graph.nodes[dest_stop_node]['y'])\n",
    "\n",
    "#     if nx.has_path(graph, closest_road_node_to_source, closest_road_node_to_dest):\n",
    "#         return nx.shortest_path(graph, closest_road_node_to_source, closest_road_node_to_dest)\n",
    "#     else:\n",
    "#         return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate Route Network from connected routes\n",
    "\n",
    "# # Global Variables used:\n",
    "# # graph_of_stops - Graph of stops that will be used to create routes\n",
    "# def generate_route_network(stop_nodes, max_walking_dist):\n",
    "#     stop_node_coordinates = [[n.lat, n.long] for n in stop_nodes]\n",
    "#     stop_nodes_kd_tree = KDTree(stop_node_coordinates)\n",
    "#     next_nodes = [n for n in stop_nodes]\n",
    "#     enable_stop_nodes(next_nodes)\n",
    "#     route_network = []\n",
    "\n",
    "#     #Create empty graph\n",
    "#     new_graph = graph_of_stops.copy() # Copy of Manila\n",
    "\n",
    "    \n",
    "#     while not all_nodes_disabled(next_nodes) and len(next_nodes) != 0:\n",
    "#         selected_node = random.choice(next_nodes) # For the first node\n",
    "#         next_nodes.remove(selected_node)\n",
    "#         used_stops.append(selected_node)\n",
    "        \n",
    "#         route_network.append(generate_route(selected_node, next_nodes, stop_nodes_kd_tree, max_walking_dist, new_graph))\n",
    "\n",
    "#     return route_network, new_graph\n",
    "\n",
    "# # Generate route from stop nodes\n",
    "# def generate_route(source, next_nodes, stop_nodes_kd_tree, max_walking_dist, new_graph):\n",
    "#     route = []\n",
    "#     totalDistance = 0\n",
    "#     selected_node = source\n",
    "\n",
    "#     while not all_nodes_disabled(next_nodes) and totalDistance < MAX_DISTANCE:\n",
    "        \n",
    "#         #print(f\"Selected node is {selected_node.getLat()}, {selected_node.getLong()}\")\n",
    "#         disable_surrounding_nodes(next_nodes, stop_nodes_kd_tree, selected_node, max_walking_dist)\n",
    "#         enabled_nodes = [n for n in next_nodes if n.enabled]\n",
    "#         orig_node = ox.distance.nearest_nodes(new_graph, selected_node.getLong(), selected_node.getLat()) # Getting the node from the graph itself\n",
    "#         old_node = selected_node\n",
    "#         selected_node = get_enabled_node_with_highest_edge_probability(selected_node, enabled_nodes)\n",
    "        \n",
    "#         if (selected_node == None or selected_node == old_node):\n",
    "#             break\n",
    "        \n",
    "#         next_nodes.remove(selected_node)\n",
    "#         dest_node = ox.distance.nearest_nodes(new_graph, selected_node.getLong(), selected_node.getLat())\n",
    "        \n",
    "#         if orig_node is None or dest_node is None:\n",
    "#             print(\"Unable to find valid nodes. Please verify the start and end coordinates.\")\n",
    "#         elif not nx.has_path(graph, orig_node, dest_node):\n",
    "#             print(\"No valid path found between the start and end nodes.\")\n",
    "#         else:\n",
    "            \n",
    "#             shortest_route = nx.shortest_path(graph, orig_node, dest_node)\n",
    "#             distance_travelled = 0\n",
    "#             # Get the total distance from point A to point B\n",
    "#             for i in range(len(shortest_route)-1):\n",
    "#                 node_data = graph.nodes[shortest_route[i]]\n",
    "#                 next_node_data = graph.nodes[shortest_route[i+1]]\n",
    "                \n",
    "#                 distance_travelled += haversine(node_data['y'], node_data['x'], next_node_data['y'], next_node_data['x'])\n",
    "\n",
    "#             # Checks if it does not exceed the max distance\n",
    "#             if totalDistance + distance_travelled <= MAX_DISTANCE:\n",
    "#                 # Add the nodes to the nx graph\n",
    "#                 new_graph.add_edge(orig_node, dest_node, weight=distance_travelled)\n",
    "                \n",
    "#                 totalDistance += distance_travelled\n",
    "#                 used_stops.append(selected_node)\n",
    "#                 route.append(shortest_route)\n",
    "#             else:\n",
    "#                 break\n",
    "#     return route\n",
    "\n",
    "# # Disable surrounding nodes\n",
    "# def disable_surrounding_nodes(next_nodes, stop_nodes_kd_tree, source_node, max_distance):\n",
    "#     source = (source_node.getLat(), source_node.getLong())\n",
    "    \n",
    "#     for node in next_nodes:\n",
    "#         point = (node.getLat(), node.getLong())\n",
    "#         distance = geodesic(source, point).meters\n",
    "#         if distance <= max_distance:\n",
    "#             node.disable()\n",
    "        \n",
    "# def get_enabled_node_with_highest_edge_probability(source_node, enabled_nodes):\n",
    "#     highest_edge_prob = 0\n",
    "#     highest_edge_prob_node = None\n",
    "\n",
    "#     for n in enabled_nodes:\n",
    "#         edge_prob = get_edge_probability(source_node, n, len(enabled_nodes))\n",
    "#         if edge_prob > highest_edge_prob:\n",
    "#             highest_edge_prob = edge_prob\n",
    "#             highest_edge_prob_node = n\n",
    "\n",
    "#     return highest_edge_prob_node\n",
    "\n",
    "\n",
    "# def get_edge_probability(source, destination, normalization_factor):\n",
    "#     source_coord = [source.getLat(), source.getLong()]\n",
    "#     dest_coord = [destination.getLat(), destination.getLong()]\n",
    "#     return exp(-(euclidean(source_coord, dest_coord))) / float(normalization_factor)\n",
    "\n",
    "\n",
    "# def radius(stops):\n",
    "#     circles = []\n",
    "#     for stop in stops:\n",
    "#         stop_point = Point(stop[1], stop[0])  # Create a Point object from [lat, lon] coordinates\n",
    "#         circle = stop_point.buffer(radius / 111000)  # Buffer the Point to create a circle (assuming 1 degree is approximately 111000 meters)\n",
    "#         circles.append(circle)\n",
    "#     return circles\n",
    "\n",
    "# def enable_stop_nodes(stop_nodes):\n",
    "#     for n in stop_nodes:\n",
    "#         n.enable()\n",
    "\n",
    "# def all_nodes_disabled(stop_nodes):\n",
    "#     return get_num_disabled(stop_nodes) == len(stop_nodes)\n",
    "\n",
    "# def get_num_disabled(stop_nodes):\n",
    "#     return sum(1 for n in stop_nodes if not n.enabled)\n",
    "\n",
    "\n",
    "\n",
    "# def haversine(lat1, lon1, lat2, lon2):\n",
    "#     # Use geopy's geodesic function to calculate the distance\n",
    "#     distance = geodesic((lat1, lon1), (lat2, lon2)).kilometers\n",
    "#     return distance\n",
    "\n",
    "# # Markers for visualization purposes\n",
    "# def add_markers(used_stops):\n",
    "#     for stop in used_stops:\n",
    "#         #popup_text = f\"Name: {stop.name}<br>Type: {stop.a_type}<br>Coordinates: {stop.getLat()}, {stop.getLong()}\"\n",
    "#         folium.Marker(location=[stop.road_lat, stop.road_long]).add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def connect_snapped_edges(snapped_edges):\n",
    "#     connected_edge = []\n",
    "\n",
    "#     while len(snapped_edges) > 0:\n",
    "#         curr_edge = consecutive_connect([], snapped_edges.pop(0))\n",
    "\n",
    "#         for e in snapped_edges:\n",
    "#             consecutive_edge = consecutive_connect(curr_edge, e)\n",
    "#             if consecutive_edge is not None:\n",
    "#                 curr_edge = consecutive_edge\n",
    "#                 snapped_edges.remove(e)\n",
    "\n",
    "#         new_connected_edge = consecutive_connect(connected_edge, curr_edge)\n",
    "#         connected_edge = new_connected_edge if new_connected_edge is not None else connected_edge\n",
    "\n",
    "#     return connected_edge\n",
    "\n",
    "\n",
    "# def consecutive_connect(e1, e2):\n",
    "#     if len(e1) == 0:\n",
    "#         return e2\n",
    "#     elif len(e2) == 0:\n",
    "#         return e1\n",
    "\n",
    "#     if e1[-1] == e2[0]:\n",
    "#         return e1 + e2\n",
    "#     elif e2[-1] == e1[0]:\n",
    "#         return e2 + e1\n",
    "#     else:\n",
    "#         return None\n",
    "\n",
    "\n",
    "\n",
    "# This crossover implementation randomly selects a route from each network and swaps them\n",
    "# More similar to the previous thesis implementation\n",
    "# num_crossovers_probabilities = list of probabilities for crossovers that will be randomly selected from\n",
    "#    e.g. [0.1, 0.2, 0.3, 0.4, 0.5] would mean a 0.1 probability for 0 crossovers, 0.2 probability for 1 crossover, etc\n",
    "# def crossover_swap_routes(network1, network2, num_crossovers_probabilities):\n",
    "#     num_crossovers = np.random.choice(len(num_crossovers_probabilities), 1, p=num_crossovers_probabilities)[0]\n",
    "\n",
    "#     for i in range(num_crossovers):\n",
    "#         # Randomly select a route from each network\n",
    "#         route1 = random.choice(network1.items())\n",
    "#         route2 = random.choice(network2.items())\n",
    "\n",
    "#         # Swap the routes\n",
    "#         network1[route1[0]] = route2[1]\n",
    "#         network2[route2[0]] = route1[1]\n",
    "\n",
    "#     return network1, network2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset of Manila Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATION OF MAIN CITY GRAPH\n",
    "# IF FIRST TIME RUNNING, RUN THIS CODE TO GENERATE THE GRAPH\n",
    "def generate_graph():\n",
    "    place = 'Manila, Philippines'\n",
    "    mode = 'drive'\n",
    "    graph = ox.graph_from_place(place, network_type = mode) # Generate graph of Metro manila\n",
    "    ox.save_graphml(graph, 'map/Manila.graphml') # Save it as a file\n",
    "\n",
    "def load_graph():\n",
    "    graph = ox.load_graphml('map/Manila.graphml')\n",
    "    \n",
    "    print(\"Graph loaded successfully\")\n",
    "    print(\"NUMBER OF EDGES: \", graph.number_of_edges())\n",
    "    print(\"NUMBER OF NODES: \", graph.number_of_nodes())\n",
    "    print('\\n')\n",
    "    return graph\n",
    "\n",
    "\n",
    "# THIS IS THE MAIN GRAPH FOR THE CITY TO BE USED FOR ALL FUNCTIONS\n",
    "CITY_GRAPH = load_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING INITIAL NETWORK\n",
    "\n",
    "manila_amenities_network = create_network(manila_amenities_polygon_gdf, manila_amenities_point_gdf)\n",
    "\n",
    "# Make a before map\n",
    "before_map = plot_network_on_map(manila_amenities_network, initial_location=[0, 0], zoom_start=100)\n",
    "before_map.save('before_map.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LEVEL 1 - CONNECTING POLYGONS OF SAME AMENITY\n",
    "\n",
    "combined_graph = combine_amenities_by_polygon(manila_amenities_network, max_distance=100, max_perimeter=10000)\n",
    "after_map = plot_network_on_map(combined_graph, initial_location=[0, 0], zoom_start=100)\n",
    "after_map.save('after_map.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKING POPULATION DENSITY OF RESIDENTIAL AREAS\n",
    "\n",
    "pop_graph = check_residential_population_density(graph=combined_graph, threshold=100)\n",
    "pop_map = plot_population_zones_map(pop_graph, initial_location=[0, 0], zoom_start=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 2 - CREATING NETWORKS OF AMENITIES\n",
    "\n",
    "graph_networks_of_polygons = create_zone_network(graph=combined_graph, max_distance=100)\n",
    "networks_map = plot_connected_zones_network_on_map(graph_networks_of_polygons, initial_location=[0, 0], zoom_start=100)\n",
    "networks_map.save('networks_map.html') # Save the map to an HTML file\n",
    "\n",
    "feature_collection = graph_to_geojson(manila_amenities_network, 'output.geojson')\n",
    "with open('output.geojson', 'w', encoding='utf-8') as f:\n",
    "    f.write(geojson.dumps(feature_collection, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placing Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 3 - CREATING STOPS TO BE PLACED ON ZONES\n",
    "graph_of_stops = nx.Graph()\n",
    "add_points_to_graph(manila_amenities_network, graph_networks_of_polygons) # Add first all transportation stops\n",
    "list_of_stops = []\n",
    "place_stops_on_roads(graph_networks_of_polygons, graph_of_stops, list_of_stops) # Adds stops graph_of_stops\n",
    "\n",
    "# Visualize the stops\n",
    "stops_map = plot_stops_on_map(networks_map, list_of_stops, initial_location=[0, 0], zoom_start=100)\n",
    "stops_map.save('stops_map.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export stops to pickle\n",
    "\n",
    "# Specify the file path where you want to save the pickle file\n",
    "file_path = 'stop_objects.pkl'\n",
    "\n",
    "# Open the file in binary write mode\n",
    "with open(file_path, 'wb') as f:\n",
    "    # Dump the list of stop objects into the pickle file\n",
    "    pickle.dump(list_of_stops, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LEVEL 4 - CONNECTING STOPS INTO A NETWORK\n",
    "WALKING_DISTANCES = [300,550,800]\n",
    "MAX_DISTANCE = 10\n",
    "CONNECTION_TYPES = [\"Default\", \"Area\", \"Degree\"]\n",
    "\n",
    "# Configuration\n",
    "set_walk_distance = WALKING_DISTANCES[0]\n",
    "num_of_networks = 10\n",
    "conn_type = CONNECTION_TYPES[0]\n",
    "max_stops = 20\n",
    "max_routes = 10\n",
    "map_html_location = \"Generated Route Networks HTML\"\n",
    "        \n",
    "# Generate route network\n",
    "list_of_networks = []\n",
    "\n",
    "for _ in range(num_of_networks):\n",
    "    route_count = 0 # Route is the connection between list of stops\n",
    "    connection_count = 0 # Connection is the connection between two stops / nodes\n",
    "    route_network, route_graph = generate_route_network(list_of_stops, set_walk_distance, max_stops, max_routes, conn_type) # Default max walking distance is 300m\n",
    "    used_stops = add_stops_to_list(route_network)\n",
    "    new_network = networkObj(route_network, used_stops, route_graph)\n",
    "    \n",
    "    # ERROR CHECKS----------\n",
    "    #print(\"Performing error checks...\")\n",
    "    #check_graph_with_route(new_network)\n",
    "    #check_graph_with_stops(new_network)\n",
    "    #check_order_route(new_network.routes)\n",
    "    \n",
    "    print()\n",
    "    # Append to list of networks\n",
    "    list_of_networks.append(new_network)\n",
    "\n",
    "\n",
    "#Export networks and graphs using pickl\n",
    "export_networks(list_of_networks, \"networks.pkl\")\n",
    "\n",
    "\n",
    "i = 1\n",
    "# Creating Maps for visualization\n",
    "for route_network in list_of_networks:\n",
    "    map_center = (14.599512, 120.984222)\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "\n",
    "    # Plotting in the Map\n",
    "    add_markers(route_network.stops, route_network.graph)\n",
    "        \n",
    "    for route in route_network.routes:\n",
    "        for connection in route:\n",
    "            ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "    m.save(f\"{map_html_location}/Map2-{i}.html\")\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import networks into list_of_networks\n",
    "# import pickl\n",
    "list_of_networks = import_networks(\"networks.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING GA ---------------------------------------------------------]\n",
    "# There should a pickle file already of the latest networks\n",
    "\n",
    "population_size = 10 # Default\n",
    "num_elites = 2\n",
    "num_generations = 5\n",
    "mutation_probability = 0.1\n",
    "num_mutations_probabilities = [0.1, 0.2, 0.3, 0.2, 0.2]\n",
    "num_crossovers_probabilities = [0.1, 0.2, 0.3, 0.2, 0.2]\n",
    "mutation_threshold_dist = 300\n",
    "with_elitism = False\n",
    "with_growing_population = False\n",
    "num_mutations_per_generation = 2\n",
    "\n",
    "#Weights and Fitness Function configuration\n",
    "num_failure_removal = 4\n",
    "weight_random_failure = 0.15\n",
    "weight_targeted_failure = 0.15\n",
    "weight_connectivity = 0.7\n",
    "\n",
    "population = perform_genetic_algorithm(list_of_networks, population_size, num_elites, num_generations, mutation_probability, \n",
    "                              num_mutations_probabilities, num_crossovers_probabilities, mutation_threshold_dist, num_failure_removal,\n",
    "                                      weight_random_failure, weight_targeted_failure, weight_connectivity,\n",
    "                              with_elitism, with_growing_population, num_mutations_per_generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Genetic Algorithm Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(population[5].routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "map_html_location = \"GA Result Route Networks HTML\"\n",
    "\n",
    "i = 1\n",
    "for network in population:\n",
    "    map_center = (14.599512, 120.984222)\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "    add_markers(network.stops, network.graph)\n",
    "    \n",
    "    for route in network.routes:\n",
    "        for connection in route:\n",
    "            ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "    m.save(f\"{map_html_location}/Map2-{i}.html\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manila Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READING DATA (All Amenities in Manila)\n",
    "merged_amenities_points_gdf = gpd.read_file('./merged and cleaned amenities/merged_amenity_points/merged_amenities_points.shp', crs='epsg:3123')\n",
    "merged_amenities_polygons_gdf = gpd.read_file('./merged and cleaned amenities/merged_amenity_polygons/cleaned_merged_with_OSM.shp', crs='epsg:3123')\n",
    "\n",
    "merged_amenities_polygons_gdf['amenity_points'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spatial index for points\n",
    "idx = rtree_index.Index()\n",
    "for j, point in merged_amenities_points_gdf.iterrows():\n",
    "    idx.insert(j, point['geometry'].bounds)\n",
    "\n",
    "# Iterate over polygons\n",
    "for i, polygon in merged_amenities_polygons_gdf.iterrows():\n",
    "    points_within_polygon = []\n",
    "    \n",
    "    # Iterate over points within the bounding box of the polygon\n",
    "    for j in idx.intersection(polygon['geometry'].bounds):\n",
    "        point = merged_amenities_points_gdf.loc[j]\n",
    "        if polygon['geometry'].intersects(point['geometry']):\n",
    "            points_within_polygon.append(j)\n",
    "    \n",
    "    merged_amenities_polygons_gdf.at[i, 'amenity_points'] = points_within_polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Manila_pikl_filepath = \"Saved Networks/Manila/\"\n",
    "Manila_map_filepath = \"Saved Maps/Manila/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING INITIAL NETWORK\n",
    "\n",
    "merged_amenities_network_Manila = create_network(merged_amenities_polygons_gdf, merged_amenities_points_gdf)\n",
    "\n",
    "# Make a before map\n",
    "merge_map_Manila = plot_network_on_map(merged_amenities_network_Manila, initial_location=[0, 0], zoom_start=100)\n",
    "merge_map_Manila.save(f'{Manila_map_filepath}merge_map.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST TO VISUALIZE RIVERS AND STREAMS\n",
    "map_center = (14.599512, 120.984222)  # TEMPORARY WILL ZOOM TO MANILA\n",
    "m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "\n",
    "# Iterate over the nodes in the network\n",
    "folium.GeoJson(filtered_rivers, style_function=lambda x: {'color': 'blue'}).add_to(m)\n",
    "\n",
    "m.save(f'{Manila_map_filepath}check.html')  # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 1 - CONNECTING POLYGONS OF SAME AMENITY\n",
    "\n",
    "connected_lines = []\n",
    "combined_graph_Manila = combine_amenities_by_polygon(merged_amenities_network_Manila, max_distance=100, max_perimeter=10000)\n",
    "after_map = plot_network_on_map(combined_graph_Manila, initial_location=[0, 0], zoom_start=100)\n",
    "\n",
    "\n",
    "# The lines to show the networks\n",
    "for line in connected_lines:\n",
    "    line_coords = [[coord[1], coord[0]] for coord in line.coords]\n",
    "    folium.PolyLine(locations=line_coords, color='black').add_to(after_map)\n",
    "after_map.save(f'{Manila_map_filepath}after_map.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORTING THE LEVEL 1 GRAPH\n",
    "path = f'{Manila_pikl_filepath}Manila_Combined_Amenities_Network.pkl'\n",
    "export_networks(combined_graph_Manila, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 2 - CREATING NETWORKS OF AMENITIES\n",
    "\n",
    "graph_networks_of_polygons_Manila = create_zone_network(graph=combined_graph_Manila, max_distance=100)\n",
    "networks_map_Manila = plot_connected_zones_network_on_map(graph_networks_of_polygons_Manila, initial_location=[0, 0], zoom_start=100)\n",
    "networks_map_Manila.save(f'{Manila_map_filepath}networks_map.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORTING THE LEVEL 2 GRAPH\n",
    "path = f'{Manila_pikl_filepath}Manila_Zone_Network.pkl'\n",
    "export_networks(graph_networks_of_polygons_Manila, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placing Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 3 - CREATING STOPS TO BE PLACED ON ZONES\n",
    "graph_of_stops_Manila = nx.Graph()\n",
    "add_points_to_graph(merged_amenities_network_Manila, graph_networks_of_polygons_Manila) # Add first all transportation stops\n",
    "list_of_stops_Manila = []\n",
    "place_stops_on_roads(graph_networks_of_polygons_Manila, graph_of_stops_Manila, list_of_stops_Manila) # Adds stops graph_of_stops\n",
    "\n",
    "# Visualize the stops\n",
    "stops_map = plot_stops_on_map(networks_map_Manila, list_of_stops_Manila, initial_location=[0, 0], zoom_start=100)\n",
    "stops_map.save(f'{Manila_map_filepath}stops_map.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export stops to pickle\n",
    "\n",
    "# Specify the file path where you want to save the pickle file\n",
    "file_path = f'{Manila_pikl_filepath}stop_objects.pkl'\n",
    "\n",
    "# Open the file in binary write mode\n",
    "with open(file_path, 'wb') as f:\n",
    "    # Dump the list of stop objects into the pickle file\n",
    "    pickle.dump(list_of_stops_Manila, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 3 - CREATING STOPS TO BE PLACED ON ZONES\n",
    "graph_of_stops_Manila = nx.Graph()\n",
    "add_points_to_graph(merged_amenities_network_Manila, graph_networks_of_polygons_Manila) # Add first all transportation stops\n",
    "list_of_stops_Manila = []\n",
    "place_stops_on_roads(graph_networks_of_polygons_Manila, graph_of_stops_Manila, list_of_stops_Manila) # Adds stops graph_of_stops\n",
    "\n",
    "# Visualize the stops\n",
    "stops_map = plot_stops_on_map(networks_map_Manila, list_of_stops_Manila, initial_location=[0, 0], zoom_start=100)\n",
    "stops_map.save(f\"{Manila_map_filepath}stops_map.html\") # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export stops to pickle\n",
    "\n",
    "# Specify the file path where you want to save the pickle file\n",
    "file_path = f'{Manila_pikl_filepath}stop_list_Manila.pkl'\n",
    "\n",
    "# Open the file in binary write mode\n",
    "with open(file_path, 'wb') as f:\n",
    "    # Dump the list of stop objects into the pickle file\n",
    "    pickle.dump(list_of_stops, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 4 - CONNECTING STOPS INTO A NETWORK\n",
    "WALKING_DISTANCES = [300,550,800]\n",
    "MAX_DISTANCE = 10\n",
    "CONNECTION_TYPES = [\"Default\", \"Area\", \"Degree\"]\n",
    "\n",
    "# Configuration\n",
    "set_walk_distance = WALKING_DISTANCES[0]\n",
    "num_of_networks = 10\n",
    "conn_type = CONNECTION_TYPES[0]\n",
    "max_stops = 20\n",
    "max_routes = 10\n",
    "map_html_location = \"Generated Route Networks HTML/Manila\"\n",
    "        \n",
    "# Generate route network\n",
    "list_of_networks_Manila = []\n",
    "\n",
    "for _ in range(num_of_networks):\n",
    "    route_count = 0 # Route is the connection between list of stops\n",
    "    connection_count = 0 # Connection is the connection between two stops / nodes\n",
    "    route_network, route_graph = generate_route_network(list_of_stops_Manila, set_walk_distance, max_stops, max_routes, conn_type) # Default max walking distance is 300m\n",
    "    used_stops = add_stops_to_list(route_network)\n",
    "    new_network = networkObj(route_network, used_stops, route_graph)\n",
    "    \n",
    "    # ERROR CHECKS----------\n",
    "    #print(\"Performing error checks...\")\n",
    "    #check_graph_with_route(new_network)\n",
    "    #check_graph_with_stops(new_network)\n",
    "    #check_order_route(new_network.routes)\n",
    "    \n",
    "    print()\n",
    "    # Append to list of networks\n",
    "    list_of_networks.append(new_network)\n",
    "\n",
    "\n",
    "#Export networks and graphs using pickl\n",
    "export_networks(list_of_networks_Manila, f\"{Manila_pikl_filepath}networks.pkl\")\n",
    "\n",
    "\n",
    "i = 1\n",
    "# Creating Maps for visualization\n",
    "for route_network in list_of_networks_Manila:\n",
    "    map_center = (14.599512, 120.984222)\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "\n",
    "    # Plotting in the Map\n",
    "    add_markers(route_network.stops, route_network.graph)\n",
    "        \n",
    "    for route in route_network.routes:\n",
    "        for connection in route:\n",
    "            ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "    m.save(f\"{map_html_location}/Map2-{i}.html\")\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import networks into list_of_networks\n",
    "# import pickl\n",
    "list_of_networks_Manila = import_networks(f\"{Manila_pikl_filepath}networks.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING GA ---------------------------------------------------------]\n",
    "# There should a pickle file already of the latest networks\n",
    "\n",
    "population_size = 10 # Default\n",
    "num_elites = 2\n",
    "num_generations = 5\n",
    "mutation_probability = 0.1\n",
    "num_mutations_probabilities = [0.1, 0.2, 0.3, 0.2, 0.2]\n",
    "num_crossovers_probabilities = [0.1, 0.2, 0.3, 0.2, 0.2]\n",
    "mutation_threshold_dist = 300\n",
    "with_elitism = False\n",
    "with_growing_population = False\n",
    "num_mutations_per_generation = 2\n",
    "\n",
    "#Weights and Fitness Function configuration\n",
    "num_failure_removal = 4\n",
    "weight_random_failure = 0.15\n",
    "weight_targeted_failure = 0.15\n",
    "weight_connectivity = 0.7\n",
    "\n",
    "population = perform_genetic_algorithm(list_of_networks_Manila, population_size, num_elites, num_generations, mutation_probability, \n",
    "                              num_mutations_probabilities, num_crossovers_probabilities, mutation_threshold_dist, num_failure_removal,\n",
    "                                      weight_random_failure, weight_targeted_failure, weight_connectivity,\n",
    "                              with_elitism, with_growing_population, num_mutations_per_generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Genetic Algorithm Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "map_html_location = \"GA Result Route Networks HTML/Manila\"\n",
    "\n",
    "i = 1\n",
    "for network in population:\n",
    "    map_center = (14.599512, 120.984222)\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "    add_markers(network.stops, network.graph)\n",
    "    \n",
    "    for route in network.routes:\n",
    "        for connection in route:\n",
    "            ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "    m.save(f\"{map_html_location}/GA_Map-{i}.html\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Makati Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READING DATA (All Amenities in Makati)\n",
    "Makati_amenities_points_gdf = gpd.read_file('./City Data/Makati City/Makati_point.geojson', crs='epsg:3123')\n",
    "Makati_amenities_polygons_gdf = gpd.read_file('././City Data/Makati City/Makati_polygon.geojson', crs='epsg:3123')\n",
    "\n",
    "Makati_amenities_polygons_gdf['amenity_points'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Makati_amenities_polygons_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spatial index for points\n",
    "idx = rtree_index.Index()\n",
    "for j, point in Makati_amenities_points_gdf.iterrows():\n",
    "    idx.insert(j, point['geometry'].bounds)\n",
    "\n",
    "# Iterate over polygons\n",
    "for i, polygon in Makati_amenities_polygons_gdf.iterrows():\n",
    "    points_within_polygon = []\n",
    "    \n",
    "    # Iterate over points within the bounding box of the polygon\n",
    "    for j in idx.intersection(polygon['geometry'].bounds):\n",
    "        point = Makati_amenities_points_gdf.loc[j]\n",
    "        if polygon['geometry'].intersects(point['geometry']):\n",
    "            points_within_polygon.append(j)\n",
    "    \n",
    "    Makati_amenities_polygons_gdf.at[i, 'amenity_points'] = points_within_polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Makati_pikl_filepath = \"Saved Networks/Makati/\"\n",
    "Makati_map_filepath = \"Saved Maps/Makati/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING INITIAL NETWORK\n",
    "\n",
    "merged_amenities_network_Makati = create_network(Makati_amenities_polygons_gdf, Makati_amenities_points_gdf)\n",
    "\n",
    "# Make a before map\n",
    "merge_map_Makati = plot_network_on_map(merged_amenities_network_Makati, initial_location=[0, 0], zoom_start=100)\n",
    "merge_map_Makati.save(f'{Makati_map_filepath}merge_map.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 1 - CONNECTING POLYGONS OF SAME AMENITY\n",
    "\n",
    "connected_lines = []\n",
    "combined_graph_Makati = combine_amenities_by_polygon(merged_amenities_network_Makati, max_distance=100, max_perimeter=10000)\n",
    "after_map = plot_network_on_map(combined_graph_Makati, initial_location=[0, 0], zoom_start=100)\n",
    "\n",
    "\n",
    "# The lines to show the networks\n",
    "for line in connected_lines:\n",
    "    line_coords = [[coord[1], coord[0]] for coord in line.coords]\n",
    "    folium.PolyLine(locations=line_coords, color='black').add_to(after_map)\n",
    "after_map.save(f'{Makati_map_filepath}after_map.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORTING THE LEVEL 1 GRAPH\n",
    "path = f'{Makati_pikl_filepath}Makati_Combined_Amenities_Network.pkl'\n",
    "export_networks(combined_graph_Makati, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 2 - CREATING NETWORKS OF AMENITIES\n",
    "\n",
    "graph_networks_of_polygons_Makati= create_zone_network(graph=combined_graph_Makati, max_distance=100)\n",
    "networks_map_Makati = plot_connected_zones_network_on_map(graph_networks_of_polygons_Makati, initial_location=[0, 0], zoom_start=100)\n",
    "networks_map_Makati.save(f'{Makati_map_filepath}networks_map.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORTING THE LEVEL 2 GRAPH\n",
    "path = f'{Makati_pikl_filepath}Makati_Zone_Network.pkl'\n",
    "export_networks(graph_networks_of_polygons_Makati, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placing Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 3 - CREATING STOPS TO BE PLACED ON ZONES\n",
    "graph_of_stops_Makati = nx.Graph()\n",
    "add_points_to_graph(merged_amenities_network_Makati, graph_networks_of_polygons_Makati) # Add first all transportation stops\n",
    "list_of_stops_Makati = []\n",
    "place_stops_on_roads(graph_networks_of_polygons_Makati, graph_of_stops_Makati, list_of_stops_Makati) # Adds stops graph_of_stops\n",
    "\n",
    "# Visualize the stops\n",
    "stops_map = plot_stops_on_map(networks_map_Makati, list_of_stops_Makati, initial_location=[0, 0], zoom_start=100)\n",
    "stops_map.save(f'{Makati_map_filepath}stops_map.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export stops to pickle\n",
    "\n",
    "# Specify the file path where you want to save the pickle file\n",
    "file_path = f'{Makati_pikl_filepath}stop_objects.pkl'\n",
    "\n",
    "# Open the file in binary write mode\n",
    "with open(file_path, 'wb') as f:\n",
    "    # Dump the list of stop objects into the pickle file\n",
    "    pickle.dump(list_of_stops_Makati, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 3 - CREATING STOPS TO BE PLACED ON ZONES\n",
    "graph_of_stops_Makati = nx.Graph()\n",
    "add_points_to_graph(merged_amenities_network_Makati, graph_networks_of_polygons_Makati) # Add first all transportation stops\n",
    "list_of_stops_Makati = []\n",
    "place_stops_on_roads(graph_networks_of_polygons_Makati, graph_of_stops_Makati, list_of_stops_Makati) # Adds stops graph_of_stops\n",
    "\n",
    "# Visualize the stops\n",
    "stops_map = plot_stops_on_map(networks_map_Makati, list_of_stops_Makati, initial_location=[0, 0], zoom_start=100)\n",
    "stops_map.save(f\"{Makati_map_filepath}stops_map.html\") # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export stops to pickle\n",
    "\n",
    "# Specify the file path where you want to save the pickle file\n",
    "file_path = f'{Makati_pikl_filepath}stop_list_Makati.pkl'\n",
    "\n",
    "# Open the file in binary write mode\n",
    "with open(file_path, 'wb') as f:\n",
    "    # Dump the list of stop objects into the pickle file\n",
    "    pickle.dump(list_of_stops, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 4 - CONNECTING STOPS INTO A NETWORK\n",
    "WALKING_DISTANCES = [300,550,800]\n",
    "MAX_DISTANCE = 10\n",
    "CONNECTION_TYPES = [\"Default\", \"Area\", \"Degree\"]\n",
    "\n",
    "# Configuration\n",
    "set_walk_distance = WALKING_DISTANCES[0]\n",
    "num_of_networks = 10\n",
    "conn_type = CONNECTION_TYPES[0]\n",
    "max_stops = 20\n",
    "max_routes = 10\n",
    "map_html_location = \"Generated Route Networks HTML/Makati\"\n",
    "        \n",
    "# Generate route network\n",
    "list_of_networks_Makati = []\n",
    "\n",
    "for _ in range(num_of_networks):\n",
    "    route_count = 0 # Route is the connection between list of stops\n",
    "    connection_count = 0 # Connection is the connection between two stops / nodes\n",
    "    route_network, route_graph = generate_route_network(list_of_stops_Makati, set_walk_distance, max_stops, max_routes, conn_type) # Default max walking distance is 300m\n",
    "    used_stops = add_stops_to_list(route_network)\n",
    "    new_network = networkObj(route_network, used_stops, route_graph)\n",
    "    \n",
    "    # ERROR CHECKS----------\n",
    "    #print(\"Performing error checks...\")\n",
    "    #check_graph_with_route(new_network)\n",
    "    #check_graph_with_stops(new_network)\n",
    "    #check_order_route(new_network.routes)\n",
    "    \n",
    "    print()\n",
    "    # Append to list of networks\n",
    "    list_of_networks.append(new_network)\n",
    "\n",
    "\n",
    "#Export networks and graphs using pickl\n",
    "export_networks(list_of_networks_Makati, f\"{Makati_pikl_filepath}networks.pkl\")\n",
    "\n",
    "\n",
    "i = 1\n",
    "# Creating Maps for visualization\n",
    "for route_network in list_of_networks_Makati:\n",
    "    map_center = (14.599512, 120.984222)\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "\n",
    "    # Plotting in the Map\n",
    "    add_markers(route_network.stops, route_network.graph)\n",
    "        \n",
    "    for route in route_network.routes:\n",
    "        for connection in route:\n",
    "            ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "    m.save(f\"{map_html_location}/Map2-{i}.html\")\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import networks into list_of_networks\n",
    "# import pickl\n",
    "list_of_networks_Makati = import_networks(f\"{Makati_pikl_filepath}networks.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING GA ---------------------------------------------------------]\n",
    "# There should a pickle file already of the latest networks\n",
    "\n",
    "population_size = 10 # Default\n",
    "num_elites = 2\n",
    "num_generations = 5\n",
    "mutation_probability = 0.1\n",
    "num_mutations_probabilities = [0.1, 0.2, 0.3, 0.2, 0.2]\n",
    "num_crossovers_probabilities = [0.1, 0.2, 0.3, 0.2, 0.2]\n",
    "mutation_threshold_dist = 300\n",
    "with_elitism = False\n",
    "with_growing_population = False\n",
    "num_mutations_per_generation = 2\n",
    "\n",
    "#Weights and Fitness Function configuration\n",
    "num_failure_removal = 4\n",
    "weight_random_failure = 0.15\n",
    "weight_targeted_failure = 0.15\n",
    "weight_connectivity = 0.7\n",
    "\n",
    "population = perform_genetic_algorithm(list_of_networks_Makati, population_size, num_elites, num_generations, mutation_probability, \n",
    "                              num_mutations_probabilities, num_crossovers_probabilities, mutation_threshold_dist, num_failure_removal,\n",
    "                                      weight_random_failure, weight_targeted_failure, weight_connectivity,\n",
    "                              with_elitism, with_growing_population, num_mutations_per_generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Genetic Algorithm Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "map_html_location = \"GA Result Route Networks HTML/Makati\"\n",
    "\n",
    "i = 1\n",
    "for network in population:\n",
    "    map_center = (14.599512, 120.984222)\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "    add_markers(network.stops, network.graph)\n",
    "    \n",
    "    for route in network.routes:\n",
    "        for connection in route:\n",
    "            ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "    m.save(f\"{map_html_location}/GA_Map-{i}.html\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mandaluyong Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READING DATA (All Amenities in Mandaluyong)\n",
    "Mandaluyong_amenities_points_gdf = gpd.read_file('./City Data/Mandaluyong City/Mandaluyong_point.geojson', crs='epsg:3123')\n",
    "Mandaluyong_amenities_polygons_gdf = gpd.read_file('././City Data/Mandaluyong City/Mandaluyong_polygon.geojson', crs='epsg:3123')\n",
    "\n",
    "Mandaluyong_amenities_polygons_gdf['amenity_points'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fid</th>\n",
       "      <th>id</th>\n",
       "      <th>amenity</th>\n",
       "      <th>layer</th>\n",
       "      <th>path</th>\n",
       "      <th>full_id</th>\n",
       "      <th>amenity_2</th>\n",
       "      <th>name</th>\n",
       "      <th>addr_postc</th>\n",
       "      <th>fid_2</th>\n",
       "      <th>addr_provi</th>\n",
       "      <th>addr_city</th>\n",
       "      <th>addr_pro_1</th>\n",
       "      <th>addr_cit_1</th>\n",
       "      <th>layer_2</th>\n",
       "      <th>path_2</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>geometry</th>\n",
       "      <th>amenity_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>48.0</td>\n",
       "      <td>residential areas</td>\n",
       "      <td>anton_tagging_mandaluyong_incomplete</td>\n",
       "      <td>C:/Users/almon/OneDrive/Desktop/amenity_taggin...</td>\n",
       "      <td>w686068378</td>\n",
       "      <td>residential areas</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>building_residential_building_apartments_Manda...</td>\n",
       "      <td>C:/Users/almon/OneDrive/Desktop/premade-amenit...</td>\n",
       "      <td>121.037</td>\n",
       "      <td>14.587</td>\n",
       "      <td>POLYGON ((121.03710 14.58734, 121.03700 14.587...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>131</td>\n",
       "      <td>227.0</td>\n",
       "      <td>residential areas</td>\n",
       "      <td>anton_tagging_mandaluyong_incomplete</td>\n",
       "      <td>C:/Users/almon/OneDrive/Desktop/amenity_taggin...</td>\n",
       "      <td>w332079378</td>\n",
       "      <td>residential areas</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>building_residential_building_apartments_Manda...</td>\n",
       "      <td>C:/Users/almon/OneDrive/Desktop/premade-amenit...</td>\n",
       "      <td>121.036</td>\n",
       "      <td>14.590</td>\n",
       "      <td>MULTIPOLYGON (((121.03557 14.58998, 121.03548 ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>236</td>\n",
       "      <td>436.0</td>\n",
       "      <td>education</td>\n",
       "      <td>anton_tagging_mandaluyong_incomplete</td>\n",
       "      <td>C:/Users/almon/OneDrive/Desktop/amenity_taggin...</td>\n",
       "      <td>None</td>\n",
       "      <td>education</td>\n",
       "      <td>Addition Hills Integrated School</td>\n",
       "      <td>None</td>\n",
       "      <td>12.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Mandaluyong</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>amenity_university_amenity_college_Mandaluyong...</td>\n",
       "      <td>C:/Users/almon/OneDrive/Desktop/premade-amenit...</td>\n",
       "      <td>121.034</td>\n",
       "      <td>14.584</td>\n",
       "      <td>POLYGON ((121.03421 14.58426, 121.03397 14.583...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>472</td>\n",
       "      <td>930.0</td>\n",
       "      <td>residential areas</td>\n",
       "      <td>anton_tagging_mandaluyong_incomplete</td>\n",
       "      <td>C:/Users/almon/OneDrive/Desktop/amenity_taggin...</td>\n",
       "      <td>w1070548322</td>\n",
       "      <td>residential areas</td>\n",
       "      <td>Mandaluyong Executive Mansion III</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>building_residential_building_apartments_Manda...</td>\n",
       "      <td>C:/Users/almon/OneDrive/Desktop/premade-amenit...</td>\n",
       "      <td>121.024</td>\n",
       "      <td>14.580</td>\n",
       "      <td>POLYGON ((121.02413 14.57967, 121.02406 14.579...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>647</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>education</td>\n",
       "      <td>anton_tagging_mandaluyong_incomplete</td>\n",
       "      <td>C:/Users/almon/OneDrive/Desktop/amenity_taggin...</td>\n",
       "      <td>None</td>\n",
       "      <td>education</td>\n",
       "      <td>Mandaluyong Elementary School</td>\n",
       "      <td>None</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Eastern Manila District</td>\n",
       "      <td>Mandaluyong</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>amenity_university_amenity_college_Mandaluyong...</td>\n",
       "      <td>C:/Users/almon/OneDrive/Desktop/premade-amenit...</td>\n",
       "      <td>121.019</td>\n",
       "      <td>14.583</td>\n",
       "      <td>POLYGON ((121.02531 14.58600, 121.02535 14.586...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10568</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>malls</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>w676184963</td>\n",
       "      <td>malls</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Mandaluyong</td>\n",
       "      <td>shop_mall_shop_department_store_Mandaluyong_poly</td>\n",
       "      <td>C:/Users/almon/OneDrive/Desktop/premade-amenit...</td>\n",
       "      <td>121.037</td>\n",
       "      <td>14.589</td>\n",
       "      <td>POLYGON ((121.03674 14.58929, 121.03682 14.589...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10569</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grocery</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>w98298274</td>\n",
       "      <td>groceries</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Metro Manila</td>\n",
       "      <td>Mandaluyong</td>\n",
       "      <td>shop_supermarket_shop_grocery_Mandaluyong_poly</td>\n",
       "      <td>C:/Users/almon/OneDrive/Desktop/premade-amenit...</td>\n",
       "      <td>121.030</td>\n",
       "      <td>14.593</td>\n",
       "      <td>POLYGON ((121.02996 14.59323, 121.03002 14.593...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10570</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grocery</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>w103094584</td>\n",
       "      <td>groceries</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Metro Manila</td>\n",
       "      <td>Mandaluyong</td>\n",
       "      <td>shop_supermarket_shop_grocery_Mandaluyong_poly</td>\n",
       "      <td>C:/Users/almon/OneDrive/Desktop/premade-amenit...</td>\n",
       "      <td>121.042</td>\n",
       "      <td>14.588</td>\n",
       "      <td>POLYGON ((121.04242 14.58867, 121.04218 14.587...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10571</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grocery</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>w185024498</td>\n",
       "      <td>groceries</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Metro Manila</td>\n",
       "      <td>Mandaluyong</td>\n",
       "      <td>shop_supermarket_shop_grocery_Mandaluyong_poly</td>\n",
       "      <td>C:/Users/almon/OneDrive/Desktop/premade-amenit...</td>\n",
       "      <td>121.045</td>\n",
       "      <td>14.587</td>\n",
       "      <td>POLYGON ((121.04490 14.58790, 121.04547 14.587...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10572</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>grocery</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>w243980438</td>\n",
       "      <td>groceries</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>shop_supermarket_shop_grocery_Mandaluyong_poly</td>\n",
       "      <td>C:/Users/almon/OneDrive/Desktop/premade-amenit...</td>\n",
       "      <td>121.045</td>\n",
       "      <td>14.587</td>\n",
       "      <td>POLYGON ((121.04527 14.58734, 121.04529 14.587...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10573 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fid      id            amenity                                 layer  \\\n",
       "0        41    48.0  residential areas  anton_tagging_mandaluyong_incomplete   \n",
       "1       131   227.0  residential areas  anton_tagging_mandaluyong_incomplete   \n",
       "2       236   436.0          education  anton_tagging_mandaluyong_incomplete   \n",
       "3       472   930.0  residential areas  anton_tagging_mandaluyong_incomplete   \n",
       "4       647  1292.0          education  anton_tagging_mandaluyong_incomplete   \n",
       "...     ...     ...                ...                                   ...   \n",
       "10568  None     NaN              malls                                  None   \n",
       "10569  None     NaN            grocery                                  None   \n",
       "10570  None     NaN            grocery                                  None   \n",
       "10571  None     NaN            grocery                                  None   \n",
       "10572  None     NaN            grocery                                  None   \n",
       "\n",
       "                                                    path      full_id  \\\n",
       "0      C:/Users/almon/OneDrive/Desktop/amenity_taggin...   w686068378   \n",
       "1      C:/Users/almon/OneDrive/Desktop/amenity_taggin...   w332079378   \n",
       "2      C:/Users/almon/OneDrive/Desktop/amenity_taggin...         None   \n",
       "3      C:/Users/almon/OneDrive/Desktop/amenity_taggin...  w1070548322   \n",
       "4      C:/Users/almon/OneDrive/Desktop/amenity_taggin...         None   \n",
       "...                                                  ...          ...   \n",
       "10568                                               None   w676184963   \n",
       "10569                                               None    w98298274   \n",
       "10570                                               None   w103094584   \n",
       "10571                                               None   w185024498   \n",
       "10572                                               None   w243980438   \n",
       "\n",
       "               amenity_2                               name addr_postc  fid_2  \\\n",
       "0      residential areas                               None       None    NaN   \n",
       "1      residential areas                               None       None    NaN   \n",
       "2              education   Addition Hills Integrated School       None   12.0   \n",
       "3      residential areas  Mandaluyong Executive Mansion III       None    NaN   \n",
       "4              education      Mandaluyong Elementary School       None    8.0   \n",
       "...                  ...                                ...        ...    ...   \n",
       "10568              malls                               None       None    NaN   \n",
       "10569          groceries                               None       None    NaN   \n",
       "10570          groceries                               None       None    NaN   \n",
       "10571          groceries                               None       None    NaN   \n",
       "10572          groceries                               None       None    NaN   \n",
       "\n",
       "                    addr_provi    addr_city    addr_pro_1   addr_cit_1  \\\n",
       "0                         None         None          None         None   \n",
       "1                         None         None          None         None   \n",
       "2                         None  Mandaluyong          None         None   \n",
       "3                         None         None          None         None   \n",
       "4      Eastern Manila District  Mandaluyong          None         None   \n",
       "...                        ...          ...           ...          ...   \n",
       "10568                     None         None          None  Mandaluyong   \n",
       "10569                     None         None  Metro Manila  Mandaluyong   \n",
       "10570                     None         None  Metro Manila  Mandaluyong   \n",
       "10571                     None         None  Metro Manila  Mandaluyong   \n",
       "10572                     None         None          None         None   \n",
       "\n",
       "                                                 layer_2  \\\n",
       "0      building_residential_building_apartments_Manda...   \n",
       "1      building_residential_building_apartments_Manda...   \n",
       "2      amenity_university_amenity_college_Mandaluyong...   \n",
       "3      building_residential_building_apartments_Manda...   \n",
       "4      amenity_university_amenity_college_Mandaluyong...   \n",
       "...                                                  ...   \n",
       "10568   shop_mall_shop_department_store_Mandaluyong_poly   \n",
       "10569     shop_supermarket_shop_grocery_Mandaluyong_poly   \n",
       "10570     shop_supermarket_shop_grocery_Mandaluyong_poly   \n",
       "10571     shop_supermarket_shop_grocery_Mandaluyong_poly   \n",
       "10572     shop_supermarket_shop_grocery_Mandaluyong_poly   \n",
       "\n",
       "                                                  path_2        x       y  \\\n",
       "0      C:/Users/almon/OneDrive/Desktop/premade-amenit...  121.037  14.587   \n",
       "1      C:/Users/almon/OneDrive/Desktop/premade-amenit...  121.036  14.590   \n",
       "2      C:/Users/almon/OneDrive/Desktop/premade-amenit...  121.034  14.584   \n",
       "3      C:/Users/almon/OneDrive/Desktop/premade-amenit...  121.024  14.580   \n",
       "4      C:/Users/almon/OneDrive/Desktop/premade-amenit...  121.019  14.583   \n",
       "...                                                  ...      ...     ...   \n",
       "10568  C:/Users/almon/OneDrive/Desktop/premade-amenit...  121.037  14.589   \n",
       "10569  C:/Users/almon/OneDrive/Desktop/premade-amenit...  121.030  14.593   \n",
       "10570  C:/Users/almon/OneDrive/Desktop/premade-amenit...  121.042  14.588   \n",
       "10571  C:/Users/almon/OneDrive/Desktop/premade-amenit...  121.045  14.587   \n",
       "10572  C:/Users/almon/OneDrive/Desktop/premade-amenit...  121.045  14.587   \n",
       "\n",
       "                                                geometry amenity_points  \n",
       "0      POLYGON ((121.03710 14.58734, 121.03700 14.587...           None  \n",
       "1      MULTIPOLYGON (((121.03557 14.58998, 121.03548 ...           None  \n",
       "2      POLYGON ((121.03421 14.58426, 121.03397 14.583...           None  \n",
       "3      POLYGON ((121.02413 14.57967, 121.02406 14.579...           None  \n",
       "4      POLYGON ((121.02531 14.58600, 121.02535 14.586...           None  \n",
       "...                                                  ...            ...  \n",
       "10568  POLYGON ((121.03674 14.58929, 121.03682 14.589...           None  \n",
       "10569  POLYGON ((121.02996 14.59323, 121.03002 14.593...           None  \n",
       "10570  POLYGON ((121.04242 14.58867, 121.04218 14.587...           None  \n",
       "10571  POLYGON ((121.04490 14.58790, 121.04547 14.587...           None  \n",
       "10572  POLYGON ((121.04527 14.58734, 121.04529 14.587...           None  \n",
       "\n",
       "[10573 rows x 20 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mandaluyong_amenities_polygons_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spatial index for points\n",
    "idx = rtree_index.Index()\n",
    "for j, point in Mandaluyong_amenities_points_gdf.iterrows():\n",
    "    idx.insert(j, point['geometry'].bounds)\n",
    "\n",
    "# Iterate over polygons\n",
    "for i, polygon in Mandaluyong_amenities_polygons_gdf.iterrows():\n",
    "    points_within_polygon = []\n",
    "    \n",
    "    # Iterate over points within the bounding box of the polygon\n",
    "    for j in idx.intersection(polygon['geometry'].bounds):\n",
    "        point = Mandaluyong_amenities_points_gdf.loc[j]\n",
    "        if polygon['geometry'].intersects(point['geometry']):\n",
    "            points_within_polygon.append(j)\n",
    "    \n",
    "    Mandaluyong_amenities_polygons_gdf.at[i, 'amenity_points'] = points_within_polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mandaluyong_pikl_filepath = \"Saved Networks/Mandaluyong/\"\n",
    "Mandaluyong_map_filepath = \"Saved Maps/Mandaluyong/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING INITIAL NETWORK\n",
    "\n",
    "merged_amenities_network_Mandaluyong = create_network(Mandaluyong_amenities_polygons_gdf, Mandaluyong_amenities_points_gdf)\n",
    "\n",
    "# Make a before map\n",
    "merge_map_Mandaluyong = plot_network_on_map(merged_amenities_network_Mandaluyong, initial_location=[0, 0], zoom_start=100)\n",
    "merge_map_Mandaluyong.save(f'{Mandaluyong_map_filepath}merge_map.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 1 - CONNECTING POLYGONS OF SAME AMENITY\n",
    "\n",
    "connected_lines = []\n",
    "combined_graph_Mandaluyong = combine_amenities_by_polygon(merged_amenities_network_Mandaluyong, max_distance=100, max_perimeter=10000)\n",
    "after_map = plot_network_on_map(combined_graph_Mandaluyong, initial_location=[0, 0], zoom_start=100)\n",
    "\n",
    "\n",
    "# The lines to show the networks\n",
    "for line in connected_lines:\n",
    "    line_coords = [[coord[1], coord[0]] for coord in line.coords]\n",
    "    folium.PolyLine(locations=line_coords, color='black').add_to(after_map)\n",
    "after_map.save(f'{Mandaluyong_map_filepath}after_map.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORTING THE LEVEL 1 GRAPH\n",
    "path = f'{Mandaluyong_pikl_filepath}Mandaluyong_Combined_Amenities_Network.pkl'\n",
    "export_networks(combined_graph_Mandaluyong, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 2 - CREATING NETWORKS OF AMENITIES\n",
    "\n",
    "graph_networks_of_polygons_Mandaluyong= create_zone_network(graph=combined_graph_Mandaluyong, max_distance=100)\n",
    "networks_map_Mandaluyong = plot_connected_zones_network_on_map(graph_networks_of_polygons_Mandaluyong, initial_location=[0, 0], zoom_start=100)\n",
    "networks_map_Mandaluyong.save(f'{Mandaluyong_map_filepath}networks_map.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORTING THE LEVEL 2 GRAPH\n",
    "path = f'{Mandaluyong_pikl_filepath}Mandaluyong_Zone_Network.pkl'\n",
    "export_networks(graph_networks_of_polygons_Mandaluyong, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placing Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 3 - CREATING STOPS TO BE PLACED ON ZONES\n",
    "graph_of_stops_Mandaluyong = nx.Graph()\n",
    "add_points_to_graph(merged_amenities_network_Mandaluyong, graph_networks_of_polygons_Mandaluyong) # Add first all transportation stops\n",
    "list_of_stops_Mandaluyong = []\n",
    "place_stops_on_roads(graph_networks_of_polygons_Mandaluyong, graph_of_stops_Mandaluyong, list_of_stops_Mandaluyong) # Adds stops graph_of_stops\n",
    "\n",
    "# Visualize the stops\n",
    "stops_map = plot_stops_on_map(networks_map_Mandaluyong, list_of_stops_Mandaluyong, initial_location=[0, 0], zoom_start=100)\n",
    "stops_map.save(f'{Mandaluyong_map_filepath}stops_map.html') # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export stops to pickle\n",
    "\n",
    "# Specify the file path where you want to save the pickle file\n",
    "file_path = f'{Mandaluyong_pikl_filepath}stop_objects.pkl'\n",
    "\n",
    "# Open the file in binary write mode\n",
    "with open(file_path, 'wb') as f:\n",
    "    # Dump the list of stop objects into the pickle file\n",
    "    pickle.dump(list_of_stops_Mandaluyong, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 3 - CREATING STOPS TO BE PLACED ON ZONES\n",
    "graph_of_stops_Mandaluyong = nx.Graph()\n",
    "add_points_to_graph(merged_amenities_network_Mandaluyong, graph_networks_of_polygons_Mandaluyong) # Add first all transportation stops\n",
    "list_of_stops_Mandaluyong = []\n",
    "place_stops_on_roads(graph_networks_of_polygons_Mandaluyong, graph_of_stops_Mandaluyong, list_of_stops_Mandaluyong) # Adds stops graph_of_stops\n",
    "\n",
    "# Visualize the stops\n",
    "stops_map = plot_stops_on_map(networks_map_Mandaluyong, list_of_stops_Mandaluyong, initial_location=[0, 0], zoom_start=100)\n",
    "stops_map.save(f\"{Mandaluyong_map_filepath}stops_map.html\") # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export stops to pickle\n",
    "\n",
    "# Specify the file path where you want to save the pickle file\n",
    "file_path = f'{Mandaluyong_pikl_filepath}stop_list_Mandaluyong.pkl'\n",
    "\n",
    "# Open the file in binary write mode\n",
    "with open(file_path, 'wb') as f:\n",
    "    # Dump the list of stop objects into the pickle file\n",
    "    pickle.dump(list_of_stops, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 4 - CONNECTING STOPS INTO A NETWORK\n",
    "WALKING_DISTANCES = [300,550,800]\n",
    "MAX_DISTANCE = 10\n",
    "CONNECTION_TYPES = [\"Default\", \"Area\", \"Degree\"]\n",
    "\n",
    "# Configuration\n",
    "set_walk_distance = WALKING_DISTANCES[0]\n",
    "num_of_networks = 10\n",
    "conn_type = CONNECTION_TYPES[0]\n",
    "max_stops = 20\n",
    "max_routes = 10\n",
    "map_html_location = \"Generated Route Networks HTML/Mandaluyong\"\n",
    "        \n",
    "# Generate route network\n",
    "list_of_networks_Mandaluyong = []\n",
    "\n",
    "for _ in range(num_of_networks):\n",
    "    route_count = 0 # Route is the connection between list of stops\n",
    "    connection_count = 0 # Connection is the connection between two stops / nodes\n",
    "    route_network, route_graph = generate_route_network(list_of_stops_Mandaluyong, set_walk_distance, max_stops, max_routes, conn_type) # Default max walking distance is 300m\n",
    "    used_stops = add_stops_to_list(route_network)\n",
    "    new_network = networkObj(route_network, used_stops, route_graph)\n",
    "    \n",
    "    # ERROR CHECKS----------\n",
    "    #print(\"Performing error checks...\")\n",
    "    #check_graph_with_route(new_network)\n",
    "    #check_graph_with_stops(new_network)\n",
    "    #check_order_route(new_network.routes)\n",
    "    \n",
    "    print()\n",
    "    # Append to list of networks\n",
    "    list_of_networks.append(new_network)\n",
    "\n",
    "\n",
    "#Export networks and graphs using pickl\n",
    "export_networks(list_of_networks_Mandaluyong, f\"{Mandaluyong_pikl_filepath}networks.pkl\")\n",
    "\n",
    "\n",
    "i = 1\n",
    "# Creating Maps for visualization\n",
    "for route_network in list_of_networks_Mandaluyong:\n",
    "    map_center = (14.599512, 120.984222)\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "\n",
    "    # Plotting in the Map\n",
    "    add_markers(route_network.stops, route_network.graph)\n",
    "        \n",
    "    for route in route_network.routes:\n",
    "        for connection in route:\n",
    "            ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "    m.save(f\"{map_html_location}/Map2-{i}.html\")\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import networks into list_of_networks\n",
    "# import pickl\n",
    "list_of_networks_Mandaluyong = import_networks(f\"{Mandaluyong_pikl_filepath}networks.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING GA ---------------------------------------------------------]\n",
    "# There should a pickle file already of the latest networks\n",
    "\n",
    "population_size = 10 # Default\n",
    "num_elites = 2\n",
    "num_generations = 5\n",
    "mutation_probability = 0.1\n",
    "num_mutations_probabilities = [0.1, 0.2, 0.3, 0.2, 0.2]\n",
    "num_crossovers_probabilities = [0.1, 0.2, 0.3, 0.2, 0.2]\n",
    "mutation_threshold_dist = 300\n",
    "with_elitism = False\n",
    "with_growing_population = False\n",
    "num_mutations_per_generation = 2\n",
    "\n",
    "#Weights and Fitness Function configuration\n",
    "num_failure_removal = 4\n",
    "weight_random_failure = 0.15\n",
    "weight_targeted_failure = 0.15\n",
    "weight_connectivity = 0.7\n",
    "\n",
    "population = perform_genetic_algorithm(list_of_networks_Mandaluyong, population_size, num_elites, num_generations, mutation_probability, \n",
    "                              num_mutations_probabilities, num_crossovers_probabilities, mutation_threshold_dist, num_failure_removal,\n",
    "                                      weight_random_failure, weight_targeted_failure, weight_connectivity,\n",
    "                              with_elitism, with_growing_population, num_mutations_per_generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Genetic Algorithm Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "map_html_location = \"GA Result Route Networks HTML/Mandaluyong\"\n",
    "\n",
    "i = 1\n",
    "for network in population:\n",
    "    map_center = (14.599512, 120.984222)\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "    add_markers(network.stops, network.graph)\n",
    "    \n",
    "    for route in network.routes:\n",
    "        for connection in route:\n",
    "            ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "    m.save(f\"{map_html_location}/GA_Map-{i}.html\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MISC (VISUALIZATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR VISUALIZATION ONLY\n",
    "all_roads_map = plot_all_roads()\n",
    "all_roads_map.save('all_roads.html')\n",
    "\n",
    "filtered_road_map = plot_all_filtered_roads()\n",
    "filtered_road_map.save('filtered_road_map.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_amenities_points_gdf['amenity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_center = (14.599512, 120.984222) # TEMPORARY WILL ZOOM TO MANILA\n",
    "m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "\n",
    "for j, point in merged_amenities_points_gdf.iterrows():\n",
    "    if point['amenity'] == 'grocery':\n",
    "        folium.Marker(location=[point['y'], point['x']], popup=f\"{point['name']}\").add_to(m)\n",
    "        \n",
    "m.save('test.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_amenity_test(amenities_network, amenity, initial_location=[0, 0], zoom_start=10):\n",
    "    # Create a map centered at the initial location\n",
    "    map_center = (14.599512, 120.984222) # TEMPORARY WILL ZOOM TO MANILA\n",
    "    m = folium.Map(location=map_center, zoom_start=zoom_start, tiles='openstreetmap')\n",
    "    \n",
    "    #Colours for Visualization\n",
    "    amenity_colors = {\n",
    "        'education': 'green',\n",
    "        'finance': 'blue',\n",
    "        'government offices': 'red',\n",
    "        'grocery': 'orange',\n",
    "        'health': 'magenta',\n",
    "        'malls': 'yellow',\n",
    "        'residential areas': 'brown',\n",
    "        'security': 'gray',\n",
    "        'transportation': 'lightblue',\n",
    "        'others': 'black'\n",
    "    }\n",
    "\n",
    "    # Iterate over the nodes in the network\n",
    "    for node, data in amenities_network.nodes(data=True):\n",
    "        if data['amenity'] == amenity:\n",
    "            # Check if the node has a geometry attribute\n",
    "            if 'geometry' in data:\n",
    "                # Get the geometry of the node\n",
    "                geometry = data['geometry']\n",
    "\n",
    "                # Check the geometry type and plot accordingly\n",
    "                if geometry.geom_type == 'Point':\n",
    "                    # Plot a marker for points    \n",
    "                    #folium.Marker(location=[geometry.y, geometry.x], popup=f\"{data['name']}\").add_to(m)\n",
    "                    continue\n",
    "                elif geometry.geom_type in ['Polygon', 'MultiPolygon']:\n",
    "                    # Plot polygons or multipolygons\n",
    "                    color = amenity_colors[data.get('amenity')]\n",
    "                    if geometry.geom_type == 'Polygon':\n",
    "                        polygons = [geometry]\n",
    "                    else:\n",
    "                        polygons = geometry.geoms\n",
    "\n",
    "                    for polygon in polygons:\n",
    "                        coordinates = []\n",
    "                        for point in polygon.exterior.coords:\n",
    "                            coordinates.append([point[1], point[0]])\n",
    "                        folium.Polygon(locations=coordinates, fill=True, color=color, fill_opacity=0.4).add_to(m)\n",
    "\n",
    "    # Return the map\n",
    "    return m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
