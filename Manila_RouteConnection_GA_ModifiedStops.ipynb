{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manila - Jeepney Route Connection and Genetic Algorithm - Modified Stop Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Route Connection and Genetic Algorithm Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import shapely\n",
    "import folium\n",
    "import geojson\n",
    "import math\n",
    "import osmnx as ox\n",
    "from rtree import index as rtree_index\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "from shapely.ops import unary_union\n",
    "from shapely.geometry import Polygon, MultiPolygon, LineString, Point\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "from __future__ import absolute_import, division\n",
    "from math import radians, sin, cos, sqrt, atan2, exp, log\n",
    "import webbrowser\n",
    "import random\n",
    "from scipy.spatial import KDTree\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "ox.settings.log_console=True\n",
    "ox.settings.use_cache=True\n",
    "\n",
    "WALKING_DISTANCES = [300,550,800]\n",
    "MAX_DISTANCE = 15\n",
    "CONNECTION_TYPES = [\"Default\", \"Area\", \"Degree\", \"Mixed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining classes for the dataframes      \n",
    "class stopCandidate:\n",
    "    def __init__(self, lat, long, isTranspo, id, area, node_id):\n",
    "        self.lat = lat\n",
    "        self.long = long\n",
    "        self.isTranspo = isTranspo\n",
    "        self.enabled = False\n",
    "        self.id = id #Stop ID\n",
    "        self.area = area\n",
    "        self.degree = 0\n",
    "        self.node_id = node_id\n",
    "        \n",
    "    def enable(self):\n",
    "        self.enabled = True\n",
    "        \n",
    "    def disable(self):\n",
    "        self.enabled = False\n",
    "        \n",
    "    def getLat(self):\n",
    "        return self.lat\n",
    "    \n",
    "    def getLong(self):\n",
    "        return self.long\n",
    "    \n",
    "    def getArea(self):\n",
    "        return self.area\n",
    "    \n",
    "    def getDegree(self):\n",
    "        return self.degree\n",
    "    \n",
    "class networkObj:\n",
    "    def __init__(self, routes, stops, graph, conn_type, walk_distance):\n",
    "        self.routes = routes\n",
    "        self.stops = stops\n",
    "        self.fitness_score = 0\n",
    "        self.graph = graph\n",
    "        self.conn_type = conn_type\n",
    "        self.walk_distance = walk_distance\n",
    "        \n",
    "class Route:\n",
    "    def __init__(self, route, route_id):\n",
    "        self.route = route\n",
    "        self.route_id = route_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For units\n",
    "def degrees_to_meters(angle_degrees):\n",
    "    return angle_degrees * 6371000 * math.pi / 180\n",
    "\n",
    "def meters_to_degrees(distance_meters):\n",
    "    return distance_meters / 6371000 * 180 / math.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and Export networks or graphs to pickle\n",
    "def export_networks(networks, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(networks, f)\n",
    "\n",
    "def import_networks(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        routes = pickle.load(f)\n",
    "    return routes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph loaded successfully\n",
      "NUMBER OF EDGES:  12617\n",
      "NUMBER OF NODES:  4926\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NOTE: SELECT THE CITY HERE, COMMENT OUT THE REMAINING CITIES\n",
    "select_city = \"Manila, Philippines\"\n",
    "city_file = 'map/Manila.graphml'\n",
    "\n",
    "\n",
    "# GENERATION OF MAIN CITY GRAPH\n",
    "# IF FIRST TIME RUNNING, RUN THIS CODE TO GENERATE THE GRAPH\n",
    "def generate_graph():\n",
    "    mode = 'drive'\n",
    "    graph = ox.graph_from_place(select_city, network_type = mode) # Generate graph of Metro manila\n",
    "    ox.save_graphml(graph, city_file) # Save it as a file\n",
    "\n",
    "def load_graph():\n",
    "    graph = ox.load_graphml(city_file)\n",
    "    \n",
    "    print(\"Graph loaded successfully\")\n",
    "    print(\"NUMBER OF EDGES: \", graph.number_of_edges())\n",
    "    print(\"NUMBER OF NODES: \", graph.number_of_nodes())\n",
    "    print('\\n')\n",
    "    return graph\n",
    "\n",
    "# NOTE: Only run this if you do not have the graph\n",
    "generate_graph()\n",
    "\n",
    "# THIS IS THE MAIN GRAPH FOR THE CITY TO BE USED FOR ALL FUNCTIONS\n",
    "CITY_GRAPH = load_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For Filtering the roads and other features\n",
    "# GETTING ROADS AND WATERWAYS\n",
    "\n",
    "# Get all the roads in Manila\n",
    "road = ox.graph_to_gdfs(CITY_GRAPH,nodes=False, edges=True)\n",
    "\n",
    "\n",
    "# Get all the roads that are not junctions (ex. Roundabouts, intersection, etc.)\n",
    "filtered_roads = road[road['junction'].isna()]\n",
    "\n",
    "# Separate roads whose highway types are only one value and those that are more than 1 (lists)\n",
    "rows_with_lists = filtered_roads[filtered_roads['highway'].apply(lambda x: isinstance(x, list))]\n",
    "rows_with_strings = filtered_roads[filtered_roads['highway'].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "# Allowed Roads to place stops\n",
    "filter_options = ['primary', 'secondary', 'tertiary', 'trunk', 'unclassified']\n",
    "\n",
    "# To separate zones\n",
    "separation_options = ['primary', 'secondary', 'tertiary', 'unclassified']\n",
    "\n",
    "# Get the roads whose widths are above the threshold\n",
    "def check_list(lst):\n",
    "    return any(x in filter_options for x in lst)\n",
    "\n",
    "# Download OpenStreetMap data for the area of interest\n",
    "waterways = ox.features_from_place(select_city, tags={'waterway': True})\n",
    "filtered_rivers = waterways[waterways['waterway'].isin(['river'])]\n",
    "filtered_streams = waterways[waterways['waterway'].isin(['stream'])]\n",
    "\n",
    "# Get all the roads with the allowed road types\n",
    "filtered_roads_strings = rows_with_strings.loc[rows_with_strings['highway'].isin(filter_options)] \n",
    "filtered_roads_lists = rows_with_lists[rows_with_lists['highway'].apply(check_list)]\n",
    "\n",
    "# Create spatial index\n",
    "filtered_roads_strings_sindex = filtered_roads_strings.sindex\n",
    "filtered_roads_lists_sindex = filtered_roads_lists.sindex\n",
    "filtered_rivers_sindex = filtered_rivers.sindex\n",
    "filtered_streams_sindex = filtered_streams.sindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will find which road or river intersects between amenities\n",
    "\n",
    "def find_intersecting_features(line):\n",
    "    # Check intersection with filtered roads\n",
    "    possible_matches_roads = filtered_roads_strings.iloc[list(filtered_roads_strings_sindex.intersection(line.bounds))]\n",
    "    for index, row in possible_matches_roads.iterrows():\n",
    "        if line.intersects(row['geometry']) and row['highway'] in separation_options:\n",
    "            return True\n",
    "\n",
    "    possible_matches_lists = filtered_roads_lists.iloc[list(filtered_roads_lists_sindex.intersection(line.bounds))]\n",
    "    for index, row in possible_matches_lists.iterrows():\n",
    "        if line.intersects(row['geometry']):\n",
    "            list_highway = row['highway']\n",
    "            if any(x in separation_options for x in list_highway):\n",
    "                return True\n",
    "    \n",
    "    # Check intersection with filtered rivers\n",
    "    possible_matches_rivers = filtered_rivers.iloc[list(filtered_rivers_sindex.intersection(line.bounds))]\n",
    "    for index, row in possible_matches_rivers.iterrows():\n",
    "        if line.intersects(row['geometry']):\n",
    "            return True\n",
    "\n",
    "    # Check intersection with filtered streams\n",
    "    possible_matches_streams = filtered_streams.iloc[list(filtered_streams_sindex.intersection(line.bounds))]\n",
    "    for index, row in possible_matches_streams.iterrows():\n",
    "        if line.intersects(row['geometry']):\n",
    "            return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD POINTS TO NX GRAPH\n",
    "# Function to add only points to the networkX graph\n",
    "# The other functions focuses on adding polygons, this function just iterates and adds points\n",
    "\n",
    "def add_points_to_graph(graph, graph_to_add):\n",
    "    for node_key, node_data in graph.nodes.items():\n",
    "        if 'geometry' in node_data and node_data['geometry'].geom_type in ['Point']:   \n",
    "            graph_to_add.add_node(node_key, geometry=node_data['geometry'], name=node_data['name'], lat=node_data['lat'], amenity=node_data['amenity'],\n",
    "                                lon=node_data['lon'])\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CREATING STOPS\n",
    "# It should return a list of coordinates/nodes for stop and a graph of stops\n",
    "# if residential area, check if the population density\n",
    "\n",
    "# Global Variables used:\n",
    "# list_of_stops - List of stops\n",
    "# graph_of_stops - graph of all stops placed\n",
    "# CITY_GRAPH - graph of the city road networks\n",
    "import random\n",
    "\n",
    "gdf_nodes = ox.graph_to_gdfs(CITY_GRAPH, nodes=True, edges=False)\n",
    "gdf_edges = ox.graph_to_gdfs(CITY_GRAPH, nodes=False, edges=True)\n",
    "\n",
    "def place_stops_on_roads(amenity_graph, graph_of_stops, list_of_stops):\n",
    "    global CITY_GRAPH\n",
    "    list_relevant_edges_set = []\n",
    "    string_relevant_edges_set = []\n",
    "    \n",
    "    stop_id = 0\n",
    "    for node_key, node_data in amenity_graph.nodes(data=True):\n",
    "        # All tranportation points are automatically stops\n",
    "        if node_data['geometry'].geom_type in ['Point']:\n",
    "            if node_data['amenity'] == 'transportation':\n",
    "                # Find the nearest edge to the location point\n",
    "                nearest_edge = ox.distance.nearest_edges(CITY_GRAPH, X=node_data['lon'], Y=node_data['lat'], return_dist=False)\n",
    "\n",
    "                # Get the coordinates of the nearest edge\n",
    "                line = gdf_edges.loc[nearest_edge]['geometry']\n",
    "                \n",
    "                edge_length = line.length\n",
    "                random_position = random.uniform(0.4 * edge_length, edge_length * 0.6)\n",
    "\n",
    "                # Calculate the coordinate along the edge at the random position\n",
    "                point_on_road = calculate_coordinate_along_edge(line, random_position)\n",
    "                \n",
    "                # Add the stop to graph and list\n",
    "                lon = point_on_road[0]\n",
    "                lat = point_on_road[1]\n",
    "                isTranspo = True\n",
    "                \n",
    "                city_node = ox.distance.nearest_nodes(CITY_GRAPH, lon, lat)\n",
    "                \n",
    "                if city_node is not None:\n",
    "                    graph_of_stops.add_node(stop_id, lon=lon, lat=lat, isTranspo=isTranspo)\n",
    "                    list_of_stops.append(stopCandidate(lat, lon, True, stop_id, 0, city_node))\n",
    "                    stop_id += 1\n",
    "                \n",
    "        elif node_data['geometry'].geom_type in ['MultiPolygon', 'Polygon']:\n",
    "            # Get the roads surrounding and inside the node polygons\n",
    "            buffer_poly = node_data['geometry'].buffer(meters_to_degrees(30))\n",
    "            relevant_edges = get_relevant_edges(buffer_poly, list_relevant_edges_set, string_relevant_edges_set)\n",
    "            \n",
    "            # Calculate the number of stops based on node size and population density\n",
    "            node_size = degrees_to_meters(node_data['geometry'].area)\n",
    "            \n",
    "            # Place stops randomly on these roads\n",
    "            stop_id = place_stops_along_edges(relevant_edges, buffer_poly, node_size, graph_of_stops, list_of_stops, stop_id)\n",
    "            \n",
    "\n",
    "def get_relevant_edges(polygon, list_relevant_edges_set, string_relevant_edges_set):\n",
    "    relevant_edges = []\n",
    "    \n",
    "    # Check intersection with filtered roads\n",
    "    possible_matches_roads = filtered_roads_strings.iloc[list(filtered_roads_strings_sindex.intersection(polygon.bounds))]\n",
    "    for index, row in possible_matches_roads.iterrows():\n",
    "        if polygon.intersects(row['geometry']) and row['highway'] in filter_options:\n",
    "            row_name = row['name']\n",
    "            if row_name not in string_relevant_edges_set:\n",
    "                relevant_edges.append(row)\n",
    "                string_relevant_edges_set.append(row_name)\n",
    "\n",
    "\n",
    "    possible_matches_lists = filtered_roads_lists.iloc[list(filtered_roads_lists_sindex.intersection(polygon.bounds))]\n",
    "    for index, row in possible_matches_lists.iterrows():\n",
    "        if polygon.intersects(row['geometry']):\n",
    "            list_highway = row['highway']\n",
    "            if any(x in filter_options for x in list_highway):\n",
    "                row_name = row['name']\n",
    "                if row_name not in list_relevant_edges_set:\n",
    "                    relevant_edges.append(row)\n",
    "                    list_relevant_edges_set.append(row_name)\n",
    "                \n",
    "    return relevant_edges\n",
    "\n",
    "def place_stops_along_edges(edges, polygon, node_size, graph_of_stops, list_of_stops, stop_id):\n",
    "    # Place stops randomly along the edges within the polygon\n",
    "    \n",
    "    if len(edges) > 0:\n",
    "        for edge in edges:\n",
    "            # Calculate the intersection between the edge and the polygon\n",
    "            intersecting_line = edge['geometry'].intersection(polygon)\n",
    "            if intersecting_line.is_empty:\n",
    "                continue\n",
    "\n",
    "            # Calculate the length of the intersecting part of the edge\n",
    "            intersecting_length = intersecting_line.length\n",
    "\n",
    "            # Generate a random position along the intersecting part of the edge\n",
    "            random_position = random.uniform(0.4 * intersecting_length, intersecting_length * 0.6)\n",
    "\n",
    "            # Calculate the coordinate along the edge at the random position\n",
    "            stop_location = calculate_coordinate_along_edge(intersecting_line, random_position)\n",
    "        \n",
    "            \n",
    "            # If there is an existing node in the main graph, then add it to the list and the stop graph\n",
    "            lon = stop_location[0]\n",
    "            lat = stop_location[1]\n",
    "            isTranspo = False\n",
    "            \n",
    "            city_node = ox.distance.nearest_nodes(CITY_GRAPH, lon, lat)\n",
    "            \n",
    "            if city_node is not None:\n",
    "                graph_of_stops.add_node(stop_id, lon=lon, lat=lat, isTranspo=isTranspo)\n",
    "                list_of_stops.append(stopCandidate(lat, lon, False, stop_id, node_size, city_node))\n",
    "                stop_id += 1\n",
    "                    \n",
    "    return stop_id\n",
    "        \n",
    "\n",
    "def calculate_coordinate_along_edge(edge, position):\n",
    "    # Calculate the coordinate along the edge at the given position\n",
    "    point = edge.interpolate(position)\n",
    "    return point.x, point.y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Route Network Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V2 - Graph with the snapping function\n",
    "# Generate Route Network from connected routes\n",
    "\n",
    "# Global Variables used:\n",
    "# graph_of_stops - Graph of stops that will be used to create routes\n",
    "def generate_route_network(stop_nodes, max_walking_dist, max_stops, max_routes, graph_of_stops, city_area_sum, connection_type=\"Default\"):\n",
    "    network_stop_list = []\n",
    "    overall_graph = nx.MultiDiGraph() # The route network graph\n",
    "    next_nodes = [n for n in stop_nodes]\n",
    "    enable_stop_nodes(next_nodes)\n",
    "    route_network = []\n",
    "    num_routes = 0 # Count number of routes\n",
    "\n",
    "    while num_routes < max_routes:\n",
    "        route_id = f'{num_routes}-A' # This will be used as a key for the edge\n",
    "        next_nodes = [n for n in stop_nodes] # Resets the list of nodes so that nodes can be reused in a different\n",
    "        selected_node = random.choice(next_nodes) # For the first node\n",
    "        next_nodes.remove(selected_node)\n",
    "        route_gen, route_stop_list = generate_route(selected_node, next_nodes, max_walking_dist, connection_type, max_stops, overall_graph, city_area_sum, route_id, network_stop_list)\n",
    "        \n",
    "        if len(route_gen) > 1:\n",
    "            # A route is a list of connections between two nodes\n",
    "            for pair in route_stop_list:\n",
    "                if pair[0] not in network_stop_list:\n",
    "                    network_stop_list.append(pair[0])\n",
    "                if pair[1] not in network_stop_list:\n",
    "                    network_stop_list.append(pair[1])\n",
    "            \n",
    "            new_route = Route(route_gen, route_id) # Create a new route object to store the Route ID and the route itself\n",
    "            \n",
    "            add_to_graph(route_gen, route_stop_list, overall_graph, graph_of_stops, route_id)\n",
    "            \n",
    "            route_network.append(new_route)   \n",
    "            num_routes += 1\n",
    "               \n",
    "    return route_network, overall_graph, network_stop_list\n",
    "\n",
    "def add_to_graph(route, route_stop_list, overall_graph, graph_of_stops, route_id):\n",
    "    \n",
    "    # Directly add nodes based on node identifiers\n",
    "    for connection in route:\n",
    "        index = route.index(connection)\n",
    "        stop_pair = route_stop_list[index]\n",
    "        overall_graph.add_node(stop_pair[0], **graph_of_stops.nodes[stop_pair[0]]) # The origin\n",
    "        overall_graph.add_node(stop_pair[1], **graph_of_stops.nodes[stop_pair[1]]) # The destination\n",
    "        \n",
    "        distance_travelled = 0\n",
    "        # Get the total distance from point A to point B\n",
    "        for i in range(len(connection)-1):\n",
    "            node_data = CITY_GRAPH.nodes[connection[i]]\n",
    "            next_node_data = CITY_GRAPH.nodes[connection[i+1]]\n",
    "            distance_travelled += haversine(node_data['y'], node_data['x'], next_node_data['y'], next_node_data['x'])\n",
    "        \n",
    "        # Finally, Add the edge\n",
    "        overall_graph.add_edge(stop_pair[0], stop_pair[1], key=route_id, road_path = connection, distance = distance_travelled) # Add edge\n",
    "        \n",
    "\n",
    "# Generate route from stop nodes\n",
    "def generate_route(source, next_nodes, max_walking_dist, connection_type, max_stops, network_graph, city_area_sum, route_id, network_stop_list):\n",
    "    route_stop_list = []\n",
    "    short_route_list = [] # List of nx.shortest_path results\n",
    "    totalDistance = 0\n",
    "    orig_node = source\n",
    "    num_stops = 0 # Count number of stops\n",
    "    \n",
    "    # CONFIGURATION\n",
    "    max_tries = 3 # This is the max number of tries before breaking the loop || To avoid longer runtimes\n",
    "    current_tries = 0\n",
    "\n",
    "    while totalDistance < MAX_DISTANCE and num_stops < max_stops:\n",
    "        \n",
    "        #print(f\"Selected node is {selected_node.getLat()}, {selected_node.getLong()}\")\n",
    "        enable_surrounding_nodes(next_nodes)\n",
    "        disable_surrounding_nodes(next_nodes, orig_node, max_walking_dist)\n",
    "        enabled_nodes = [n for n in next_nodes if n.enabled]\n",
    "        if len(enabled_nodes) == 0:\n",
    "            break\n",
    "        \n",
    "        #print(f\"{len(enabled_nodes)} nodes out of {len(next_nodes)}\")\n",
    "        dest_node = get_enabled_node_with_highest_edge_probability(orig_node, enabled_nodes, connection_type, city_area_sum, network_graph) # Getting the destination node\n",
    "        \n",
    "        if (dest_node == None or dest_node.id == orig_node.id):\n",
    "            break\n",
    "        \n",
    "        # Remove it as a candidate\n",
    "        next_nodes.remove(dest_node)\n",
    "        \n",
    "        # This is to check if there is already an exiting edge in the route. If true, then it should not connect\n",
    "        connection_edge1 = network_graph.has_edge(orig_node.id, dest_node.id, route_id)\n",
    "        connection_edge2 = network_graph.has_edge(dest_node.id, orig_node.id, route_id)\n",
    "        \n",
    "        # If there is no possible path or there is atleast one existing edge, do not connect\n",
    "        if not nx.has_path(CITY_GRAPH, orig_node.node_id, dest_node.node_id) or connection_edge1 or connection_edge2:\n",
    "            current_tries += 1\n",
    "            if current_tries == max_tries:\n",
    "                break\n",
    "        else:\n",
    "            shortest_route = nx.shortest_path(CITY_GRAPH, orig_node.node_id, dest_node.node_id)\n",
    "            distance_travelled = 0\n",
    "            # Get the total distance from point A to point B\n",
    "            for i in range(len(shortest_route)-1):\n",
    "                node_data = CITY_GRAPH.nodes[shortest_route[i]]\n",
    "                next_node_data = CITY_GRAPH.nodes[shortest_route[i+1]]\n",
    "                \n",
    "                distance_travelled += haversine(node_data['y'], node_data['x'], next_node_data['y'], next_node_data['x'])\n",
    "\n",
    "            # Checks if it does not exceed the max distance\n",
    "            if totalDistance + distance_travelled <= MAX_DISTANCE:\n",
    "                \n",
    "                # Updating local degree count used for connection probability\n",
    "                orig_node.degree += 1\n",
    "                dest_node.degree += 1\n",
    "                \n",
    "                totalDistance += distance_travelled\n",
    "                short_route_list.append(shortest_route)\n",
    "                route_stop_list.append([orig_node.id, dest_node.id])\n",
    "                num_stops += 1\n",
    "                \n",
    "                orig_node = dest_node # Now change the origin to the destination\n",
    "            else:\n",
    "                break\n",
    "    if len(short_route_list) > 4 and totalDistance > 7:\n",
    "        print(f\"# OF CONNECTIONS AND TOTAL DISTANCE: {len(short_route_list)} - {totalDistance}\")\n",
    "        return short_route_list, route_stop_list\n",
    "    \n",
    "    else:\n",
    "        return [], []\n",
    "\n",
    "# Disable surrounding nodes\n",
    "def disable_surrounding_nodes(next_nodes, source_node, max_distance):\n",
    "    max_radius = 2000 # This is max radius in which all nodes outside will be disabled\n",
    "    source = (source_node.getLat(), source_node.getLong())\n",
    "    \n",
    "    for node in next_nodes:\n",
    "        point = (node.getLat(), node.getLong())\n",
    "        distance_to_source = geodesic(source, point).meters\n",
    "        if distance_to_source <= max_distance or distance_to_source > max_radius:\n",
    "            node.disable()\n",
    "            \n",
    "# Enable surrounding nodes\n",
    "def enable_surrounding_nodes(next_nodes):\n",
    "    for node in next_nodes:\n",
    "        node.enable()\n",
    "        \n",
    "def get_enabled_node_with_highest_edge_probability(source_node, enabled_nodes, connection_type, city_area_sum, network_graph):\n",
    "\n",
    "    prob_list = []\n",
    "    for n in enabled_nodes:\n",
    "        edge_prob = get_edge_probability(source_node, n, len(enabled_nodes), connection_type, city_area_sum, network_graph)\n",
    "        prob_list.append(edge_prob)\n",
    "    \n",
    "    \n",
    "    min_score = min(prob_list)\n",
    "    if min_score < 0: # Shift the scores to ensure all are positive\n",
    "        prob_list = [score - min_score for score in prob_list]\n",
    "    total = sum(prob_list)\n",
    "    selection_p = [score / total for score in prob_list]\n",
    "    \n",
    "    chosen_node = np.random.choice(enabled_nodes, 1, p=selection_p)[0]    \n",
    "\n",
    "    return chosen_node\n",
    "\n",
    "# Probabilities of candidate nodes based on distance, area, node degree, and if transpo stop\n",
    "def get_edge_probability(source, destination, normalization_factor, connection_type, city_area_sum, network_graph):\n",
    "    source_coord = [source.getLat(), source.getLong()]\n",
    "    dest_coord = [destination.getLat(), destination.getLong()]\n",
    "\n",
    "    base_prob = exp(-(euclidean(source_coord, dest_coord))) / float(normalization_factor)\n",
    "    \n",
    "    # If there is already an existing edge between source and destination, decrease the probability\n",
    "    if network_graph.has_edge(source.id, destination.id):\n",
    "        base_prob *= 0.5 # The penalty\n",
    "\n",
    "    if connection_type == \"Default\":\n",
    "        if destination.isTranspo:\n",
    "            return base_prob * 1.5\n",
    "        return base_prob\n",
    "    elif connection_type == \"Area\":\n",
    "        if destination.isTranspo:\n",
    "            return base_prob * 1.5\n",
    "        return base_prob * (1 + (destination.getArea() / city_area_sum))\n",
    "    elif connection_type == \"Degree\":\n",
    "        if destination.isTranspo:\n",
    "            return base_prob * 1.5 * (1 + (destination.getDegree() / 10))\n",
    "        return base_prob * (1 + (destination.getDegree() / 10))\n",
    "\n",
    "def radius(stops):\n",
    "    circles = []\n",
    "    for stop in stops:\n",
    "        stop_point = Point(stop[1], stop[0])  # Create a Point object from [lat, lon] coordinates\n",
    "        circle = stop_point.buffer(radius / 111000)  # Buffer the Point to create a circle (assuming 1 degree is approximately 111000 meters)\n",
    "        circles.append(circle)\n",
    "    return circles\n",
    "\n",
    "def enable_stop_nodes(stop_nodes):\n",
    "    for n in stop_nodes:\n",
    "        n.enable()\n",
    "\n",
    "def all_nodes_disabled(stop_nodes):\n",
    "    return get_num_disabled(stop_nodes) == len(stop_nodes)\n",
    "\n",
    "def get_num_disabled(stop_nodes):\n",
    "    return sum(1 for n in stop_nodes if not n.enabled)\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Use geopy's geodesic function to calculate the distance\n",
    "    distance = geodesic((lat1, lon1), (lat2, lon2)).kilometers\n",
    "    return distance\n",
    "\n",
    "# Markers for visualization purposes\n",
    "def add_markers(used_stops, network_graph):\n",
    "    for stop in used_stops:\n",
    "        #popup_text = f\"Name: {stop.name}<br>Type: {stop.a_type}<br>Coordinates: {stop.getLat()}, {stop.getLong()}\"\n",
    "        lat = network_graph.nodes[stop]['lat']\n",
    "        long = network_graph.nodes[stop]['lon']\n",
    "        folium.Marker(location=[lat, long]).add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: CONNECT THE ROUTE REVERSAL\n",
    "# Reverse route traversal\n",
    "def get_reverse_route(network):\n",
    "    reverse_route_network = []\n",
    "    \n",
    "    for route in network.routes:\n",
    "        index = len(route)-1\n",
    "        \n",
    "        reverse_route = []\n",
    "        totalDistance = 0\n",
    "        while index >= 0:\n",
    "            connection = route[index] # Get the connection\n",
    "            rev_origin = connection[-1]\n",
    "            rev_dest = connection[0]\n",
    "            \n",
    "            if nx.has_path(CITY_GRAPH, rev_origin, rev_dest):\n",
    "                rev_path = nx.shortest_path(CITY_GRAPH, rev_origin, rev_dest) # Get the path\n",
    "                \n",
    "                distance_travelled = 0\n",
    "                # Get the total distance from point A to point B\n",
    "                for i in range(len(rev_path)-1):\n",
    "                    node_data = CITY_GRAPH.nodes[rev_path[i]]\n",
    "                    next_node_data = CITY_GRAPH.nodes[rev_path[i+1]]\n",
    "                    distance_travelled += haversine(node_data['y'], node_data['x'], next_node_data['y'], next_node_data['x'])\n",
    "                    \n",
    "                totalDistance += distance_travelled\n",
    "                \n",
    "                reverse_route.append(rev_path)\n",
    "                index -= 1\n",
    "            else:\n",
    "                # there is no reverse route for this so append nothing to the \n",
    "                reverse_route_network.append([])\n",
    "                break\n",
    "    \n",
    "        # Checks if it does not exceed the max distance\n",
    "        if totalDistance <= MAX_DISTANCE:\n",
    "            reverse_route_network.append(reverse_route)\n",
    "        else:\n",
    "            reverse_route_network.append([])\n",
    "            \n",
    "    return reverse_route_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GA VERSION 2 - Finding the optimal Network\n",
    "\n",
    "# This implementation takes only 2 parents from the whole generation and generates the population from them\n",
    "# Instead of the what's in the paper that says the whole population will go through crossovers and mutations\n",
    "# Cite Nayeem et al for GA with elitism and growing population size\n",
    "def perform_genetic_algorithm(network_population, graph_of_stops, mutation_probability, num_mutations_probabilities, num_failure_removal,\n",
    "                                      weight_random_failure, weight_targeted_failure, weight_connectivity, plateau_threshold, plateau_count_limit, max_gens):\n",
    "    \n",
    "    max_fitness_score = 0 # This is the max score of the current population\n",
    "    max_score_list = [] # This is to store all the max scores of each generation\n",
    "    #prev_avg_fitness_score = None\n",
    "    prev_max_fitness_score = None\n",
    "    plateau_counter = 0\n",
    "    most_optimal_gen = None # This is to store the most optimal generation\n",
    "    current_highest_max_score = 0 # This will help determine the most optimal generation\n",
    "    current_highest_avg_score = 0 # This will help determine the most optimal generation\n",
    "    \n",
    "    generation_num = 1\n",
    "\n",
    "    while True:\n",
    "        print(f\"Generation {generation_num}\", flush=True)\n",
    "        \n",
    "        # Evaluate the fitness of each network in the population\n",
    "        for network in network_population:\n",
    "            network_graph = network.graph\n",
    "            if network.fitness_score == 0:\n",
    "                network.fitness_score = compute_fitness_score(network_graph, num_failure_removal, weight_random_failure, weight_targeted_failure, weight_connectivity)\n",
    "            \n",
    "        # Sort the network population by fitness score\n",
    "        sorted_network_population = sorted(network_population, key=lambda x: x.fitness_score, reverse=True)\n",
    "        fitness_scores = [network.fitness_score for network in sorted_network_population]\n",
    "        \n",
    "        # for printing purposes in order\n",
    "        for network in sorted_network_population:\n",
    "            print(f\"Network Score: {network.fitness_score}\", flush=True)\n",
    "        \n",
    "        # The max network score of this generation\n",
    "        max_fitness_score = max(fitness_scores)\n",
    "        max_score_list.append(max_fitness_score)\n",
    "        print(f\"Generation {generation_num} Max Score: {max_fitness_score}\", flush=True)\n",
    "        \n",
    "        # The average network score of this generation\n",
    "        total_score = sum(fitness_scores)\n",
    "        average_score = total_score / len(fitness_scores)\n",
    "        print(f\"Generation {generation_num} Average Score: {average_score}\", flush=True)\n",
    "        \n",
    "        # Check if the score is optimal. If it is, then stop\n",
    "        # if max_fitness_score >= optimal_fitness_score:\n",
    "        #     print(f\"WE FOUND THE OPTIMAL NETWORK IN GENERATION {generation_num}\")\n",
    "        #     most_optimal_network = sorted_network_population[0]\n",
    "        #     print(f\"Fitness Score of the most optimal network: {most_optimal_network.fitness_score}\")\n",
    "        #     break\n",
    "        \n",
    "        # Check if this generation has the highest max fitness score and highest average score\n",
    "        if max_fitness_score >= current_highest_max_score and average_score >= current_highest_avg_score:\n",
    "            current_highest_avg_score = average_score\n",
    "            current_highest_max_score = max_fitness_score\n",
    "            most_optimal_gen = sorted_network_population\n",
    "        \n",
    "        # Check if score plateaus based on max score\n",
    "        if prev_max_fitness_score is not None and abs(max_fitness_score - prev_max_fitness_score) <= plateau_threshold:\n",
    "            plateau_counter += 1\n",
    "            if plateau_counter >= plateau_count_limit:\n",
    "                print(f\"Plateau detected in generation {generation_num}. Stopping.\")\n",
    "                break\n",
    "        else:\n",
    "            plateau_counter = 0\n",
    "        prev_max_fitness_score = max_fitness_score\n",
    "        \n",
    "        \n",
    "        # Choosing 10% of the networks to be parents using Roulette Wheel Selection\n",
    "        #print(\"Choosing parents...\", flush=True)\n",
    "        \n",
    "        #Getting the number of parents to be selected\n",
    "        num_parents = int(len(network_population) * 0.10)\n",
    "        if num_parents % 2 == 1:\n",
    "            num_parents += 1\n",
    "        \n",
    "        # List of parents\n",
    "        parent_networks = []\n",
    "        #print(\"NUM PARENTS \", num_parents)\n",
    "        for i in range(num_parents):\n",
    "            # Get the list of all fitness scores\n",
    "            fitness_scores = [network.fitness_score for network in sorted_network_population]\n",
    "            \n",
    "            # Shift the scores to ensure all are positive\n",
    "            min_score = min(fitness_scores)\n",
    "            if min_score < 0:\n",
    "                fitness_scores = [score - min_score for score in fitness_scores]\n",
    "            \n",
    "            # Get the probabilities\n",
    "            total = sum(fitness_scores)\n",
    "            selection_p = [score / total for score in fitness_scores]\n",
    "            \n",
    "            # Getting the parent\n",
    "            chosen_parent = np.random.choice(sorted_network_population, 1, p=selection_p)[0]\n",
    "            #print(f\"parent {i} Score, \", chosen_parent.fitness_score, flush=True)\n",
    "            sorted_network_population.remove(chosen_parent)\n",
    "            parent_networks.append(chosen_parent)\n",
    "            \n",
    "            \n",
    "        # Add back all the removed parent networks\n",
    "        sorted_network_population.extend(parent_networks)\n",
    "        \n",
    "        # Sort the networks by fitness function again\n",
    "        sorted_network_population = sorted(network_population, key=lambda x: x.fitness_score, reverse=True)\n",
    "        \n",
    "        # Pairing the parents\n",
    "        parent_pairs = [parent_networks[i:i+2] for i in range(0, len(parent_networks), 2)]\n",
    "\n",
    "        # Each parent pair will now produce children\n",
    "        #print(\"GETTING CHILDREN\", flush=True)\n",
    "        children_networks = []\n",
    "        for pair in parent_pairs:\n",
    "            parent1 = pair[0]\n",
    "            parent2 = pair[1]\n",
    "                   \n",
    "            # Get 2 children from crossovers between the two parents\n",
    "            child1, child2, is_different = crossover_split_index(parent1, parent2)\n",
    "            \n",
    "            # Getting the number of mutations. If the children are entirely different from their parents, there should be atleast one mutation\n",
    "            if is_different:\n",
    "                index_array = list(range(len(num_mutations_probabilities)))\n",
    "                num_mutations = np.random.choice(index_array, 1, p=num_mutations_probabilities)[0]\n",
    "            else:\n",
    "                temp_mutation_probs = [0, 0.1, 0.4, 0.3, 0.2]\n",
    "                index_array = list(range(len(temp_mutation_probs)))\n",
    "                num_mutations = np.random.choice(index_array, 1, p=temp_mutation_probs)[0]\n",
    "            \n",
    "            # # Getting the number of mutations.\n",
    "            # index_array = list(range(len(num_mutations_probabilities)))\n",
    "            # num_mutations = np.random.choice(index_array, 1, p=num_mutations_probabilities)[0]\n",
    "\n",
    "            for j in range(num_mutations):\n",
    "                # Apply mutations to the children based on mutation probability hyperparameter\n",
    "                if np.random.rand() < mutation_probability:\n",
    "                    mutate(child1, graph_of_stops)\n",
    "                    \n",
    "                if np.random.rand() < mutation_probability:\n",
    "                    mutate(child2, graph_of_stops)\n",
    "            \n",
    "            # Add the children to the list of children\n",
    "            children_networks.append(child1)\n",
    "            children_networks.append(child2)\n",
    "            \n",
    "        \n",
    "        # Preparing the next generation\n",
    "        \n",
    "        # Remove the lowest scored networks and replace it with the children\n",
    "        network_population = sorted_network_population[:-len(children_networks)]\n",
    "        network_population.extend(children_networks)\n",
    "        \n",
    "        # Increment the generation number\n",
    "        generation_num += 1\n",
    "        if generation_num > max_gens:\n",
    "                print(f\"Reached maximum generation count of {generation_num}. Stopping.\")\n",
    "                break\n",
    "        print()\n",
    "        \n",
    "    if most_optimal_gen is not None:\n",
    "        most_optimal_gen = sorted(most_optimal_gen, key=lambda x: x.fitness_score, reverse=True)\n",
    "\n",
    "    print(f\"Highest score of all generations: {max(max_score_list)}\")\n",
    "    return most_optimal_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V2 - Crossover routes should not have the same routes\n",
    "# CROSSOVER SPLIT INDEX FUNCTION\n",
    "\n",
    "def crossover_split_index(network1, network2):\n",
    "    # Split both networks based on which routes do not have the same connections\n",
    "    # network.routes is a list of routes or list of lists of shortest_path\n",
    "    routes_same1 = []\n",
    "    routes_not_same1 = []\n",
    "    routes_same2 = []\n",
    "    routes_not_same2 = []\n",
    "    \n",
    "    # Standardize and store the routes of network2 for comparison\n",
    "    network1_routes_standardized = {standardize_route(route.route): route for route in network1.routes}\n",
    "    network2_routes_standardized = {standardize_route(route.route): route for route in network2.routes}\n",
    "    \n",
    "    # Compare each route in network1 with routes in network2\n",
    "    for route in network1.routes:\n",
    "        standardized_route1 = standardize_route(route.route)\n",
    "        if standardized_route1 in network2_routes_standardized:\n",
    "            routes_same1.append(route)\n",
    "        else:\n",
    "            routes_not_same1.append(route)\n",
    "            \n",
    "    for route in network2.routes:\n",
    "        standardized_route2 = standardize_route(route.route)\n",
    "        if standardized_route2 in network1_routes_standardized:\n",
    "            routes_same2.append(route)\n",
    "        else:\n",
    "            routes_not_same2.append(route)\n",
    "    \n",
    "    # Create new graphs for the left and right sides\n",
    "    route_graph1 = nx.MultiDiGraph()\n",
    "    route_graph2 = nx.MultiDiGraph()\n",
    "    \n",
    "    route_network1 = []\n",
    "    route_network2 = []\n",
    "    \n",
    "    used_stops1 = []\n",
    "    used_stops2 = []\n",
    "    \n",
    "    conn_type1 = network1.conn_type\n",
    "    conn_type2 = network2.conn_type\n",
    "\n",
    "    walk_type1 = network1.walk_distance\n",
    "    walk_type2 = network2.walk_distance\n",
    "    \n",
    "    # If all have similar connections, then do not split\n",
    "    if len(routes_not_same1) == 0:\n",
    "        test_graph_net1 = network1.graph.copy()\n",
    "        test_routes_net1 = [copy.deepcopy(r) for r in network1.routes]\n",
    "        test_stops_net1 = [copy.deepcopy(s) for s in network1.stops]\n",
    "        child1 = networkObj(test_routes_net1, test_stops_net1, test_graph_net1, network1.conn_type, network1.walk_distance)\n",
    "\n",
    "        test_graph_net2 = network2.graph.copy()\n",
    "        test_routes_net2 = [copy.deepcopy(r) for r in network2.routes]\n",
    "        test_stops_net2 = [copy.deepcopy(s) for s in network2.stops]\n",
    "        child2 = networkObj(test_routes_net2, test_stops_net2, test_graph_net2, network2.conn_type, network2.walk_distance)\n",
    "        \n",
    "        #print(\"THERE ARE NO DIFFERENT ROUTES\")\n",
    "        is_different = False\n",
    "        \n",
    "    # If all routes of both networks are different, then split at a random index\n",
    "    elif len(routes_same1) == 0:\n",
    "        # Split both networks at a random index\n",
    "        # network.routes is a list of routes or list of lists of shortest_path\n",
    "        if len(network1.routes) < len(network2.routes):\n",
    "            split_index = random.randint(0, len(network2.routes)-1)\n",
    "        else:\n",
    "            split_index = random.randint(0, len(network1.routes)-1)\n",
    "            \n",
    "        count = 0 # This is the index count, this will also serve as the new route ID\n",
    "        for route in network1.routes:\n",
    "            new_route_id = f\"{count}-A\"\n",
    "            new_route = Route([copy.deepcopy(r) for r in route.route],new_route_id)\n",
    "            \n",
    "            if count < split_index: # if 0-split_index -> child1 graph\n",
    "                for connection in route.route:\n",
    "                    route_graph1.add_node(connection[0], **network1.graph.nodes[connection[0]])\n",
    "                    if connection[0] not in used_stops1:\n",
    "                        used_stops1.append(connection[0])\n",
    "                        \n",
    "                    route_graph1.add_node(connection[-1], **network1.graph.nodes[connection[-1]])\n",
    "                    if connection[-1] not in used_stops1:\n",
    "                        used_stops1.append(connection[-1])\n",
    "                    \n",
    "                    route_graph1.add_edge(connection[0], connection[-1], key=new_route_id, **network1.graph.get_edge_data(connection[0], connection[-1], route.route_id))\n",
    "                route_network1.append(new_route)\n",
    "                \n",
    "                    \n",
    "            else: # else its for child2 graph\n",
    "                for connection in route.route:\n",
    "                    route_graph2.add_node(connection[0], **network1.graph.nodes[connection[0]])\n",
    "                    if connection[0] not in used_stops2:\n",
    "                        used_stops2.append(connection[0])\n",
    "                        \n",
    "                    route_graph2.add_node(connection[-1], **network1.graph.nodes[connection[-1]])\n",
    "                    if connection[-1] not in used_stops2:\n",
    "                        used_stops2.append(connection[-1])\n",
    "                    \n",
    "                    route_graph2.add_edge(connection[0], connection[-1], key=new_route_id, **network1.graph.get_edge_data(connection[0], connection[-1], route.route_id))\n",
    "                route_network2.append(new_route)\n",
    "            count += 1\n",
    "            \n",
    "        count = 0\n",
    "        for route in network2.routes:\n",
    "            new_route_id = f\"{count}-A\"\n",
    "            new_route = Route([copy.deepcopy(r) for r in route.route],new_route_id)\n",
    "            \n",
    "            if count >= split_index: # if split_index-end -> child1 graph\n",
    "                for connection in route.route:\n",
    "                    route_graph1.add_node(connection[0], **network2.graph.nodes[connection[0]])\n",
    "                    if connection[0] not in used_stops1:\n",
    "                        used_stops1.append(connection[0])\n",
    "                        \n",
    "                    route_graph1.add_node(connection[-1], **network2.graph.nodes[connection[-1]])\n",
    "                    if connection[-1] not in used_stops1:\n",
    "                        used_stops1.append(connection[-1])\n",
    "                    \n",
    "                    route_graph1.add_edge(connection[0], connection[-1], key=new_route_id, **network2.graph.get_edge_data(connection[0], connection[-1], route.route_id))\n",
    "                route_network1.append(new_route)\n",
    "                    \n",
    "                    \n",
    "            else: # else its for child2 graph\n",
    "                for connection in route.route:\n",
    "                    route_graph2.add_node(connection[0], **network2.graph.nodes[connection[0]])\n",
    "                    if connection[0] not in used_stops2:\n",
    "                        used_stops2.append(connection[0])\n",
    "                        \n",
    "                    route_graph2.add_node(connection[-1], **network2.graph.nodes[connection[-1]])\n",
    "                    if connection[-1] not in used_stops2:\n",
    "                        used_stops2.append(connection[-1])\n",
    "                    \n",
    "                    route_graph2.add_edge(connection[0], connection[-1], key=new_route_id, **network2.graph.get_edge_data(connection[0], connection[-1], route.route_id))\n",
    "                route_network2.append(new_route)\n",
    "            count += 1\n",
    "        \n",
    "        child1 = networkObj(route_network1, used_stops1, route_graph1, conn_type1, walk_type1)\n",
    "        child2 = networkObj(route_network2, used_stops2, route_graph2, conn_type2, walk_type2)\n",
    "        \n",
    "        #print(\"ALL ROUTES ARE DIFFERENT\")\n",
    "        is_different = True\n",
    "            \n",
    "    # If there are some different routes, then split according to the number of different routes\n",
    "    else:\n",
    "        # CHILD 1        \n",
    "        # All same routes from parent 1 will go to child 1\n",
    "        \n",
    "        count = 0\n",
    "        for route in routes_same1:\n",
    "            new_route_id = f\"{count}-A\"\n",
    "            new_route = Route([copy.deepcopy(r) for r in route.route],new_route_id)\n",
    "            \n",
    "            for connection in route.route:\n",
    "                route_graph1.add_node(connection[0], **network1.graph.nodes[connection[0]])\n",
    "                if connection[0] not in used_stops1:\n",
    "                    used_stops1.append(connection[0])\n",
    "                    \n",
    "                route_graph1.add_node(connection[-1], **network1.graph.nodes[connection[-1]])\n",
    "                if connection[-1] not in used_stops1:\n",
    "                    used_stops1.append(connection[-1])\n",
    "                \n",
    "                route_graph1.add_edge(connection[0], connection[-1], key=new_route_id, **network1.graph.get_edge_data(connection[0], connection[-1], route.route_id))\n",
    "            route_network1.append(new_route)\n",
    "            count += 1\n",
    "            \n",
    "        # All not same routes from parent 2 will go to child 1\n",
    "        for route in routes_not_same2:\n",
    "            new_route_id = f\"{count}-A\"\n",
    "            new_route = Route([copy.deepcopy(r) for r in route.route],new_route_id)\n",
    "            \n",
    "            for connection in route.route:\n",
    "                route_graph1.add_node(connection[0], **network2.graph.nodes[connection[0]])\n",
    "                if connection[0] not in used_stops1:\n",
    "                    used_stops1.append(connection[0])\n",
    "                    \n",
    "                route_graph1.add_node(connection[-1], **network2.graph.nodes[connection[-1]])\n",
    "                if connection[-1] not in used_stops1:\n",
    "                    used_stops1.append(connection[-1])\n",
    "                \n",
    "                route_graph1.add_edge(connection[0], connection[-1], key=new_route_id, **network2.graph.get_edge_data(connection[0], connection[-1], route.route_id))\n",
    "            route_network1.append(new_route)\n",
    "            count += 1\n",
    "            \n",
    "        #CHILD2\n",
    "        # All not same routes from parent 1 will go to child 2\n",
    "        \n",
    "        count = 0\n",
    "        for route in routes_not_same1:\n",
    "            new_route_id = f\"{count}-A\"\n",
    "            new_route = Route([copy.deepcopy(r) for r in route.route],new_route_id)\n",
    "            \n",
    "            for connection in route.route:\n",
    "                route_graph2.add_node(connection[0], **network1.graph.nodes[connection[0]])\n",
    "                if connection[0] not in used_stops2:\n",
    "                    used_stops2.append(connection[0])\n",
    "                    \n",
    "                route_graph2.add_node(connection[-1], **network1.graph.nodes[connection[-1]])\n",
    "                if connection[-1] not in used_stops2:\n",
    "                    used_stops2.append(connection[-1])\n",
    "                \n",
    "                route_graph2.add_edge(connection[0], connection[-1], key=new_route_id, **network1.graph.get_edge_data(connection[0], connection[-1], route.route_id))\n",
    "            route_network2.append(new_route)\n",
    "            count += 1\n",
    "        \n",
    "        # All same routes from parent 2 will go to child 2\n",
    "        for route in routes_same2:\n",
    "            new_route_id = f\"{count}-A\"\n",
    "            new_route = Route([copy.deepcopy(r) for r in route.route],new_route_id)\n",
    "            \n",
    "            for connection in route.route:\n",
    "                route_graph2.add_node(connection[0], **network2.graph.nodes[connection[0]])\n",
    "                if connection[0] not in used_stops2:\n",
    "                    used_stops2.append(connection[0])\n",
    "                    \n",
    "                route_graph2.add_node(connection[-1], **network2.graph.nodes[connection[-1]])\n",
    "                if connection[-1] not in used_stops2:\n",
    "                    used_stops2.append(connection[-1])\n",
    "                \n",
    "                route_graph2.add_edge(connection[0], connection[-1], key=new_route_id, **network2.graph.get_edge_data(connection[0], connection[-1], route.route_id))\n",
    "            route_network2.append(new_route)\n",
    "            count += 1\n",
    "    \n",
    "        child1 = networkObj(route_network1, used_stops1, route_graph1, conn_type1, walk_type1)\n",
    "        child2 = networkObj(route_network2, used_stops2, route_graph2, conn_type2, walk_type2)\n",
    "        \n",
    "        #print(\"SOME ROUTES ARE DIFFERENT\")\n",
    "        is_different = True\n",
    "    \n",
    "    \n",
    "    # # ----------- ERROR CHECKING ---------------------\n",
    "    # print(\"* Checking Child 1 for errors:\", flush=True)\n",
    "    # # TODO: DELETE FOR TESTING IF GRAPH IS CONSISTENT WITH ITS LIST OF ROUTES\n",
    "    # print(\"Checking for graph and route consistency...\", flush=True)\n",
    "    # check_graph_with_route(child1)\n",
    "    # print(\"Checking for graph and list of stops consistency...\", flush=True)\n",
    "    # check_graph_with_stops(child1)\n",
    "    # print(\"Checking if order of routes is correct...\", flush=True)\n",
    "    # check_order_route(child1.routes)\n",
    "    # print(\"Checking for list of stops and route consistency...\", flush=True)\n",
    "    # check_stops_routes(child1)\n",
    "    # print(\"Checking for duplicates in routes...\")\n",
    "    # check_duplicate_routes(child1)\n",
    "    # print()\n",
    "    \n",
    "    # # print(\"* Checking Child 2 for errors:\", flush=True)\n",
    "    # # # TODO: DELETE FOR TESTING IF GRAPH IS CONSISTENT WITH ITS LIST OF ROUTES\n",
    "    # print(\"Checking for graph and route consistency...\", flush=True)\n",
    "    # check_graph_with_route(child2)\n",
    "    # print(\"Checking for graph and list of stops consistency...\", flush=True)\n",
    "    # check_graph_with_stops(child2)\n",
    "    # print(\"Checking if order of routes is correct...\", flush=True)\n",
    "    # check_order_route(child2.routes)\n",
    "    # print(\"Checking for list of stops and route consistency...\", flush=True)\n",
    "    # check_stops_routes(child2)\n",
    "    # print(\"Checking for duplicates in routes...\")\n",
    "    # check_duplicate_routes(child2)\n",
    "\n",
    "    return child1, child2, is_different\n",
    "\n",
    "\n",
    "# Standardizes the route for more efficiency in comparing routes\n",
    "def standardize_route(route):\n",
    "    return tuple(tuple(sorted(connection)) for connection in route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUTATION FUNCTION\n",
    "\n",
    "# Modify the stop connections of a random route in the network\n",
    "# Randomly select a route and randomly select a stop in that route\n",
    "# Then randomly select another stop that is a not too far from the selected stop based on threshold\n",
    "# Swap connections with that stop\n",
    "def mutate(network_to_mutate, graph_of_stops):\n",
    "    global set_walk_distance, MAX_DISTANCE\n",
    "    \n",
    "    # Randomly select a route\n",
    "    random_route_obj = random.choice(network_to_mutate.routes)\n",
    "    random_route = random_route_obj.route\n",
    "    random_route_id = random_route_obj.route_id\n",
    "\n",
    "    # Randomly select a stop in the route\n",
    "    index_array = list(range(1, len(random_route)-1))\n",
    "    connection_index = random.choice(index_array)\n",
    "    random_node_connection = random_route[connection_index]\n",
    "    \n",
    "    connection_stop_index = random.choice([0, -1]) # Choose whether the origin or destination node\n",
    "    random_stop = random_node_connection[connection_stop_index] # The random stop to be swapped\n",
    "    \n",
    "    # Get the old total distance\n",
    "    old_total_distance = 0\n",
    "    for connection in random_route:\n",
    "        edge_data = network_to_mutate.graph.get_edge_data(connection[0], connection[-1], random_route_id)\n",
    "        \n",
    "        if edge_data == None:\n",
    "            print(\"-- ERROR MISSING EDGE INFORMATION: \", connection[0], \" - \", connection[-1])\n",
    "        else:\n",
    "            old_total_distance += edge_data['distance']\n",
    "    \n",
    "    \n",
    "    # This is to get the subset distance (Distance without the connection with chosen random stop)\n",
    "    if connection_stop_index == 0: # If it is the origin node in that connection (A, B, C and B is the chosen. Get B-C and A-B)\n",
    "        prev_connection = random_route[connection_index-1] # Get the previous connection\n",
    "        prev_node = prev_connection[0] # Get the origin node for that connection\n",
    "        distance1 = network_to_mutate.graph.get_edge_data(prev_node, random_stop, random_route_id)['distance'] # Get the distance of the previous connection\n",
    "        distance2 = network_to_mutate.graph.get_edge_data(random_stop, random_node_connection[-1], random_route_id)['distance'] # Get the distance of the current connection\n",
    "        distance_to_subtract = distance1 + distance2\n",
    "        \n",
    "        # Previous connection: node1 - random_node\n",
    "        # Current connection: random_node - node2\n",
    "        node1 = prev_node # Setting the partner nodes\n",
    "        node2 = random_node_connection[-1]\n",
    "        \n",
    "    else: #If it is the dest node in that connection\n",
    "        distance1 = network_to_mutate.graph.get_edge_data(random_node_connection[0], random_stop, random_route_id)['distance'] # Get the distance of the current connection\n",
    "        next_connection = random_route[connection_index+1] # Get the next route\n",
    "        next_node = next_connection[-1] # Get the destination node for the next connection\n",
    "        distance2 = network_to_mutate.graph.get_edge_data(random_stop, next_node, random_route_id)['distance']\n",
    "        distance_to_subtract = distance1 + distance2\n",
    "        \n",
    "        # Previous connection: node1 - random_node\n",
    "        # Current connection: random_node - node2\n",
    "        node2 = next_node\n",
    "        node1 = random_node_connection[0]\n",
    "    \n",
    "    # Get the subset different -> This will be used to make sure that the distance of the connections to the new node will be less than or equal to MAX_DISTANCE (15km)\n",
    "    subset_distance = old_total_distance - distance_to_subtract\n",
    "    \n",
    "    # Will try searching for a random stop\n",
    "    for i in range(100):\n",
    "        # Get a random stop\n",
    "        new_random_stop, new_random_stop_data = random.choice(list(graph_of_stops.nodes(data=True)))\n",
    "        \n",
    "        # Check if the new random stop is not within walking distance with the other stop in the route\n",
    "        # Walking distance between node1 in route and stop to be swapped with\n",
    "        source = (new_random_stop_data['lat'], new_random_stop_data['lon'])\n",
    "        point = (graph_of_stops.nodes[node1]['lat'], graph_of_stops.nodes[node1]['lon'])\n",
    "        walking_distance1 = geodesic(source, point).meters\n",
    "        \n",
    "        # Walking distance between node2 in route and stop to be swapped with\n",
    "        source = (new_random_stop_data['lat'], new_random_stop_data['lon'])\n",
    "        point = (graph_of_stops.nodes[node2]['lat'], graph_of_stops.nodes[node2]['lon'])\n",
    "        walking_distance2 = geodesic(source, point).meters\n",
    "        \n",
    "        # Check if it already has been used in the route\n",
    "        isCandidate = True\n",
    "        for connection in random_route:\n",
    "            if new_random_stop == connection[0] or new_random_stop == connection[-1]:\n",
    "                isCandidate = False\n",
    "                continue\n",
    "        \n",
    "        # Check if the edge has already been used\n",
    "        has_edge1 = network_to_mutate.graph.has_edge(node1, new_random_stop, random_route_id)\n",
    "        has_edge2 = network_to_mutate.graph.has_edge(new_random_stop, node1, random_route_id)\n",
    "        has_edge3 = network_to_mutate.graph.has_edge(new_random_stop, node2, random_route_id)\n",
    "        has_edge4 = network_to_mutate.graph.has_edge(node2, new_random_stop, random_route_id)\n",
    "        \n",
    "        # If it is not within walking distances, has not been used in the same route, has a path, has no existing edge\n",
    "        if walking_distance1 >= set_walk_distance and walking_distance2 >= set_walk_distance and isCandidate and nx.has_path(CITY_GRAPH, node1, new_random_stop) and nx.has_path(CITY_GRAPH, new_random_stop, node2) and not has_edge1 and not has_edge2 and not has_edge3 and not has_edge4:\n",
    "            # DISTANCE 1: Get the total distance from point A to point B\n",
    "            shortest_route1 = nx.shortest_path(CITY_GRAPH, node1, new_random_stop)\n",
    "            distance_travelled1 = 0\n",
    "            for i in range(len(shortest_route1)-1):\n",
    "                node_data = CITY_GRAPH.nodes[shortest_route1[i]]\n",
    "                next_node_data = CITY_GRAPH.nodes[shortest_route1[i+1]]\n",
    "                distance_travelled1 += haversine(node_data['y'], node_data['x'], next_node_data['y'], next_node_data['x'])\n",
    "            \n",
    "            # DISTANCE 2: Get the total distance from point A to point B\n",
    "            shortest_route2 = nx.shortest_path(CITY_GRAPH, new_random_stop, node2)\n",
    "            distance_travelled2 = 0\n",
    "            for i in range(len(shortest_route2)-1):\n",
    "                node_data = CITY_GRAPH.nodes[shortest_route2[i]]\n",
    "                next_node_data = CITY_GRAPH.nodes[shortest_route2[i+1]]\n",
    "                distance_travelled2 += haversine(node_data['y'], node_data['x'], next_node_data['y'], next_node_data['x'])\n",
    "            \n",
    "            # If its within the 15km distance, then this new stop can be used\n",
    "            if subset_distance + distance_travelled1 + distance_travelled2 <= MAX_DISTANCE:\n",
    "                # Add the new stop to the used stops\n",
    "                if new_random_stop not in network_to_mutate.stops:\n",
    "                    network_to_mutate.stops.append(new_random_stop)\n",
    "                \n",
    "                # Modify the graph by adding the new node\n",
    "                network_to_mutate.graph.add_node(new_random_stop, **graph_of_stops.nodes[new_random_stop])\n",
    "                \n",
    "                # Connect the new stop to the edges\n",
    "                network_to_mutate.graph.add_edge(shortest_route1[0], shortest_route1[-1], key=random_route_id, distance = distance_travelled1) # Add edge\n",
    "                network_to_mutate.graph.add_edge(shortest_route2[0], shortest_route2[-1], key=random_route_id, distance = distance_travelled2) # Add edge \n",
    "            \n",
    "                # Remove the old connections and node if it has no other connections\n",
    "                network_to_mutate.graph.remove_edge(node1, random_stop, random_route_id)\n",
    "                network_to_mutate.graph.remove_edge(random_stop, node2, random_route_id)\n",
    "                if (network_to_mutate.graph.degree(random_stop) == 0):\n",
    "                    network_to_mutate.graph.remove_node(random_stop)                \n",
    "                    network_to_mutate.stops.remove(random_stop)\n",
    "                \n",
    "                \n",
    "                # Modify the route\n",
    "                if connection_stop_index == 0: #If its the origin node\n",
    "                    random_route[connection_index-1] = shortest_route1 # Change the previous connection\n",
    "                    random_route[connection_index] = shortest_route2 # Change the current connection\n",
    "                    \n",
    "                else: #else If its the dest node\n",
    "                    random_route[connection_index] = shortest_route1 # Change the current connection\n",
    "                    random_route[connection_index+1] = shortest_route2 # Change the next connection\n",
    "                \n",
    "                        \n",
    "                # ----------- FOR ERROR CHECKING -------------------\n",
    "                # print(\"Checking for graph and route consistency...\")\n",
    "                # check_graph_with_route(network_to_mutate)\n",
    "                # print(\"Checking for graph and list of stops consistency...\")\n",
    "                # check_graph_with_stops(network_to_mutate)\n",
    "                # print(\"Checking if order of routes is correct...\")\n",
    "                # check_order_route(network_to_mutate.routes)\n",
    "                # print(\"Checking for list of stops and route consistency...\")\n",
    "                # check_stops_routes(network_to_mutate)\n",
    "                # print(\"Checking for duplicates in routes...\")\n",
    "                # check_duplicate_routes(network_to_mutate)\n",
    "                # print(\"MUTATION DONE\", flush=True)\n",
    "                \n",
    "                # Break the loop once we swap\n",
    "                print()\n",
    "                break  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitness Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitness function\n",
    "\n",
    "def select_highest_scoring_mutation(candidate_road_snapped_networks, num_failure_removal,\n",
    "                                    weight_random_failure, weight_targeted_failure, weight_radius_of_gyration):\n",
    "    max_fitness_score = -np.inf\n",
    "    max_candidate_route_snapped_network = None\n",
    "\n",
    "    for n in candidate_road_snapped_networks:\n",
    "        fitness_score = compute_fitness_score(n, num_failure_removal,\n",
    "                                              weight_random_failure, weight_targeted_failure, weight_radius_of_gyration)\n",
    "        if fitness_score > max_fitness_score:\n",
    "            max_fitness_score = fitness_score\n",
    "            max_candidate_route_snapped_network = n\n",
    "\n",
    "    return max_candidate_route_snapped_network\n",
    "\n",
    "def compute_fitness_score(road_snapped_network_graph, num_failure_removal,\n",
    "                          weight_random_failure, weight_targeted_failure, weight_connectivity):\n",
    "\n",
    "    random_failure_robustness = compute_random_failure_robustness(road_snapped_network_graph, num_failure_removal)\n",
    "    weighted_random_failure_robustness = weight_random_failure * random_failure_robustness\n",
    "\n",
    "    targeted_failure_robustness = compute_targeted_failure_robustness(road_snapped_network_graph, num_failure_removal)\n",
    "    weighted_targeted_failure_robustness = weight_targeted_failure * targeted_failure_robustness\n",
    "\n",
    "    connectivity_score = compute_connectivity(road_snapped_network_graph)\n",
    "    weighted_connectivity = weight_connectivity * connectivity_score\n",
    "    \n",
    "    # print(\"Random Failure Score: \", weighted_random_failure_robustness)\n",
    "    # print(\"Target Failure Score: \", weighted_targeted_failure_robustness)\n",
    "    # print(\"Connectivity: \", weighted_connectivity)\n",
    "\n",
    "    # Will use this return for now to utilize target and random failure nodes \n",
    "    return weighted_connectivity - weighted_random_failure_robustness - weighted_targeted_failure_robustness\n",
    "    # return weighted_radius_of_gyration\n",
    "\n",
    "\n",
    "### WRITTEN IN PSEUDOCODE\n",
    "def compute_connectivity(network):\n",
    "    # External connectivity - measure how connected is the jeepney route network with other modes of transpo\n",
    "    \n",
    "    # Get the ratio of transportation stops to total stops in the network\n",
    "    transpo_stops = [node for node, node_data in network.nodes(data=True) if node_data['isTranspo'] == True]\n",
    "    total_stops = len(network.nodes(data=True))\n",
    "    transpo_stop_ratio = len(transpo_stops) / total_stops\n",
    "\n",
    "    # Get the average degree of all transportation stops in the network\n",
    "    if len(transpo_stops) > 0:\n",
    "        avg_transpo_degree = sum(network.degree(stop) for stop in transpo_stops) / len(transpo_stops)\n",
    "    else:\n",
    "        avg_transpo_degree = 1\n",
    "\n",
    "    # Find a way to normalize the two values and combine them \n",
    "\n",
    "    # Internal connectivity - measure how connected is each jeepney route to other jeepney routes\n",
    "                    \n",
    "    # This counts how many nodes have intersections (Meaning node is connected to more than one route by route ID)\n",
    "    num_intersections = 0\n",
    "    for node, node_data in network.nodes(data=True):\n",
    "        if network.in_degree(node) > 1 or network.out_degree(node) > 1:\n",
    "            num_intersections += 1\n",
    "\n",
    "    \n",
    "    # Change these weights based on what the expected values for \n",
    "    # the transpo_stop_ratio, avg_transpo_degree, and num_intersections will be\n",
    "    external_weight = 0.5\n",
    "    internal_weight = 0.5\n",
    "    \n",
    "    # TODO: Delete this\n",
    "    # print(\"Transpo stop ratio: \", transpo_stop_ratio)\n",
    "    # print(\"Num intersections: \", num_intersections)\n",
    "    # print(\"Average degree: \", avg_transpo_degree)\n",
    "\n",
    "    # Formula subject to change\n",
    "    return external_weight * (transpo_stop_ratio * avg_transpo_degree) + internal_weight * num_intersections\n",
    "\n",
    "\n",
    "def compute_random_failure_robustness(road_snapped_network_graph, num_removals):\n",
    "    graph_copy = road_snapped_network_graph.copy() # Make a copy\n",
    "    \n",
    "    for i in range(num_removals):\n",
    "        selected_node = random.choice(list(graph_copy.nodes()))\n",
    "        graph_copy.remove_node(selected_node)\n",
    "\n",
    "    diameter, avg_path_length = compute_network_statistics(graph_copy)\n",
    "    return compute_failure_robustness(graph_copy, diameter)\n",
    "\n",
    "def compute_targeted_failure_robustness(road_snapped_network_graph, num_removals):\n",
    "    graph_copy = road_snapped_network_graph.copy() # Make a copy\n",
    "    \n",
    "    for i in range(num_removals):\n",
    "        node_degrees = graph_copy.degree()\n",
    "        # Iterate over the DegreeView object to find the maximum degree\n",
    "        max_degree = max(degree for _, degree in node_degrees)\n",
    "        max_degree_node = get_node_with_degree(node_degrees, max_degree)\n",
    "        graph_copy.remove_node(max_degree_node)\n",
    "\n",
    "    diameter, avg_path_length = compute_network_statistics(graph_copy)\n",
    "    return compute_failure_robustness(graph_copy, diameter)\n",
    "\n",
    "def compute_failure_robustness(road_snapped_network_graph, max_path_length):\n",
    "    return float(max_path_length) / float(len(road_snapped_network_graph) - 1)\n",
    "\n",
    "def compute_network_statistics(road_snapped_network_graph):\n",
    "    path_lengths = get_path_lengths(road_snapped_network_graph) # Get the sum of all possible\n",
    "    avg_path_length = np.mean(path_lengths)\n",
    "    max_path_length = max(path_lengths)\n",
    "\n",
    "    #network_size = len(path_lengths)\n",
    "    #gcc = sorted(nx.connected_component_subgraphs(road_snapped_network_graph), key=len, reverse=True)\n",
    "    #giant_component_fraction = float(float(gcc[0].order()) / float(network_size))\n",
    "    #return max_path_length, avg_path_length, giant_component_fraction\n",
    "    return max_path_length, avg_path_length\n",
    "\n",
    "def get_node_with_degree(node_degrees, degree):\n",
    "    # Iterate over the DegreeView object to find the node with the specified degree\n",
    "    for node, _ in node_degrees:\n",
    "        if _ == degree:\n",
    "            return node\n",
    "    return None  # Return None if no node with the specified degree is found\n",
    "\n",
    "def get_path_lengths(snapped_road_network_graph):\n",
    "    return [sum(nx.single_source_shortest_path_length(snapped_road_network_graph, n).values())\n",
    "            for n in snapped_road_network_graph]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Error Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ERROR CHECK - Checking if there are duplicate routes in the list of routes\n",
    "def check_duplicate_routes(network):\n",
    "    routes = network.routes\n",
    "    seen_routes = set()\n",
    "    error = \"xxx\"\n",
    "\n",
    "    for route_obj in routes:\n",
    "        standardized_route = tuple(tuple(sorted(sublist)) for sublist in route_obj.route)\n",
    "\n",
    "        if standardized_route in seen_routes:\n",
    "            print(f\"----- ERROR{error} FOUND EXACT DUPLICATE ROUTES\")\n",
    "        else:\n",
    "            seen_routes.add(standardized_route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERROR Check - Checks if routes is consistent with its stops\n",
    "def check_stops_routes(network, list_of_stops):\n",
    "    node_id_list = []\n",
    "    error = \"xxx\"\n",
    "    # Checks if each node in the route is in the list of stops\n",
    "    for route in network.routes:\n",
    "        for connection in route.route:\n",
    "            if connection[0] not in node_id_list:\n",
    "                node_id_list.append(connection[0])\n",
    "            if connection[-1] not in node_id_list:\n",
    "                node_id_list.append(connection[-1])\n",
    "                \n",
    "    for stop in network.stops:\n",
    "        node_id = list_of_stops[stop].node_id\n",
    "        if node_id not in node_id_list:\n",
    "            print(f\"----- ERROR{error} MISSING STOP NODE ID IN LIST\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERROR Check - Checks if the routes are in correct order\n",
    "def check_order_route(routes):\n",
    "    error = \"xxx\"\n",
    "    for route in routes:\n",
    "        for connection in route.route:\n",
    "            if route.route.index(connection) > 0:\n",
    "                if connection[0] != prev_connection[-1]:\n",
    "                    print(f\"---- ERROR{error} WRONG ORDER DETECTED --\")\n",
    "                    print(prev_connection[0], \" - \", prev_connection[-1])\n",
    "                    print(connection[0], \" - \", connection[-1])\n",
    "                    print(\"--------------------------\")\n",
    "            prev_connection = connection\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERROR CHECK - Checks the consistency of the network with its list of stops\n",
    "def check_graph_with_stops(_network):\n",
    "    error = \"xxx\"\n",
    "    # Checks if all stops in the list is in the graph\n",
    "    for stop in _network.stops:\n",
    "        if not _network.graph.has_node(stop):\n",
    "            print(f\"---- ERROR{error} MISSING LIST STOP IN GRAPH: \", stop)\n",
    "            \n",
    "    # Checks if all nodes in the graph are in the list\n",
    "    for node, node_data in _network.graph.nodes(data=True):\n",
    "        if node not in _network.stops:\n",
    "            print(f\"---- ERROR{error} MISSING GRAPH NODE IN LIST: \", node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: WORKING IN PROGRESS\n",
    "def simplicity_metric(network):\n",
    "    routes = network.routes\n",
    "    \n",
    "    for route in routes:\n",
    "        for i in range(len(route) - 1):\n",
    "            u, v = route[i], route[i + 1]\n",
    "            \n",
    "            if CITY_GRAPH.has_edge(u, v):\n",
    "                edge_data = CITY_GRAPH.get_edge_data(u, v)\n",
    "            else:\n",
    "                # Skip if there's no direct edge between u and v\n",
    "                continue\n",
    "            \n",
    "            # Edge data might have multiple edges with different keys\n",
    "            for key in edge_data:\n",
    "                road_name = edge_data[key].get('name', 'Unnamed Road')\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Analysis Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longest route, shortest route, average route length, network diamater"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot/visualize connected zones on the map\n",
    "import random\n",
    "\n",
    "# This is to better visualize the networks\n",
    "def plot_connected_zones_network_on_map(graph, initial_location=[0, 0], zoom_start=10):\n",
    "    # Create a map centered at the initial location\n",
    "    map_center = (14.599512, 120.984222) # TEMPORARY WILL ZOOM TO MANILA\n",
    "    m = folium.Map(location=map_center, zoom_start=zoom_start, tiles='openstreetmap')\n",
    "    \n",
    "    #Colours for Visualization\n",
    "    colors = [\n",
    "    \"Red\", \"Green\", \"Blue\", \"Yellow\", \"Orange\", \"Purple\", \"Cyan\", \"Magenta\", \"Maroon\",\n",
    "    \"Olive\", \"Lime\", \"Teal\", \"Navy\", \"Aqua\", \"Fuchsia\", \"Coral\", \"Indigo\", \"Violet\"]\n",
    "    \n",
    "    color_map = {}\n",
    "\n",
    "    # Iterate over the nodes in the network\n",
    "    for node, data in graph.nodes(data=True):\n",
    "        # Check if the node has a geometry attribute\n",
    "        if 'geometry' in data:\n",
    "            # Get the geometry of the node\n",
    "            geometry = data['geometry']\n",
    "\n",
    "            # Check the geometry type and plot accordingly\n",
    "            if geometry.geom_type == 'Point':\n",
    "                # Plot a marker for points    \n",
    "                #folium.Marker(location=[geometry.y, geometry.x], popup=f\"{data['name']}\").add_to(m)\n",
    "                continue\n",
    "            elif geometry.geom_type in ['Polygon', 'MultiPolygon']:\n",
    "                \n",
    "                network_id = data[\"network_id\"]\n",
    "                \n",
    "                if network_id not in color_map:\n",
    "                    color = random.choice(colors)\n",
    "                    color_map[network_id] = color\n",
    "                else:\n",
    "                    color = color_map[network_id]\n",
    "                \n",
    "                if geometry.geom_type == 'Polygon':\n",
    "                    polygons = [geometry]\n",
    "                else:\n",
    "                    polygons = geometry.geoms\n",
    "\n",
    "                for polygon in polygons:\n",
    "                    coordinates = []\n",
    "                    for point in polygon.exterior.coords:\n",
    "                        coordinates.append([point[1], point[0]])\n",
    "                    folium.Polygon(locations=coordinates, fill=True, color=color, fill_opacity=0.4).add_to(m)\n",
    "\n",
    "    # Return the map\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to visualize the stops\n",
    "def plot_stops_on_map(stops, initial_location=[0, 0], zoom_start=10):\n",
    "    # Iterate over the nodes in the network\n",
    "    map_center = (14.599512, 120.984222)\n",
    "    network_map = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "    for stop in stops:\n",
    "        \n",
    "        if stop.isTranspo:\n",
    "            marker_color = 'blue'\n",
    "        else:\n",
    "            marker_color = 'red'\n",
    "            \n",
    "        folium.Marker(location=[stop.lat, stop.long], popup=f\"Transportation: {stop.isTranspo}\", icon=folium.Icon(color=marker_color)).add_to(network_map)\n",
    "        \n",
    "    return network_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting filtered roads FOR VISUALIZATION ONLY\n",
    "def plot_all_filtered_roads():\n",
    "    map_center = (14.599512, 120.984222)\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "\n",
    "    # Iterate through each road\n",
    "    for index, road in filtered_roads_strings.iterrows():\n",
    "        line_coords = list(road['geometry'].coords)\n",
    "\n",
    "        if road['highway'] == 'primary':\n",
    "            folium.PolyLine(locations=[(y, x) for x, y in line_coords], color='blue').add_to(m)\n",
    "\n",
    "        if road['highway'] == 'secondary':\n",
    "            folium.PolyLine(locations=[(y, x) for x, y in line_coords], color='red').add_to(m)\n",
    "\n",
    "        if road['highway'] == 'tertiary':\n",
    "            folium.PolyLine(locations=[(y, x) for x, y in line_coords], color='green').add_to(m)\n",
    "            \n",
    "        if road['highway'] == 'trunk':\n",
    "            folium.PolyLine(locations=[(y, x) for x, y in line_coords], color='black').add_to(m)\n",
    "            \n",
    "        if road['highway'] == 'residential':\n",
    "            folium.PolyLine(locations=[(y, x) for x, y in line_coords], color='brown').add_to(m)\n",
    "\n",
    "        if road['highway'] == 'unclassified':\n",
    "            folium.PolyLine(locations=[(y, x) for x, y in line_coords], color='orange').add_to(m)\n",
    "\n",
    "    for index, road in filtered_roads_lists.iterrows():\n",
    "        line_coords = list(road['geometry'].coords)\n",
    "        folium.PolyLine(locations=[(y, x) for x, y in line_coords], color='purple').add_to(m)\n",
    "\n",
    "    # Return the map\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manila Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Paths\n",
    "Manila_pikl_filepath = \"Saved Networks/Manila/\"\n",
    "Manila_map_filepath = \"Saved Maps/Manila/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READING DATA (All Amenities in Manila)\n",
    "#CHANGE THIS BACK\n",
    "merged_amenities_points_gdf = gpd.read_file('./City Data/Manila City/Manila_point.geojson')\n",
    "merged_amenities_polygons_gdf= gpd.read_file('././City Data/Manila City/Manila_polygon.geojson')\n",
    "\n",
    "merged_amenities_polygons_gdf['amenity_points'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q0/zbq8f0v11vb5hv6jh21spfwm0000gn/T/ipykernel_15887/2666581131.py:2: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  merged_amenities_polygons_gdf['area'] = degrees_to_meters(merged_amenities_polygons_gdf['geometry'].area)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "135.26544097431915"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Getting total area to be used for the area connection type\n",
    "merged_amenities_polygons_gdf['area'] = degrees_to_meters(merged_amenities_polygons_gdf['geometry'].area)\n",
    "manila_area_sum = merged_amenities_polygons_gdf['area'].sum()\n",
    "\n",
    "manila_area_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spatial index for points\n",
    "idx = rtree_index.Index()\n",
    "for j, point in merged_amenities_points_gdf.iterrows():\n",
    "    idx.insert(j, point['geometry'].bounds)\n",
    "\n",
    "# Iterate over polygons\n",
    "for i, polygon in merged_amenities_polygons_gdf.iterrows():\n",
    "    points_within_polygon = []\n",
    "    \n",
    "    # Iterate over points within the bounding box of the polygon\n",
    "    for j in idx.intersection(polygon['geometry'].bounds):\n",
    "        point = merged_amenities_points_gdf.loc[j]\n",
    "        if polygon['geometry'].intersects(point['geometry']):\n",
    "            points_within_polygon.append(j)\n",
    "    \n",
    "    merged_amenities_polygons_gdf.at[i, 'amenity_points'] = points_within_polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Manila Zone Network Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- LEVEL 1 \n",
    "# IMPORT INITIAL NETWORK\n",
    "initial_network_Manila = import_networks(f\"{Manila_pikl_filepath}Manila_Initial_Network.pkl\")\n",
    "\n",
    "# IMPORT FILTERED NETWORK\n",
    "filtered_manila_amenities_network = import_networks(f\"{Manila_pikl_filepath}Manila_Filtered_Network.pkl\")\n",
    "\n",
    "# IMPORT COMBINED AMENITIES NETWORK\n",
    "combined_graph_Manila = import_networks(f\"{Manila_pikl_filepath}Manila_Combined_Amenities_Network.pkl\")\n",
    "\n",
    "# ------- LEVEL 2\n",
    "# IMPORT POPULATION GRAPH\n",
    "pop_graph = import_networks(f\"{Manila_pikl_filepath}Manila_Population_Graph.pkl\")\n",
    "\n",
    "# IMPORT ZONE NETWORK\n",
    "graph_networks_of_polygons_Manila = import_networks(f\"{Manila_pikl_filepath}Manila_Zone_Network.pkl\")\n",
    "networks_map_Manila = plot_connected_zones_network_on_map(graph_networks_of_polygons_Manila, initial_location=[0, 0], zoom_start=100)\n",
    "\n",
    "add_points_to_graph(initial_network_Manila, graph_networks_of_polygons_Manila) # Add all points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Stop list and Graph (Only to test the same stops)\n",
    "list_of_stops_Manila = import_networks(f\"{Manila_pikl_filepath}stop_list_Manila.pkl\")\n",
    "graph_of_stops_Manila = import_networks(f\"{Manila_pikl_filepath}stop_graph_Manila.pkl\")\n",
    "\n",
    "# Visualize the stops\n",
    "stops_map = plot_stops_on_map(networks_map_Manila, list_of_stops_Manila, initial_location=[0, 0], zoom_start=100)\n",
    "stops_map.save(f\"{Manila_map_filepath}stops_map.html\") # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Generated Routes (Only to test the same routes)\n",
    "# WALKING_DISTANCES -> 300,550,800\n",
    "# CONNECTION_TYPES -> \"Default\", \"Area\", \"Degree\", \"Mixed\"\n",
    "import_conn_type = CONNECTION_TYPES[0]\n",
    "import_walk_distance = WALKING_DISTANCES[0]\n",
    "\n",
    "if import_conn_type == 'Mixed':\n",
    "    list_of_networks_Manila = import_networks(f\"{Manila_pikl_filepath}Manila_Route_networks_{import_conn_type}.pkl\")\n",
    "else:\n",
    "    list_of_networks_Manila = import_networks(f\"{Manila_pikl_filepath}Manila_Route_networks_{import_conn_type}_{import_walk_distance}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing GA Results (Only to analyze shared results)\n",
    "# WALKING_DISTANCES -> 300,550,800\n",
    "# CONNECTION_TYPES -> \"Default\", \"Area\", \"Degree\", \"Mixed\"\n",
    "import_conn_type = CONNECTION_TYPES[0]\n",
    "import_walk_distance = WALKING_DISTANCES[0]\n",
    "\n",
    "if import_conn_type == 'Mixed':\n",
    "    population = import_networks(f\"{Manila_pikl_filepath}Manila_GA_Route_networks_{import_conn_type}.pkl\")\n",
    "else:\n",
    "    population = import_networks(f\"{Manila_pikl_filepath}Manila_GA_Route_networks_{import_conn_type}_{import_walk_distance}.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop Placement (Only to generate new stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 3 - CREATING STOPS TO BE PLACED ON ZONES\n",
    "graph_of_stops_Manila = nx.Graph()\n",
    "list_of_stops_Manila = []\n",
    "place_stops_on_roads(graph_networks_of_polygons_Manila, graph_of_stops_Manila, list_of_stops_Manila) # Adds stops graph_of_stops, and gets the relevant edges\n",
    "\n",
    "# Visualize the stops\n",
    "stops_map = plot_stops_on_map(list_of_stops_Manila, initial_location=[0, 0], zoom_start=100)\n",
    "stops_map.save(f\"{Manila_map_filepath}stops_map.html\") # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export stops to pickle\n",
    "file_path = f'{Manila_pikl_filepath}stop_list_Manila.pkl'\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(list_of_stops_Manila, f)\n",
    "    \n",
    "file_path = f'{Manila_pikl_filepath}stop_graph_Manila.pkl'\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(graph_of_stops_Manila, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop Connection (Only to generate new routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHOSEN CONNECTION TYPE: Default\n",
      "NETWORK 0\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 7 - 11.29248875574146\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 6 - 13.394040918142124\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 7 - 14.077136810938905\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 6 - 14.628217608115513\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 8 - 14.245635616028958\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 7 - 14.850063372635242\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 5 - 12.67398588457606\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 6 - 14.394526480244886\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 6 - 12.890683463706047\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 5 - 12.767690699463234\n",
      "Checking for graph and list of stops consistency...\n",
      "Checking if order of routes is correct...\n",
      "Checking for list of stops and route consistency...\n",
      "Checking for duplicates in routes...\n",
      "\n",
      "NETWORK 1\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 5 - 12.072551765446057\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 6 - 13.730947431671954\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 6 - 14.195854230946413\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 8 - 14.208796023820353\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 7 - 14.915150960223091\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 8 - 14.13011969206373\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 6 - 12.715249251010388\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 9 - 13.172582909475434\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 8 - 14.885103565816152\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 6 - 11.28501801736262\n",
      "Checking for graph and list of stops consistency...\n",
      "Checking if order of routes is correct...\n",
      "Checking for list of stops and route consistency...\n",
      "Checking for duplicates in routes...\n",
      "\n",
      "NETWORK 2\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 7 - 14.462263514503233\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 5 - 12.840742183807894\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 7 - 14.865624432360102\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 6 - 14.010603713561581\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 8 - 14.487622573499127\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 7 - 13.019202960728771\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 6 - 13.111591808357495\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 6 - 12.901370257355179\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 8 - 13.472573931442588\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 5 - 12.473082657140234\n",
      "Checking for graph and list of stops consistency...\n",
      "Checking if order of routes is correct...\n",
      "Checking for list of stops and route consistency...\n",
      "Checking for duplicates in routes...\n",
      "\n",
      "NETWORK 3\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 8 - 13.99689439261223\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 8 - 12.8528632363732\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 8 - 12.707186190041295\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 6 - 13.926631626091359\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 8 - 14.797921876256504\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 5 - 14.334350305184806\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 7 - 14.278967806159093\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 7 - 14.178068173446805\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 8 - 13.70714912302575\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 6 - 13.42934486404382\n",
      "Checking for graph and list of stops consistency...\n",
      "Checking if order of routes is correct...\n",
      "Checking for list of stops and route consistency...\n",
      "Checking for duplicates in routes...\n",
      "\n",
      "NETWORK 4\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 6 - 14.756264657245225\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 7 - 13.623938235948968\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 6 - 14.817357576804325\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 7 - 14.708449940391635\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 8 - 13.633026280581566\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 7 - 13.847415609718485\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 5 - 11.670930263229428\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 7 - 14.211259096495604\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 7 - 13.045328590652247\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 8 - 14.504464217077091\n",
      "Checking for graph and list of stops consistency...\n",
      "Checking if order of routes is correct...\n",
      "Checking for list of stops and route consistency...\n",
      "Checking for duplicates in routes...\n",
      "\n",
      "NETWORK 5\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 6 - 14.325040097453929\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 10 - 14.903359331524584\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 8 - 14.625369348830416\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 7 - 13.13496402630662\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 8 - 14.00050064556166\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 6 - 13.931886290530617\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 7 - 14.88342441642059\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 8 - 14.955293381463754\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 7 - 12.683257719837174\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 8 - 14.707270931509854\n",
      "Checking for graph and list of stops consistency...\n",
      "Checking if order of routes is correct...\n",
      "Checking for list of stops and route consistency...\n",
      "Checking for duplicates in routes...\n",
      "\n",
      "NETWORK 6\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 10 - 14.547949563411251\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 6 - 13.67394828311395\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 6 - 12.647663245104146\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 8 - 14.807324394568553\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 6 - 13.194660451267362\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 7 - 13.641038709737952\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 8 - 14.8100130166502\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 8 - 14.085353862720845\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 7 - 13.107670806536662\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 9 - 14.674066437707006\n",
      "Checking for graph and list of stops consistency...\n",
      "Checking if order of routes is correct...\n",
      "Checking for list of stops and route consistency...\n",
      "Checking for duplicates in routes...\n",
      "\n",
      "NETWORK 7\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 6 - 12.300685902546737\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 7 - 14.407310369772622\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 9 - 14.323854084939537\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 7 - 13.963081348580793\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 6 - 14.6952219529695\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 9 - 11.897154362599895\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 7 - 13.937233151995626\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 6 - 13.791002487939581\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 7 - 12.216365623257097\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 7 - 14.626688915208854\n",
      "Checking for graph and list of stops consistency...\n",
      "Checking if order of routes is correct...\n",
      "Checking for list of stops and route consistency...\n",
      "Checking for duplicates in routes...\n",
      "\n",
      "NETWORK 8\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 9 - 14.152766499098963\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 7 - 14.585608792906505\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 6 - 14.779077239020111\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 6 - 14.580264016974002\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 7 - 13.981105069227825\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 5 - 13.831577044019994\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 7 - 14.959008913609638\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 6 - 14.694581792046428\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 6 - 13.627942728820123\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 5 - 13.080981740000897\n",
      "Checking for graph and list of stops consistency...\n",
      "Checking if order of routes is correct...\n",
      "Checking for list of stops and route consistency...\n",
      "Checking for duplicates in routes...\n",
      "\n",
      "NETWORK 9\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 6 - 13.54642252673021\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 8 - 13.9781020387501\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 6 - 13.108488220660623\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 7 - 13.900938633044088\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 6 - 13.182670800633286\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 7 - 14.9216656189743\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 8 - 13.806565765692797\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 5 - 13.471387988761153\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 6 - 12.631407579775562\n",
      "# OF CONNECTIONS AND TOTAL DISTANCE: 5 - 12.851964903124834\n",
      "Checking for graph and list of stops consistency...\n",
      "Checking if order of routes is correct...\n",
      "Checking for list of stops and route consistency...\n",
      "Checking for duplicates in routes...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LEVEL 4 - CONNECTING STOPS INTO A NETWORK\n",
    "\n",
    "# Configuration\n",
    "set_walk_distance = WALKING_DISTANCES[0]\n",
    "num_of_networks = 10\n",
    "conn_type = CONNECTION_TYPES[0]\n",
    "max_stops = 20\n",
    "max_routes = 10 # temporary, should be 30\n",
    "map_html_location = f\"Generated Route Networks HTML/Manila/{conn_type}/\"\n",
    "        \n",
    "# Generate route network\n",
    "list_of_networks_Manila = []\n",
    "\n",
    "print(f\"CHOSEN CONNECTION TYPE: {conn_type}\")\n",
    "current_network_count = 0\n",
    "for _ in range(num_of_networks):\n",
    "    \n",
    "    print(f\"NETWORK {current_network_count}\")\n",
    "    if conn_type == \"Mixed\":\n",
    "        temp_conn_type = random.choice(CONNECTION_TYPES[:-1])\n",
    "        temp_walk_type = random.choice(WALKING_DISTANCES)\n",
    "        print(f\"NETWORK CONNECTION TYPE: {temp_conn_type}\")\n",
    "        route_network, route_graph, stop_id_list = generate_route_network(list_of_stops_Manila, set_walk_distance, max_stops, max_routes, graph_of_stops_Manila, manila_area_sum, temp_conn_type) # Default max walking distance is 300m\n",
    "        new_network = networkObj(route_network, stop_id_list, route_graph, temp_conn_type, temp_walk_type)\n",
    "    else:\n",
    "        route_network, route_graph, stop_id_list = generate_route_network(list_of_stops_Manila, set_walk_distance, max_stops, max_routes, graph_of_stops_Manila, manila_area_sum, conn_type) # Default max walking distance is 300m\n",
    "        new_network = networkObj(route_network, stop_id_list, route_graph, conn_type, set_walk_distance)\n",
    "    \n",
    "    # ERROR CHECKS----------\n",
    "    print(\"Checking for graph and list of stops consistency...\", flush=True)\n",
    "    check_graph_with_stops(new_network)\n",
    "    print(\"Checking if order of routes is correct...\", flush=True)\n",
    "    check_order_route(new_network.routes)\n",
    "    print(\"Checking for list of stops and route consistency...\", flush=True)\n",
    "    check_stops_routes(new_network, list_of_stops_Manila)\n",
    "    print(\"Checking for duplicates in routes...\")\n",
    "    check_duplicate_routes(new_network)\n",
    "    \n",
    "    print()\n",
    "    list_of_networks_Manila.append(new_network) # Append to list of networks\n",
    "    current_network_count += 1\n",
    "\n",
    "#Export networks and graphs using pickl\n",
    "if conn_type == 'Mixed':\n",
    "    export_networks(list_of_networks_Manila, f\"{Manila_pikl_filepath}Manila_Route_networks_{conn_type}.pkl\")\n",
    "else:\n",
    "    export_networks(list_of_networks_Manila, f\"{Manila_pikl_filepath}Manila_Route_networks_{conn_type}_{set_walk_distance}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Maps for visualization\n",
    "\n",
    "i = 1\n",
    "for route_network in list_of_networks_Manila:\n",
    "    map_center = (14.599512, 120.984222)\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "\n",
    "    # Plotting in the Map\n",
    "    add_markers(route_network.stops, route_network.graph)\n",
    "        \n",
    "    for route in route_network.routes:\n",
    "        for connection in route:\n",
    "            ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "    m.save(f\"{map_html_location}Route Map-{i}.html\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genetic Algorithm (Only to generate new GA results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING GA ---------------------------------------------------------]\n",
    "# There should a pickle file already of the latest networks\n",
    "\n",
    "# GA Configuration\n",
    "mutation_probability = 0.2\n",
    "num_mutations_probabilities = [0.1, 0.1, 0.4, 0.2, 0.2]\n",
    "plateau_threshold = 0.01\n",
    "plateau_max_count = 50\n",
    "max_generations = 100\n",
    "\n",
    "#Weights and Fitness Function configuration\n",
    "num_failure_removal = 4\n",
    "weight_random_failure = 0.15\n",
    "weight_targeted_failure = 0.15\n",
    "weight_connectivity = 0.7\n",
    "\n",
    "population = perform_genetic_algorithm(list_of_networks_Manila, graph_of_stops_Manila, mutation_probability, num_mutations_probabilities, num_failure_removal,\n",
    "                                  weight_random_failure, weight_targeted_failure, weight_connectivity, plateau_threshold, plateau_max_count, max_generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for network in population:\n",
    "    print(f\"Network Score {network.fitness_score}\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting GA Results\n",
    "unique_types = {obj.conn_type for obj in population}\n",
    "if len(unique_types) > 1:\n",
    "    export_conn_type = \"Mixed\"\n",
    "    \n",
    "    export_networks(population, f\"{Manila_pikl_filepath}Manila_GA_Route_networks_{export_conn_type}.pkl\")\n",
    "    print(f\"Exported: Manila_GA_Route_networks_{export_conn_type}.pkl\")\n",
    "else:\n",
    "    export_conn_type = population[0].conn_type\n",
    "    export_walk_distance = population[0].walk_distance\n",
    "\n",
    "    export_networks(population, f\"{Manila_pikl_filepath}Manila_GA_Route_networks_{export_conn_type}_{export_walk_distance}.pkl\")\n",
    "    print(f\"Exported: Manila_GA_Route_networks_{export_conn_type}_{export_walk_distance}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Genetic Algorithm Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "unique_types = {obj.conn_type for obj in population}\n",
    "if len(unique_types) > 1:\n",
    "    export_conn_type = \"Mixed\"\n",
    "    map_html_location = \"GA Result Route Networks HTML/Manila/Mixed/\"\n",
    "else:\n",
    "    export_conn_type = population[0].conn_type\n",
    "    export_walk_distance = population[0].walk_distance\n",
    "    map_html_location = f\"GA Result Route Networks HTML/Manila/{export_conn_type}/{export_walk_distance}/\"\n",
    "\n",
    "i = 1\n",
    "for network in population:\n",
    "    map_center = (14.599512, 120.984222)\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "    add_markers(network.stops, network.graph)\n",
    "    \n",
    "    for route in network.routes:\n",
    "        for connection in route:\n",
    "            ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "    m.save(f\"{map_html_location}GA Map-{i}.html\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Allowed Roads for Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_road_map = plot_all_filtered_roads()\n",
    "filtered_road_map.save(f\"{Manila_map_filepath}Allowed_Roads.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MULTIDIGRAPH TESTING ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FITNESS FUNCTION TEST\n",
    "num_failure_removal = 4\n",
    "weight_random_failure = 0.15\n",
    "weight_targeted_failure = 0.15\n",
    "weight_connectivity = 0.7\n",
    "\n",
    "list_copy = []\n",
    "for network1 in list_of_networks_Manila:\n",
    "    test_graph_net1 = network1.graph.copy()\n",
    "    test_routes_net1 = [copy.deepcopy(r) for r in network1.routes]\n",
    "    test_stops_net1 = [copy.deepcopy(s) for s in network1.stops]\n",
    "    list_copy.append(networkObj(test_routes_net1, test_stops_net1, test_graph_net1, network1.conn_type, network1.walk_distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for network in list_copy:\n",
    "    network.fitness_score = compute_fitness_score(network.graph, num_failure_removal, weight_random_failure, weight_targeted_failure, weight_connectivity)\n",
    "    print(f\"Network Score: {network.fitness_score}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CROSSOVER TESTING\n",
    "parent1 = list_copy[0]\n",
    "parent2 = list_copy[1]\n",
    "\n",
    "child1, child2, is_different = crossover_split_index(parent1, parent2)\n",
    "\n",
    "print(\"IS DIFFERENT \", is_different)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_center = (14.599512, 120.984222)\n",
    "m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "add_markers(child1.stops, child1.graph)\n",
    "\n",
    "for route in child1.routes:\n",
    "    for connection in route.route:\n",
    "        ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "m.save(f\"CROSSOVER TEST 1.html\")\n",
    "\n",
    "\n",
    "m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "add_markers(child2.stops, child2.graph)\n",
    "\n",
    "for route in child2.routes:\n",
    "    for connection in route.route:\n",
    "        ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "m.save(f\"CROSSOVER TEST 2.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutate(child1, graph_of_stops_Manila)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_center = (14.599512, 120.984222)\n",
    "m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "add_markers(child1.stops, child1.graph)\n",
    "\n",
    "for route in child1.routes:\n",
    "    for connection in route.route:\n",
    "        ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "m.save(f\"MUTATE TEST 1.html\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
