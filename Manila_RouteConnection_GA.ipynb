{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manila - Jeepney Route Connection and Genetic Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Route Connection and Genetic Algorithm Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import shapely\n",
    "import folium\n",
    "import geojson\n",
    "import math\n",
    "import osmnx as ox\n",
    "from rtree import index as rtree_index\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "from shapely.ops import unary_union\n",
    "from shapely.geometry import Polygon, MultiPolygon, LineString, Point\n",
    "from geopy.distance import geodesic\n",
    "\n",
    "from __future__ import absolute_import, division\n",
    "from math import radians, sin, cos, sqrt, atan2, exp, log\n",
    "import webbrowser\n",
    "import random\n",
    "from scipy.spatial import KDTree\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "ox.settings.log_console=True\n",
    "ox.settings.use_cache=True\n",
    "\n",
    "WALKING_DISTANCES = [300,550,800]\n",
    "MAX_DISTANCE = 15\n",
    "CONNECTION_TYPES = [\"Default\", \"Area\", \"Degree\", \"Mixed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining classes for the dataframes      \n",
    "class stopCandidate:\n",
    "    def __init__(self, lat, long, isTranspo, id, area):\n",
    "        self.lat = lat\n",
    "        self.long = long\n",
    "        self.isTranspo = isTranspo\n",
    "        self.enabled = False\n",
    "        self.id = id #node ID\n",
    "        self.area = area\n",
    "        self.degree = 0\n",
    "        \n",
    "    def enable(self):\n",
    "        self.enabled = True\n",
    "        \n",
    "    def disable(self):\n",
    "        self.enabled = False\n",
    "        \n",
    "    def getLat(self):\n",
    "        return self.lat\n",
    "    \n",
    "    def getLong(self):\n",
    "        return self.long\n",
    "    \n",
    "    def getArea(self):\n",
    "        return self.area\n",
    "    \n",
    "    def getDegree(self):\n",
    "        return self.degree\n",
    "    \n",
    "class networkObj():\n",
    "    def __init__(self, routes, stops, graph, conn_type, walk_distance):\n",
    "        self.routes = routes\n",
    "        self.stops = stops\n",
    "        self.fitness_score = 0\n",
    "        self.graph = graph\n",
    "        self.conn_type = conn_type\n",
    "        self.walk_distance = walk_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For units\n",
    "def degrees_to_meters(angle_degrees):\n",
    "    return angle_degrees * 6371000 * math.pi / 180\n",
    "\n",
    "def meters_to_degrees(distance_meters):\n",
    "    return distance_meters / 6371000 * 180 / math.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and Export networks or graphs to pickle\n",
    "def export_networks(networks, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(networks, f)\n",
    "\n",
    "def import_networks(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        routes = pickle.load(f)\n",
    "    return routes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: SELECT THE CITY HERE, COMMENT OUT THE REMAINING CITIES\n",
    "select_city = \"Manila, Philippines\"\n",
    "city_file = 'map/Manila.graphml'\n",
    "\n",
    "\n",
    "# GENERATION OF MAIN CITY GRAPH\n",
    "# IF FIRST TIME RUNNING, RUN THIS CODE TO GENERATE THE GRAPH\n",
    "def generate_graph():\n",
    "    mode = 'drive'\n",
    "    graph = ox.graph_from_place(select_city, network_type = mode) # Generate graph of Metro manila\n",
    "    ox.save_graphml(graph, city_file) # Save it as a file\n",
    "\n",
    "def load_graph():\n",
    "    graph = ox.load_graphml(city_file)\n",
    "    \n",
    "    print(\"Graph loaded successfully\")\n",
    "    print(\"NUMBER OF EDGES: \", graph.number_of_edges())\n",
    "    print(\"NUMBER OF NODES: \", graph.number_of_nodes())\n",
    "    print('\\n')\n",
    "    return graph\n",
    "\n",
    "# NOTE: Only run this if you do not have the graph\n",
    "generate_graph()\n",
    "\n",
    "# THIS IS THE MAIN GRAPH FOR THE CITY TO BE USED FOR ALL FUNCTIONS\n",
    "CITY_GRAPH = load_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For Filtering the roads and other features\n",
    "# GETTING ROADS AND WATERWAYS\n",
    "\n",
    "# Get all the roads in Manila\n",
    "road = ox.graph_to_gdfs(CITY_GRAPH,nodes=False, edges=True)\n",
    "\n",
    "\n",
    "# Get all the roads that are not junctions (ex. Roundabouts, intersection, etc.)\n",
    "filtered_roads = road[road['junction'].isna()]\n",
    "\n",
    "# Separate roads whose widths are only one value and those that are more than 1 (lists)\n",
    "rows_with_lists = filtered_roads[filtered_roads['highway'].apply(lambda x: isinstance(x, list))]\n",
    "rows_with_strings = filtered_roads[filtered_roads['highway'].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "filter_options = ['primary', 'secondary', 'tertiary', 'trunk', 'unclassified']\n",
    "separation_options = ['primary', 'secondary', 'tertiary', 'unclassified']\n",
    "\n",
    "# Get the roads whose widths are above the threshold\n",
    "def check_list(lst):\n",
    "    return any(x in filter_options for x in lst)\n",
    "\n",
    "# Download OpenStreetMap data for the area of interest\n",
    "waterways = ox.features_from_place(select_city, tags={'waterway': True})\n",
    "filtered_rivers = waterways[waterways['waterway'].isin(['river'])]\n",
    "filtered_streams = waterways[waterways['waterway'].isin(['stream'])]\n",
    "\n",
    "# Get all the roads with the allowed road types\n",
    "filtered_roads_strings = rows_with_strings.loc[rows_with_strings['highway'].isin(filter_options)] \n",
    "filtered_roads_lists = rows_with_lists[rows_with_lists['highway'].apply(check_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will find which road or river intersects between amenities\n",
    "# Create spatial index\n",
    "filtered_roads_strings_sindex = filtered_roads_strings.sindex\n",
    "filtered_roads_lists_sindex = filtered_roads_lists.sindex\n",
    "filtered_rivers_sindex = filtered_rivers.sindex\n",
    "filtered_streams_sindex = filtered_streams.sindex\n",
    "\n",
    "def find_intersecting_features(line):\n",
    "    # Check intersection with filtered roads\n",
    "    possible_matches_roads = filtered_roads_strings.iloc[list(filtered_roads_strings_sindex.intersection(line.bounds))]\n",
    "    for index, row in possible_matches_roads.iterrows():\n",
    "        if line.intersects(row['geometry']) and row['highway'] in separation_options:\n",
    "            return True\n",
    "\n",
    "    possible_matches_lists = filtered_roads_lists.iloc[list(filtered_roads_lists_sindex.intersection(line.bounds))]\n",
    "    for index, row in possible_matches_lists.iterrows():\n",
    "        if line.intersects(row['geometry']):\n",
    "            list_highway = row['highway']\n",
    "            if any(x in separation_options for x in list_highway):\n",
    "                return True\n",
    "    \n",
    "    # Check intersection with filtered rivers\n",
    "    possible_matches_rivers = filtered_rivers.iloc[list(filtered_rivers_sindex.intersection(line.bounds))]\n",
    "    for index, row in possible_matches_rivers.iterrows():\n",
    "        if line.intersects(row['geometry']):\n",
    "            return True\n",
    "\n",
    "    # Check intersection with filtered streams\n",
    "    possible_matches_streams = filtered_streams.iloc[list(filtered_streams_sindex.intersection(line.bounds))]\n",
    "    for index, row in possible_matches_streams.iterrows():\n",
    "        if line.intersects(row['geometry']):\n",
    "            return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD POINTS TO NX GRAPH\n",
    "# Function to add only points to the networkX graph\n",
    "# The other functions focuses on adding polygons, this function just iterates and adds points\n",
    "\n",
    "def add_points_to_graph(graph, graph_to_add):\n",
    "    for node_key, node_data in graph.nodes.items():\n",
    "        if 'geometry' in node_data and node_data['geometry'].geom_type in ['Point']:   \n",
    "            graph_to_add.add_node(node_key, geometry=node_data['geometry'], name=node_data['name'], lat=node_data['lat'], amenity=node_data['amenity'],\n",
    "                                lon=node_data['lon'])\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CREATING STOPS\n",
    "# It should return a list of coordinates/nodes for stop and a graph of stops\n",
    "# if residential area, check if the population density\n",
    "\n",
    "# Global Variables used:\n",
    "# list_of_stops - List of stops\n",
    "# graph_of_stops - graph of all stops placed\n",
    "# CITY_GRAPH - graph of the city road networks\n",
    "import random\n",
    "\n",
    "def place_stops_on_roads(amenity_graph, graph_of_stops, list_of_stops):\n",
    "    global CITY_GRAPH  \n",
    "    for node_key, node_data in amenity_graph.nodes(data=True):\n",
    "        # All tranportation points are automatically stops\n",
    "        if node_data['geometry'].geom_type in ['Point']:\n",
    "            if node_data['amenity'] == 'transportation':\n",
    "                nearest_node = ox.distance.nearest_nodes(CITY_GRAPH, node_data['lon'], node_data['lat'])\n",
    "                \n",
    "                # If there is an existing node in the main graph, then add it to the list and the stop graph\n",
    "                if nearest_node is not None:\n",
    "                    if not graph_of_stops.has_node(nearest_node):\n",
    "                        lon = CITY_GRAPH.nodes[nearest_node]['x']\n",
    "                        lat = CITY_GRAPH.nodes[nearest_node]['y']\n",
    "                        isTranspo = True\n",
    "                        graph_of_stops.add_node(nearest_node, lon=lon, lat=lat, isTranspo=isTranspo)\n",
    "                        list_of_stops.append(stopCandidate(CITY_GRAPH.nodes[nearest_node]['y'], CITY_GRAPH.nodes[nearest_node]['x'], True, nearest_node, 0))\n",
    "        \n",
    "        else:\n",
    "            # Calculate the number of stops based on node size and population density\n",
    "            num_stops, node_size = calculate_num_stops(node_key, node_data)\n",
    "            \n",
    "            buffer_poly = node_data['geometry'].buffer(meters_to_degrees(30))\n",
    "            # Get the roads surrounding and inside the node polygons\n",
    "            relevant_edges = get_relevant_edges(buffer_poly)\n",
    "            \n",
    "            # Place stops randomly on these roads\n",
    "            place_stops_along_edges(relevant_edges, buffer_poly, num_stops, node_size, graph_of_stops, list_of_stops)\n",
    "\n",
    "def calculate_num_stops(node_key, node_data):\n",
    "    # Example calculation based on node size and population density\n",
    "    node_size = degrees_to_meters(node_data['geometry'].area) # Size of the node polygon\n",
    "    # Adjust factors and formula as needed\n",
    "    num_stops = 0\n",
    "    \n",
    "    if node_key in pop_graph:\n",
    "        pop_density = pop_graph.nodes[node_key]['density']\n",
    "        num_stops = node_size * pop_density / 10000000  # Adjust this factor as needed\n",
    "        \n",
    "        if num_stops < 1:\n",
    "            num_stops = 1\n",
    "        elif num_stops > 3:\n",
    "            num_stops = 3\n",
    "    else:\n",
    "        list_sum = len(node_data['amenity_points'])\n",
    "\n",
    "        if list_sum > 0:\n",
    "            num_stops = 5\n",
    "        else:\n",
    "            num_stops = 3\n",
    "        \n",
    "    return int(num_stops), node_size\n",
    "\n",
    "\n",
    "# Create spatial index\n",
    "filtered_roads_strings_sindex = filtered_roads_strings.sindex\n",
    "filtered_roads_lists_sindex = filtered_roads_lists.sindex\n",
    "def get_relevant_edges(polygon):\n",
    "    relevant_edges = []\n",
    "    \n",
    "    # Check intersection with filtered roads\n",
    "    possible_matches_roads = filtered_roads_strings.iloc[list(filtered_roads_strings_sindex.intersection(polygon.bounds))]\n",
    "    for index, row in possible_matches_roads.iterrows():\n",
    "        if polygon.intersects(row['geometry']) and row['highway'] in ['primary', 'secondary', 'tertiary', 'residential']:\n",
    "            relevant_edges.append(row)\n",
    "\n",
    "    possible_matches_lists = filtered_roads_lists.iloc[list(filtered_roads_lists_sindex.intersection(polygon.bounds))]\n",
    "    for index, row in possible_matches_lists.iterrows():\n",
    "        if polygon.intersects(row['geometry']):\n",
    "            list_highway = row['highway']\n",
    "            if any(x in ['primary', 'secondary', 'tertiary', 'residential'] for x in list_highway):\n",
    "                relevant_edges.append(row)\n",
    "    return relevant_edges\n",
    "\n",
    "def place_stops_along_edges(edges, polygon, num_stops, node_size, graph_of_stops, list_of_stops):\n",
    "    # Place stops randomly along the edges within the polygon\n",
    "    \n",
    "    if len(edges) > 0:\n",
    "        for _ in range(num_stops):\n",
    "            edge = random.choice(edges)\n",
    "            # Calculate the intersection between the edge and the polygon\n",
    "            intersecting_line = edge['geometry'].intersection(polygon)\n",
    "            if intersecting_line.is_empty:\n",
    "                continue\n",
    "\n",
    "            # Calculate the length of the intersecting part of the edge\n",
    "            intersecting_length = intersecting_line.length\n",
    "\n",
    "            # Generate a random position along the intersecting part of the edge\n",
    "            random_position = random.uniform(0, intersecting_length)\n",
    "\n",
    "            # Calculate the coordinate along the edge at the random position\n",
    "            stop_location = calculate_coordinate_along_edge(intersecting_line, random_position)\n",
    "            #print(\"Stop placed at:\", stop_location)\n",
    "            \n",
    "            nearest_node = ox.distance.nearest_nodes(CITY_GRAPH, stop_location[0], stop_location[1])\n",
    "            \n",
    "            # If there is an existing node in the main graph, then add it to the list and the stop graph\n",
    "            if nearest_node is not None:\n",
    "                if not graph_of_stops.has_node(nearest_node):\n",
    "                    lon = CITY_GRAPH.nodes[nearest_node]['x']\n",
    "                    lat = CITY_GRAPH.nodes[nearest_node]['y']\n",
    "                    isTranspo = False\n",
    "                    graph_of_stops.add_node(nearest_node, lon=lon, lat=lat, isTranspo=isTranspo)\n",
    "                    list_of_stops.append(stopCandidate(CITY_GRAPH.nodes[nearest_node]['y'], CITY_GRAPH.nodes[nearest_node]['x'], False,  nearest_node, node_size))\n",
    "            else:\n",
    "                _ -= 1\n",
    "        \n",
    "            \n",
    "\n",
    "def calculate_coordinate_along_edge(edge, position):\n",
    "    # Calculate the coordinate along the edge at the given position\n",
    "    point = edge.interpolate(position)\n",
    "    return point.x, point.y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Route Network Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V2 - Graph with the snapping function\n",
    "# Generate Route Network from connected routes\n",
    "\n",
    "# Global Variables used:\n",
    "# graph_of_stops - Graph of stops that will be used to create routes\n",
    "def generate_route_network(stop_nodes, max_walking_dist, max_stops, max_routes, graph_of_stops, city_area_sum, connection_type=\"Default\"):\n",
    "    global route_count\n",
    "    overall_graph = nx.Graph()\n",
    "    \n",
    "    stop_node_coordinates = [[n.lat, n.long] for n in stop_nodes]\n",
    "    stop_nodes_kd_tree = KDTree(stop_node_coordinates)\n",
    "    next_nodes = [n for n in stop_nodes]\n",
    "    enable_stop_nodes(next_nodes)\n",
    "    route_network = []\n",
    "    num_routes = 0 # Count number of routes\n",
    "\n",
    "    while num_routes < max_routes:\n",
    "        next_nodes = [n for n in stop_nodes] # Resets the list of nodes so that nodes can be reused in a different\n",
    "        selected_node = random.choice(next_nodes) # For the first node\n",
    "        next_nodes.remove(selected_node)\n",
    "        route_gen = generate_route(selected_node, next_nodes, stop_nodes_kd_tree, max_walking_dist, connection_type, max_stops, overall_graph, city_area_sum)\n",
    "        \n",
    "        if len(route_gen) > 1:\n",
    "            # A route is a list of connections between two nodes\n",
    "            snap_route_to_road(route_gen, overall_graph, graph_of_stops)\n",
    "            route_count += 1\n",
    "            \n",
    "            #snapped_edges = list(snapped_route.edges(data='road_path', default=1))\n",
    "            #snapped_route = connect_snapped_edges(snapped_edges)\n",
    "            route_network.append(route_gen)   \n",
    "            num_routes += 1\n",
    "               \n",
    "    return route_network, overall_graph\n",
    "\n",
    "def snap_route_to_road(route, overall_graph, graph_of_stops):\n",
    "    global connection_count\n",
    "    \n",
    "    # Directly add nodes based on node identifiers\n",
    "    for connection in route:\n",
    "        overall_graph.add_node(connection[0], **graph_of_stops.nodes[connection[0]]) # The origin\n",
    "        overall_graph.add_node(connection[-1], **graph_of_stops.nodes[connection[-1]]) # The destination\n",
    "        \n",
    "        name = f\"{connection[0]}_{connection[-1]}\" # \"node1_node2\" as name\n",
    "        \n",
    "        distance_travelled = 0\n",
    "        # Get the total distance from point A to point B\n",
    "        for i in range(len(connection)-1):\n",
    "            node_data = CITY_GRAPH.nodes[connection[i]]\n",
    "            next_node_data = CITY_GRAPH.nodes[connection[i+1]]\n",
    "            distance_travelled += haversine(node_data['y'], node_data['x'], next_node_data['y'], next_node_data['x'])\n",
    "        \n",
    "        overall_graph.add_edge(connection[0], connection[-1], road_path=connection, edge_name=name, edge_id = connection_count, route_id = route_count, distance = distance_travelled) # Add edge\n",
    "        connection_count += 1 # Global variable - increment the number of connections\n",
    "        \n",
    "        \n",
    "        if not overall_graph.has_node(connection[0]):\n",
    "                print(\"missing \", connection[0], \" in route\")\n",
    "        \n",
    "        if not overall_graph.has_node(connection[-1]):\n",
    "                print(\"missing \", connection[-1], \" in route \")\n",
    "\n",
    "\n",
    "# Generate route from stop nodes\n",
    "def generate_route(source, next_nodes, stop_nodes_kd_tree, max_walking_dist, connection_type, max_stops, network_graph, city_area_sum):\n",
    "    short_route_list = [] # List of nx.shortest_path results\n",
    "    totalDistance = 0\n",
    "    orig_node = source\n",
    "    num_stops = 0 # Count number of stops\n",
    "    \n",
    "    # CONFIGURATION\n",
    "    max_tries = 3 # This is the max number of tries before breaking the loop || To avoid longer runtimes\n",
    "    current_tries = 0\n",
    "\n",
    "    while totalDistance < MAX_DISTANCE and num_stops < max_stops:\n",
    "        \n",
    "        #print(f\"Selected node is {selected_node.getLat()}, {selected_node.getLong()}\")\n",
    "        enable_surrounding_nodes(next_nodes)\n",
    "        disable_surrounding_nodes(next_nodes, orig_node, max_walking_dist)\n",
    "        enabled_nodes = [n for n in next_nodes if n.enabled]\n",
    "        if len(enabled_nodes) == 0:\n",
    "            break\n",
    "        \n",
    "        #print(f\"{len(enabled_nodes)} nodes out of {len(next_nodes)}\")\n",
    "        dest_node = get_enabled_node_with_highest_edge_probability(orig_node, enabled_nodes, connection_type, city_area_sum) # Getting the destination node\n",
    "        \n",
    "        if (dest_node == None or dest_node.id == orig_node.id):\n",
    "            break\n",
    "        \n",
    "        next_nodes.remove(dest_node) # Remove it as a candidate\n",
    "        \n",
    "        connection_edge = network_graph.has_edge(orig_node.id, dest_node.id) # This is to check if there is already an existing edge. If true, then it should not connect\n",
    "        \n",
    "        if not nx.has_path(CITY_GRAPH, orig_node.id, dest_node.id) or connection_edge:\n",
    "            current_tries += 1\n",
    "            if current_tries == max_tries:\n",
    "                break\n",
    "        else:\n",
    "            shortest_route = nx.shortest_path(CITY_GRAPH, orig_node.id, dest_node.id)\n",
    "            distance_travelled = 0\n",
    "            # Get the total distance from point A to point B\n",
    "            for i in range(len(shortest_route)-1):\n",
    "                node_data = CITY_GRAPH.nodes[shortest_route[i]]\n",
    "                next_node_data = CITY_GRAPH.nodes[shortest_route[i+1]]\n",
    "                \n",
    "                distance_travelled += haversine(node_data['y'], node_data['x'], next_node_data['y'], next_node_data['x'])\n",
    "\n",
    "            # Checks if it does not exceed the max distance\n",
    "            if totalDistance + distance_travelled <= MAX_DISTANCE:\n",
    "                \n",
    "                # Updating local degree count used for connection probability\n",
    "                orig_node.degree += 1\n",
    "                dest_node.degree += 1\n",
    "                \n",
    "                totalDistance += distance_travelled\n",
    "                short_route_list.append(shortest_route)\n",
    "                num_stops += 1\n",
    "                \n",
    "                orig_node = dest_node # Now change the origin to the destination\n",
    "            else:\n",
    "                break\n",
    "    if len(short_route_list) > 4 and totalDistance > 7:\n",
    "        print(f\"# OF CONNECTIONS AND TOTAL DISTANCE: {len(short_route_list)} - {totalDistance}\")\n",
    "        return short_route_list\n",
    "    \n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Disable surrounding nodes\n",
    "def disable_surrounding_nodes(next_nodes, source_node, max_distance):\n",
    "    max_radius = 2000 # This is max radius in which all nodes outside will be disabled\n",
    "    source = (source_node.getLat(), source_node.getLong())\n",
    "    \n",
    "    for node in next_nodes:\n",
    "        point = (node.getLat(), node.getLong())\n",
    "        distance_to_source = geodesic(source, point).meters\n",
    "        if distance_to_source <= max_distance or distance_to_source > max_radius:\n",
    "            node.disable()\n",
    "            \n",
    "# Enable surrounding nodes\n",
    "def enable_surrounding_nodes(next_nodes):\n",
    "    for node in next_nodes:\n",
    "        node.enable()\n",
    "        \n",
    "def get_enabled_node_with_highest_edge_probability(source_node, enabled_nodes, connection_type, city_area_sum):\n",
    "    highest_edge_prob = 0\n",
    "    highest_edge_prob_node = None\n",
    "\n",
    "    prob_list = []\n",
    "    for n in enabled_nodes:\n",
    "        # TODO: fix probability\n",
    "        edge_prob = get_edge_probability(source_node, n, len(enabled_nodes), connection_type, city_area_sum)\n",
    "        prob_list.append(edge_prob)\n",
    "    \n",
    "    \n",
    "    min_score = min(prob_list)\n",
    "    if min_score < 0: # Shift the scores to ensure all are positive\n",
    "        prob_list = [score - min_score for score in prob_list]\n",
    "    total = sum(prob_list)\n",
    "    selection_p = [score / total for score in prob_list]\n",
    "    \n",
    "    chosen_node = np.random.choice(enabled_nodes, 1, p=selection_p)[0]    \n",
    "\n",
    "    return chosen_node\n",
    "\n",
    "# Probabilities of candidate nodes based on distance, area, node degree, and if transpo stop\n",
    "def get_edge_probability(source, destination, normalization_factor, connection_type, city_area_sum):\n",
    "    source_coord = [source.getLat(), source.getLong()]\n",
    "    dest_coord = [destination.getLat(), destination.getLong()]\n",
    "\n",
    "    base_prob = exp(-(euclidean(source_coord, dest_coord))) / float(normalization_factor)\n",
    "\n",
    "    if connection_type == \"Default\":\n",
    "        if destination.isTranspo:\n",
    "            return base_prob * 1.5\n",
    "        return base_prob\n",
    "    elif connection_type == \"Area\":\n",
    "        if destination.isTranspo:\n",
    "            return base_prob * 1.5\n",
    "        return base_prob * (1 + (destination.getArea() / city_area_sum))\n",
    "    elif connection_type == \"Degree\":\n",
    "        if destination.isTranspo:\n",
    "            return base_prob * 1.5 * (1 + (destination.getDegree() / 10))\n",
    "        return base_prob * (1 + (destination.getDegree() / 10))\n",
    "\n",
    "def radius(stops):\n",
    "    circles = []\n",
    "    for stop in stops:\n",
    "        stop_point = Point(stop[1], stop[0])  # Create a Point object from [lat, lon] coordinates\n",
    "        circle = stop_point.buffer(radius / 111000)  # Buffer the Point to create a circle (assuming 1 degree is approximately 111000 meters)\n",
    "        circles.append(circle)\n",
    "    return circles\n",
    "\n",
    "def enable_stop_nodes(stop_nodes):\n",
    "    for n in stop_nodes:\n",
    "        n.enable()\n",
    "\n",
    "def all_nodes_disabled(stop_nodes):\n",
    "    return get_num_disabled(stop_nodes) == len(stop_nodes)\n",
    "\n",
    "def get_num_disabled(stop_nodes):\n",
    "    return sum(1 for n in stop_nodes if not n.enabled)\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Use geopy's geodesic function to calculate the distance\n",
    "    distance = geodesic((lat1, lon1), (lat2, lon2)).kilometers\n",
    "    return distance\n",
    "\n",
    "# Markers for visualization purposes\n",
    "def add_markers(used_stops, network_graph):\n",
    "    for stop in used_stops:\n",
    "        #popup_text = f\"Name: {stop.name}<br>Type: {stop.a_type}<br>Coordinates: {stop.getLat()}, {stop.getLong()}\"\n",
    "        lat = network_graph.nodes[stop]['lat']\n",
    "        long = network_graph.nodes[stop]['lon']\n",
    "        folium.Marker(location=[lat, long]).add_to(m)\n",
    "        \n",
    "def add_stops_to_list(routes):\n",
    "    used_stops = []\n",
    "    for route in routes:\n",
    "        for conn in route:\n",
    "            if conn[0] not in used_stops:\n",
    "                used_stops.append(conn[0])\n",
    "            if conn[-1] not in used_stops:\n",
    "                used_stops.append(conn[-1])\n",
    "    return used_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: CONNECT THE ROUTE REVERSAL\n",
    "# Reverse route traversal\n",
    "def get_reverse_route(network):\n",
    "    reverse_route_network = []\n",
    "    \n",
    "    for route in network.routes:\n",
    "        index = len(route)-1\n",
    "        \n",
    "        reverse_route = []\n",
    "        totalDistance = 0\n",
    "        while index >= 0:\n",
    "            connection = route[index] # Get the connection\n",
    "            rev_origin = connection[-1]\n",
    "            rev_dest = connection[0]\n",
    "            \n",
    "            if nx.has_path(CITY_GRAPH, rev_origin, rev_dest):\n",
    "                rev_path = nx.shortest_path(CITY_GRAPH, rev_origin, rev_dest) # Get the path\n",
    "                \n",
    "                distance_travelled = 0\n",
    "                # Get the total distance from point A to point B\n",
    "                for i in range(len(rev_path)-1):\n",
    "                    node_data = CITY_GRAPH.nodes[rev_path[i]]\n",
    "                    next_node_data = CITY_GRAPH.nodes[rev_path[i+1]]\n",
    "                    distance_travelled += haversine(node_data['y'], node_data['x'], next_node_data['y'], next_node_data['x'])\n",
    "                    \n",
    "                totalDistance += distance_travelled\n",
    "                \n",
    "                reverse_route.append(rev_path)\n",
    "                index -= 1\n",
    "            else:\n",
    "                # there is no reverse route for this so append nothing to the \n",
    "                reverse_route_network.append([])\n",
    "                break\n",
    "    \n",
    "        # Checks if it does not exceed the max distance\n",
    "        if totalDistance <= MAX_DISTANCE:\n",
    "            reverse_route_network.append(reverse_route)\n",
    "        else:\n",
    "            reverse_route_network.append([])\n",
    "            \n",
    "    return reverse_route_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GA VERSION 2 - Finding the optimal Network\n",
    "# TODO: WORKING IN PROGRESS - Find a way to make sure that it will stop when the scores start to plateau, and make sure that crossover children will not be the same\n",
    "\n",
    "# This implementation takes only 2 parents from the whole generation and generates the population from them\n",
    "# Instead of the what's in the paper that says the whole population will go through crossovers and mutations\n",
    "# Cite Nayeem et al for GA with elitism and growing population size\n",
    "def perform_genetic_algorithm(network_population, graph_of_stops, population_size, num_elites, num_generations, mutation_probability, \n",
    "                              num_mutations_probabilities, num_crossovers_probabilities, mutation_threshold_dist, num_failure_removal,\n",
    "                                      weight_random_failure, weight_targeted_failure, weight_connectivity, optimal_fitness_score,\n",
    "                              with_elitism=False, with_growing_population=False, num_mutations_per_generation=1):\n",
    "    \n",
    "    max_fitness_score = 0 # This is the max score of the current population\n",
    "    max_score_list = [] # This is to store all the max scores of each generation\n",
    "    \n",
    "    generation_num = 1\n",
    "    # This will continue to loop until the generation with the max score is equal to the optimal score\n",
    "    #while True:\n",
    "    for _ in range(5000): # Test only\n",
    "        print(f\"Generation {generation_num}\", flush=True)\n",
    "        \n",
    "        # Evaluate the fitness of each network in the population\n",
    "        for network in network_population:\n",
    "            network_graph = network.graph\n",
    "            if network.fitness_score == 0:\n",
    "                network.fitness_score = compute_fitness_score(network_graph, num_failure_removal, weight_random_failure, weight_targeted_failure, weight_connectivity)\n",
    "            \n",
    "        # Sort the network population by fitness score\n",
    "        sorted_network_population = sorted(network_population, key=lambda x: x.fitness_score, reverse=True)\n",
    "        fitness_scores = [network.fitness_score for network in sorted_network_population]\n",
    "        \n",
    "        # for printing purposes in order\n",
    "        for network in sorted_network_population:\n",
    "            print(f\"Network Score {network.fitness_score}\", flush=True)\n",
    "        \n",
    "        # The max network score of this generation\n",
    "        max_fitness_score = max(fitness_scores)\n",
    "        max_score_list.append(max_fitness_score)\n",
    "        print(f\"Generation {generation_num} Max Score: {max_fitness_score}\", flush=True)\n",
    "        \n",
    "        # The average network score of this generation\n",
    "        total_score = sum(fitness_scores)\n",
    "        average_score = total_score / len(fitness_scores)\n",
    "        print(f\"Generation {generation_num} Average Score: {average_score}\", flush=True)\n",
    "        \n",
    "        # Check if the score is optimal. If it is, then stop\n",
    "        if max_fitness_score >= optimal_fitness_score:\n",
    "            print(f\"WE FOUND THE OPTIMAL NETWORK IN GENERATION {generation_num}\")\n",
    "            most_optimal_network = sorted_network_population[0]\n",
    "            print(f\"Fitness Score of the most optimal network: {most_optimal_network.fitness_score}\")\n",
    "            break\n",
    "        \n",
    "        \n",
    "        # Choosing 10% of the networks to be parents using Roulette Wheel Selection\n",
    "        print(\"Choosing parents...\", flush=True)\n",
    "        \n",
    "        #Getting the number of parents to be selected\n",
    "        num_parents = int(len(network_population) * 0.10)\n",
    "        if num_parents % 2 == 1:\n",
    "            num_parents += 1\n",
    "        \n",
    "        # List of parents\n",
    "        parent_networks = []\n",
    "        print(\"NUM PARENTS \", num_parents)\n",
    "        for i in range(num_parents):\n",
    "            # Get the list of all fitness scores\n",
    "            fitness_scores = [network.fitness_score for network in sorted_network_population]\n",
    "            \n",
    "            # Shift the scores to ensure all are positive\n",
    "            min_score = min(fitness_scores)\n",
    "            if min_score < 0:\n",
    "                fitness_scores = [score - min_score for score in fitness_scores]\n",
    "            \n",
    "            # Get the probabilities\n",
    "            total = sum(fitness_scores)\n",
    "            selection_p = [score / total for score in fitness_scores]\n",
    "            \n",
    "            # Getting the parent\n",
    "            chosen_parent = np.random.choice(sorted_network_population, 1, p=selection_p)[0]\n",
    "            print(f\"parent {i} Score, \", chosen_parent.fitness_score, flush=True)\n",
    "            sorted_network_population.remove(chosen_parent)\n",
    "            parent_networks.append(chosen_parent)\n",
    "            \n",
    "            \n",
    "        # Add back all the removed parent networks\n",
    "        sorted_network_population.extend(parent_networks)\n",
    "        \n",
    "        # Sort the networks by fitness function again\n",
    "        sorted_network_population = sorted(network_population, key=lambda x: x.fitness_score, reverse=True)\n",
    "        \n",
    "        # Pairing the parents\n",
    "        parent_pairs = [parent_networks[i:i+2] for i in range(0, len(parent_networks), 2)]\n",
    "\n",
    "        # Each parent pair will now produce children\n",
    "        print(\"GETTING CHILDREN\", flush=True)\n",
    "        children_networks = []\n",
    "        for pair in parent_pairs:\n",
    "            parent1 = pair[0]\n",
    "            parent2 = pair[1]\n",
    "                   \n",
    "            # Get 2 children from crossovers between the two parents\n",
    "            child1, child2 = crossover_split_index(parent1, parent2)\n",
    "            \n",
    "            # Getting the number of mutations\n",
    "            index_array = list(range(len(num_mutations_probabilities)))\n",
    "            num_mutations = np.random.choice(index_array, 1, p=num_mutations_probabilities)[0]\n",
    "\n",
    "            for j in range(num_mutations):\n",
    "                # Apply mutations to the children based on mutation probability hyperparameter\n",
    "                if np.random.rand() < mutation_probability:\n",
    "                    mutate(child1, graph_of_stops)\n",
    "                    \n",
    "                if np.random.rand() < mutation_probability:\n",
    "                    mutate(child2, graph_of_stops)\n",
    "            \n",
    "            # Add the children to the list of children\n",
    "            children_networks.append(child1)\n",
    "            children_networks.append(child2)\n",
    "            \n",
    "        \n",
    "        # Preparing the next generation\n",
    "        \n",
    "        # Remove the lowest scored networks and replace it with the children\n",
    "        network_population = sorted_network_population[:-len(children_networks)]\n",
    "        network_population.extend(children_networks)\n",
    "        \n",
    "        # Increment the generation number\n",
    "        generation_num += 1\n",
    "        print()\n",
    "\n",
    "    print(f\"Highest score of all generations: {max(max_score_list)}\")\n",
    "    return network_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V2 - Crossover routes should not have the same routes\n",
    "# CROSSOVER SPLIT INDEX FUNCTION\n",
    "\n",
    "def crossover_split_index(network1, network2):\n",
    "    # Split both networks based on which routes do not have the same connections\n",
    "    # network.routes is a list of routes or list of lists of shortest_path\n",
    "    routes_same1 = []\n",
    "    routes_not_same1 = []\n",
    "    \n",
    "    for route in network1.routes:\n",
    "        not_same = True\n",
    "        \n",
    "        for connection in route:\n",
    "            if network2.graph.has_edge(connection[0], connection[-1]):\n",
    "                not_same = False\n",
    "                continue\n",
    "            \n",
    "        if not_same:\n",
    "            routes_not_same1.append(route)\n",
    "        else:\n",
    "            routes_same1.append(route)\n",
    "    \n",
    "    routes_same2 = []\n",
    "    routes_not_same2 = []\n",
    "    for route in network2.routes:\n",
    "        not_same = True\n",
    "        \n",
    "        for connection in route:\n",
    "            if network1.graph.has_edge(connection[0], connection[-1]):\n",
    "                not_same = False\n",
    "                continue\n",
    "            \n",
    "        if not_same:\n",
    "            routes_not_same2.append(route)\n",
    "        else:\n",
    "            routes_same2.append(route)\n",
    "    \n",
    "    # Create new graphs for the left and right sides\n",
    "    route_graph1 = nx.Graph()\n",
    "    route_graph2 = nx.Graph()\n",
    "    \n",
    "    route_network1 = []\n",
    "    route_network2 = []\n",
    "    \n",
    "    used_stops1 = []\n",
    "    used_stops2 = []\n",
    "    \n",
    "    conn_type1 = network1.conn_type\n",
    "    conn_type2 = network2.conn_type\n",
    "\n",
    "    walk_type1 = network1.walk_distance\n",
    "    walk_type2 = network2.walk_distance\n",
    "    \n",
    "    # If all have similar connections, then do not split\n",
    "    if len(routes_not_same1) == 0:\n",
    "        test_graph_net1 = network1.graph.copy()\n",
    "        test_routes_net1 = [copy.deepcopy(r) for r in network1.routes]\n",
    "        test_stops_net1 = [copy.deepcopy(s) for s in network1.stops]\n",
    "        child1 = networkObj(test_routes_net1, test_stops_net1, test_graph_net1, network1.conn_type, network1.walk_distance)\n",
    "\n",
    "        test_graph_net2 = network2.graph.copy()\n",
    "        test_routes_net2 = [copy.deepcopy(r) for r in network2.routes]\n",
    "        test_stops_net2 = [copy.deepcopy(s) for s in network2.stops]\n",
    "        child2 = networkObj(test_routes_net2, test_stops_net2, test_graph_net2, network2.conn_type, network2.walk_distance)\n",
    "        \n",
    "        print(\"THERE ARE NO DIFFERENT ROUTES\")\n",
    "        \n",
    "    # If all routes of both networks are different, then split at a random index\n",
    "    elif len(routes_same1) == 0:\n",
    "        # Split both networks at a random index\n",
    "        # network.routes is a list of routes or list of lists of shortest_path\n",
    "        if len(network1.routes) < len(network2.routes):\n",
    "            split_index = random.randint(0, len(network2.routes)-1)\n",
    "        else:\n",
    "            split_index = random.randint(0, len(network1.routes)-1)\n",
    "            \n",
    "        count = 0\n",
    "        for route in network1.routes:\n",
    "            if count < split_index: # if 0-split_index -> child1 graph\n",
    "                for connection in route:\n",
    "                    route_graph1.add_node(connection[0], **network1.graph.nodes[connection[0]])\n",
    "                    if connection[0] not in used_stops1:\n",
    "                        used_stops1.append(connection[0])\n",
    "                        \n",
    "                    route_graph1.add_node(connection[-1], **network1.graph.nodes[connection[-1]])\n",
    "                    if connection[-1] not in used_stops1:\n",
    "                        used_stops1.append(connection[-1])\n",
    "                    \n",
    "                    route_graph1.add_edge(connection[0], connection[-1], **network1.graph.get_edge_data(connection[0], connection[-1]))\n",
    "                route_network1.append(route.copy())\n",
    "                \n",
    "                    \n",
    "            else: # else its for child2 graph\n",
    "                for connection in route:\n",
    "                    route_graph2.add_node(connection[0], **network1.graph.nodes[connection[0]])\n",
    "                    if connection[0] not in used_stops2:\n",
    "                        used_stops2.append(connection[0])\n",
    "                        \n",
    "                    route_graph2.add_node(connection[-1], **network1.graph.nodes[connection[-1]])\n",
    "                    if connection[-1] not in used_stops2:\n",
    "                        used_stops2.append(connection[-1])\n",
    "                    \n",
    "                    route_graph2.add_edge(connection[0], connection[-1], **network1.graph.get_edge_data(connection[0], connection[-1]))\n",
    "                route_network2.append(route.copy())\n",
    "            count += 1\n",
    "            \n",
    "        count = 0\n",
    "        for route in network2.routes:\n",
    "            if count >= split_index: # if split_index-end -> child1 graph\n",
    "                for connection in route:\n",
    "                    route_graph1.add_node(connection[0], **network2.graph.nodes[connection[0]])\n",
    "                    if connection[0] not in used_stops1:\n",
    "                        used_stops1.append(connection[0])\n",
    "                        \n",
    "                    route_graph1.add_node(connection[-1], **network2.graph.nodes[connection[-1]])\n",
    "                    if connection[-1] not in used_stops1:\n",
    "                        used_stops1.append(connection[-1])\n",
    "                    \n",
    "                    route_graph1.add_edge(connection[0], connection[-1], **network2.graph.get_edge_data(connection[0], connection[-1]))\n",
    "                route_network1.append(route.copy())\n",
    "                    \n",
    "                    \n",
    "            else: # else its for child2 graph\n",
    "                for connection in route:\n",
    "                    route_graph2.add_node(connection[0], **network2.graph.nodes[connection[0]])\n",
    "                    if connection[0] not in used_stops2:\n",
    "                        used_stops2.append(connection[0])\n",
    "                        \n",
    "                    route_graph2.add_node(connection[-1], **network2.graph.nodes[connection[-1]])\n",
    "                    if connection[-1] not in used_stops2:\n",
    "                        used_stops2.append(connection[-1])\n",
    "                    \n",
    "                    route_graph2.add_edge(connection[0], connection[-1], **network2.graph.get_edge_data(connection[0], connection[-1]))\n",
    "                route_network2.append(route.copy())\n",
    "            count += 1\n",
    "        \n",
    "        child1 = networkObj(route_network1, used_stops1, route_graph1, conn_type1, walk_type1)\n",
    "        child2 = networkObj(route_network2, used_stops2, route_graph2, conn_type2, walk_type2)\n",
    "        \n",
    "        print(\"ALL ROUTES ARE DIFFERENT\")\n",
    "            \n",
    "    # If there are some different routes, then split according to the number of different routes\n",
    "    else:\n",
    "        # PARENT 1\n",
    "        # All not same routes from parent 1 will go to child 2\n",
    "        for route in routes_not_same1:\n",
    "            for connection in route:\n",
    "                route_graph2.add_node(connection[0], **network1.graph.nodes[connection[0]])\n",
    "                if connection[0] not in used_stops2:\n",
    "                    used_stops2.append(connection[0])\n",
    "                    \n",
    "                route_graph2.add_node(connection[-1], **network1.graph.nodes[connection[-1]])\n",
    "                if connection[-1] not in used_stops2:\n",
    "                    used_stops2.append(connection[-1])\n",
    "                \n",
    "                route_graph2.add_edge(connection[0], connection[-1], **network1.graph.get_edge_data(connection[0], connection[-1]))\n",
    "            route_network2.append(route.copy())\n",
    "        \n",
    "        # All same routes from parent 1 will go to child 1\n",
    "        for route in routes_same1:\n",
    "            for connection in route:\n",
    "                route_graph1.add_node(connection[0], **network1.graph.nodes[connection[0]])\n",
    "                if connection[0] not in used_stops1:\n",
    "                    used_stops1.append(connection[0])\n",
    "                    \n",
    "                route_graph1.add_node(connection[-1], **network1.graph.nodes[connection[-1]])\n",
    "                if connection[-1] not in used_stops1:\n",
    "                    used_stops1.append(connection[-1])\n",
    "                \n",
    "                route_graph1.add_edge(connection[0], connection[-1], **network1.graph.get_edge_data(connection[0], connection[-1]))\n",
    "            route_network1.append(route.copy())\n",
    "            \n",
    "        # PARENT 2\n",
    "        # All not same routes from parent 2 will go to child 1\n",
    "        for route in routes_not_same2:\n",
    "            for connection in route:\n",
    "                route_graph1.add_node(connection[0], **network2.graph.nodes[connection[0]])\n",
    "                if connection[0] not in used_stops1:\n",
    "                    used_stops1.append(connection[0])\n",
    "                    \n",
    "                route_graph1.add_node(connection[-1], **network2.graph.nodes[connection[-1]])\n",
    "                if connection[-1] not in used_stops1:\n",
    "                    used_stops1.append(connection[-1])\n",
    "                \n",
    "                route_graph1.add_edge(connection[0], connection[-1], **network2.graph.get_edge_data(connection[0], connection[-1]))\n",
    "            route_network1.append(route.copy())\n",
    "        \n",
    "        # All same routes from parent 2 will go to child 2\n",
    "        for route in routes_same2:\n",
    "            for connection in route:\n",
    "                route_graph2.add_node(connection[0], **network2.graph.nodes[connection[0]])\n",
    "                if connection[0] not in used_stops2:\n",
    "                    used_stops2.append(connection[0])\n",
    "                    \n",
    "                route_graph2.add_node(connection[-1], **network2.graph.nodes[connection[-1]])\n",
    "                if connection[-1] not in used_stops2:\n",
    "                    used_stops2.append(connection[-1])\n",
    "                \n",
    "                route_graph2.add_edge(connection[0], connection[-1], **network2.graph.get_edge_data(connection[0], connection[-1]))\n",
    "            route_network2.append(route.copy())\n",
    "    \n",
    "        child1 = networkObj(route_network1, used_stops1, route_graph1, conn_type1, walk_type1)\n",
    "        child2 = networkObj(route_network2, used_stops2, route_graph2, conn_type2, walk_type2)\n",
    "        \n",
    "        print(\"SOME ROUTES ARE DIFFERENT\")\n",
    "    \n",
    "    print(\"* Checking Child 1 for errors:\", flush=True)\n",
    "    # TODO: DELETE FOR TESTING IF GRAPH IS CONSISTENT WITH ITS LIST OF ROUTES\n",
    "    print(\"Checking for graph and route consistency...\", flush=True)\n",
    "    check_graph_with_route(child1)\n",
    "    print(\"Checking for graph and list of stops consistency...\", flush=True)\n",
    "    check_graph_with_stops(child1)\n",
    "    print(\"Checking if order of routes is correct...\", flush=True)\n",
    "    check_order_route(child1.routes)\n",
    "    print(\"Checking for list of stops and route consistency...\", flush=True)\n",
    "    check_stops_routes(child1)\n",
    "    print(\"Checking for duplicates in routes...\")\n",
    "    check_duplicate_routes(child1)\n",
    "    print()\n",
    "    \n",
    "    print(\"* Checking Child 2 for errors:\", flush=True)\n",
    "    # TODO: DELETE FOR TESTING IF GRAPH IS CONSISTENT WITH ITS LIST OF ROUTES\n",
    "    print(\"Checking for graph and route consistency...\", flush=True)\n",
    "    check_graph_with_route(child2)\n",
    "    print(\"Checking for graph and list of stops consistency...\", flush=True)\n",
    "    check_graph_with_stops(child2)\n",
    "    print(\"Checking if order of routes is correct...\", flush=True)\n",
    "    check_order_route(child2.routes)\n",
    "    print(\"Checking for list of stops and route consistency...\", flush=True)\n",
    "    check_stops_routes(child2)\n",
    "    print(\"Checking for duplicates in routes...\")\n",
    "    check_duplicate_routes(child2)\n",
    "\n",
    "    return child1, child2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MUTATION FUNCTION\n",
    "\n",
    "# Modify the stop connections of a random route in the network\n",
    "# Randomly select a route and randomly select a stop in that route\n",
    "# Then randomly select another stop that is a not too far from the selected stop based on threshold\n",
    "# Swap connections with that stop\n",
    "def mutate(network_to_mutate, graph_of_stops):\n",
    "    global set_walk_distance, MAX_DISTANCE\n",
    "    \n",
    "    # This is to copy the original network to be compared later\n",
    "    test_graph_net2 = network_to_mutate.graph.copy()\n",
    "    test_routes_net2 = [copy.deepcopy(r) for r in network_to_mutate.routes]\n",
    "    test_stops_net2 = network_to_mutate.stops.copy()\n",
    "    test_stops_connType2 = network_to_mutate.conn_type\n",
    "    test_stops_walkType2 = network_to_mutate.walk_distance\n",
    "    copy_test_network = networkObj(test_routes_net2, test_stops_net2, test_graph_net2, test_stops_connType2, test_stops_walkType2)\n",
    "    \n",
    "    # Randomly select a route\n",
    "    random_route = random.choice(network_to_mutate.routes)\n",
    "\n",
    "    \n",
    "    # TODO: This is a temporary solution, it chooses either of the connections within the route except for the first and last connection\n",
    "    # Randomly select a stop in the route\n",
    "    # random_node_connection = random.choice(random_route) # Choose a random connection in the route\n",
    "    index_array = list(range(1, len(random_route)-1))\n",
    "    connection_index = random.choice(index_array)\n",
    "    random_node_connection = random_route[connection_index]\n",
    "    \n",
    "    connection_stop_index = random.choice([0, -1]) # Choose whether the origin or destination node\n",
    "    random_stop = random_node_connection[connection_stop_index] # The random stop to be swapped\n",
    "    \n",
    "    print(\"PICKED NODE TO SWAP - \", random_stop)\n",
    "    \n",
    "    # Get the old total distance\n",
    "    old_total_distance = 0\n",
    "    for connection in random_route:\n",
    "        edge_data = network_to_mutate.graph.get_edge_data(connection[0], connection[-1])\n",
    "        \n",
    "        if edge_data == None:\n",
    "            print(\"-- ERROR MISSING EDGE INFORMATION: \", connection[0], \" - \", connection[-1])\n",
    "        else:\n",
    "            old_total_distance += edge_data['distance']\n",
    "    \n",
    "    \n",
    "    # This is to get the subset distance (Distance without the connection with chosen random stop)\n",
    "    if connection_stop_index == 0: # If it is the origin node in that connection (A, B, C and B is the chosen. Get B-C and A-B)\n",
    "        prev_connection = random_route[connection_index-1] # Get the previous connection\n",
    "        prev_node = prev_connection[0] # Get the origin node for that connection\n",
    "        distance1 = network_to_mutate.graph.get_edge_data(prev_node, random_stop)['distance'] # Get the distance of the previous connection\n",
    "        distance2 = network_to_mutate.graph.get_edge_data(random_stop, random_node_connection[-1])['distance'] # Get the distance of the current connection\n",
    "        distance_to_subtract = distance1 + distance2\n",
    "        \n",
    "        # Previous connection: node1 - random_node\n",
    "        # Current connection: random_node - node2\n",
    "        node1 = prev_node # Setting the partner nodes\n",
    "        node2 = random_node_connection[-1]\n",
    "        \n",
    "    else: #If it is the dest node in that connection\n",
    "        distance1 = network_to_mutate.graph.get_edge_data(random_node_connection[0], random_stop)['distance'] # Get the distance of the current connection\n",
    "        next_connection = random_route[connection_index+1] # Get the next route\n",
    "        next_node = next_connection[-1] # Get the destination node for the next connection\n",
    "        distance2 = network_to_mutate.graph.get_edge_data(random_stop, next_node)['distance']\n",
    "        distance_to_subtract = distance1 + distance2\n",
    "        \n",
    "        # Previous connection: node1 - random_node\n",
    "        # Current connection: random_node - node2\n",
    "        node2 = next_node\n",
    "        node1 = random_node_connection[0]\n",
    "        \n",
    "    subset_distance = old_total_distance - distance_to_subtract\n",
    "    # Get the route id\n",
    "    random_route_id = network_to_mutate.graph.get_edge_data(random_node_connection[0], random_node_connection[-1])['route_id']\n",
    "    \n",
    "    # Will try searching for a random stop 50 times (arbitrary)\n",
    "    for i in range(50):\n",
    "        # Get a random stop\n",
    "        new_random_stop, new_random_stop_data = random.choice(list(graph_of_stops.nodes(data=True)))\n",
    "        \n",
    "        \n",
    "        # Check if the new random stop is not within walking distance with the other stop in the route\n",
    "        # Walking distance between node1 in route and stop to be swapped with\n",
    "        source = (new_random_stop_data['lat'], new_random_stop_data['lon'])\n",
    "        point = (graph_of_stops.nodes[node1]['lat'], graph_of_stops.nodes[node1]['lon'])\n",
    "        walking_distance1 = geodesic(source, point).meters\n",
    "        \n",
    "        # Walking distance between node2 in route and stop to be swapped with\n",
    "        source = (new_random_stop_data['lat'], new_random_stop_data['lon'])\n",
    "        point = (graph_of_stops.nodes[node2]['lat'], graph_of_stops.nodes[node2]['lon'])\n",
    "        walking_distance2 = geodesic(source, point).meters\n",
    "        \n",
    "        # Check if it already has been used in the route\n",
    "        isCandidate = True\n",
    "        for connection in random_route:\n",
    "            if new_random_stop == connection[0] or new_random_stop == connection[-1]:\n",
    "                isCandidate = False\n",
    "                print(\"NEW NODE WAS ALREADY USED\", flush=True)\n",
    "                continue\n",
    "        \n",
    "        # Check if the edge has already been used\n",
    "        has_edge1 = network_to_mutate.graph.has_edge(node1, new_random_stop)\n",
    "        has_edge2 = network_to_mutate.graph.has_edge(new_random_stop, node2)\n",
    "        \n",
    "        if has_edge1:\n",
    "            print(f\"** Already have edge 1\")\n",
    "        if has_edge2:\n",
    "            print(f\"** Already have edge 2\")\n",
    "            \n",
    "        if i == 49:\n",
    "            print(\"------REACHED END\")\n",
    "        \n",
    "        # If it is not within walking distances, has not been used in the same route, has a path, has no existing edge\n",
    "        if walking_distance1 >= set_walk_distance and walking_distance2 >= set_walk_distance and isCandidate and nx.has_path(CITY_GRAPH, node1, new_random_stop) and nx.has_path(CITY_GRAPH, new_random_stop, node2) and not has_edge1 and not has_edge2:\n",
    "            # DISTANCE 1: Get the total distance from point A to point B\n",
    "            shortest_route1 = nx.shortest_path(CITY_GRAPH, node1, new_random_stop)\n",
    "            distance_travelled1 = 0\n",
    "            for i in range(len(shortest_route1)-1):\n",
    "                node_data = CITY_GRAPH.nodes[shortest_route1[i]]\n",
    "                next_node_data = CITY_GRAPH.nodes[shortest_route1[i+1]]\n",
    "                distance_travelled1 += haversine(node_data['y'], node_data['x'], next_node_data['y'], next_node_data['x'])\n",
    "            \n",
    "            # DISTANCE 2: Get the total distance from point A to point B\n",
    "            shortest_route2 = nx.shortest_path(CITY_GRAPH, new_random_stop, node2)\n",
    "            distance_travelled2 = 0\n",
    "            for i in range(len(shortest_route2)-1):\n",
    "                node_data = CITY_GRAPH.nodes[shortest_route2[i]]\n",
    "                next_node_data = CITY_GRAPH.nodes[shortest_route2[i+1]]\n",
    "                distance_travelled2 += haversine(node_data['y'], node_data['x'], next_node_data['y'], next_node_data['x'])\n",
    "                \n",
    "            \n",
    "            # If its within the 15km distance, then this new stop can be used\n",
    "            if subset_distance + distance_travelled1 + distance_travelled2 <= MAX_DISTANCE:\n",
    "                # Add the new stop to the used stops\n",
    "                if new_random_stop not in network_to_mutate.stops:\n",
    "                    network_to_mutate.stops.append(new_random_stop)\n",
    "                \n",
    "                # Modify the graph by adding the new node\n",
    "                network_to_mutate.graph.add_node(new_random_stop, **graph_of_stops.nodes[new_random_stop])\n",
    "                print(\"MUTATION: ADDED NEW NODE TO GRAPH \", new_random_stop)\n",
    "                \n",
    "                # Connect the new stop to the edges\n",
    "                name1 = f\"{shortest_route1[0]}_{shortest_route1[-1]}\"\n",
    "                name2 = f\"{shortest_route2[0]}_{shortest_route2[-1]}\"\n",
    "                connection_count1 = network_to_mutate.graph.get_edge_data(node1, random_stop)['edge_id']\n",
    "                connection_count2 = network_to_mutate.graph.get_edge_data(random_stop, node2)['edge_id']\n",
    "                network_to_mutate.graph.add_edge(shortest_route1[0], shortest_route1[-1], road_path=shortest_route1, edge_name=name1, edge_id = connection_count1, route_id = random_route_id, distance = distance_travelled1) # Add edge\n",
    "                network_to_mutate.graph.add_edge(shortest_route2[0], shortest_route2[-1], road_path=shortest_route2, edge_name=name2, edge_id = connection_count2, route_id = random_route_id, distance = distance_travelled2) # Add edge \n",
    "                \n",
    "                #TODO: DELETE PRINT FOR TESTING\n",
    "                print(\"MUTATION: CONNECTED NEW STOP TO EDGES\")  \n",
    "                \n",
    "                # Remove the old connections and node if it has no other connections\n",
    "                network_to_mutate.graph.remove_edge(node1, random_stop)\n",
    "                network_to_mutate.graph.remove_edge(random_stop, node2)\n",
    "                print(\"MUTATION: REMOVED OLD CONNECTIONS TO NODE\")\n",
    "                if (network_to_mutate.graph.degree(random_stop) == 0):\n",
    "                    network_to_mutate.graph.remove_node(random_stop)                \n",
    "                    network_to_mutate.stops.remove(random_stop)\n",
    "                    \n",
    "                    print(\"MUTATION: REMOVED OLD NODE \", random_stop)\n",
    "                else:\n",
    "                    print(\"MUTATION: DIDNT REMOVED OLD NODE \", random_stop)\n",
    "                \n",
    "                # TODO: Delete FOR TESTING ONLY\n",
    "                unique_nodes_G1 = set(copy_test_network.graph.nodes) - set(network_to_mutate.graph.nodes)\n",
    "                unique_edges_G1 = set(copy_test_network.graph.edges) - set(network_to_mutate.graph.edges)\n",
    "\n",
    "                unique_nodes_G2 = set(network_to_mutate.graph.nodes) - set(copy_test_network.graph.nodes)\n",
    "                unique_edges_G2 = set(network_to_mutate.graph.edges) - set(copy_test_network.graph.edges)\n",
    "                print(\"TESTING DIFFERENCES BETWEEN ORIGINAL AND OLD GRAPH\")\n",
    "                \n",
    "                # Display unique nodes and edges for G1\n",
    "                print(\"Unique nodes in original (not in new):\")\n",
    "                for node in unique_nodes_G1:\n",
    "                    print(node)\n",
    "\n",
    "                print(\"Unique edges in original (not in new):\")\n",
    "                for edge in unique_edges_G1:\n",
    "                    print(edge)\n",
    "\n",
    "                # Display unique nodes and edges for G2\n",
    "                print(\"Unique nodes in new (not in original):\")\n",
    "                for node in unique_nodes_G2:\n",
    "                    print(node)\n",
    "\n",
    "                print(\"Unique edges in new (not in original):\")\n",
    "                for edge in unique_edges_G2:\n",
    "                    print(edge)\n",
    "                \n",
    "                # Modify the route\n",
    "                if connection_stop_index == 0: #If its the origin node\n",
    "                    random_route[connection_index-1] = shortest_route1 # Change the previous connection\n",
    "                    random_route[connection_index] = shortest_route2 # Change the current connection\n",
    "                    \n",
    "                    #TODO: DELETE FOR TESTING\n",
    "                    random_route2 = copy_test_network.routes[network_to_mutate.routes.index(random_route)]\n",
    "                    print(\"ORIGINAL: \", random_route2[connection_index-1][0], \" - \", random_route2[connection_index-1][-1])\n",
    "                    print(\"ORIGINAL: \", random_route2[connection_index][0], \" - \", random_route2[connection_index][-1])\n",
    "                    print(\"MODIFIED: \", random_route[connection_index-1][0], \" - \", random_route[connection_index-1][-1])\n",
    "                    print(\"MODIFIED: \", random_route[connection_index][0], \" - \", random_route[connection_index][-1])\n",
    "                    \n",
    "                else: #else If its the dest node\n",
    "                    random_route[connection_index] = shortest_route1 # Change the current connection\n",
    "                    random_route[connection_index+1] = shortest_route2 # Change the next connection\n",
    "                    \n",
    "                    #TODO: DELETE FOR TESTING\n",
    "                    random_route2 = copy_test_network.routes[network_to_mutate.routes.index(random_route)]\n",
    "                    print(\"ORIGINAL: \", random_route2[connection_index][0], \" - \", random_route2[connection_index][-1])\n",
    "                    print(\"ORIGINAL: \", random_route2[connection_index+1][0], \" - \", random_route2[connection_index+1][-1])\n",
    "                    print(\"MODIFIED: \", random_route[connection_index][0], \" - \", random_route[connection_index][-1])\n",
    "                    print(\"MODIFIED: \", random_route[connection_index+1][0], \" - \", random_route[connection_index+1][-1])\n",
    "                    \n",
    "                print(\"MUTATION: MODIFIED THE NETWORK OBJECT'S ROUTE\")\n",
    "                \n",
    "                        \n",
    "                # TODO: DELETE FOR TESTING IF GRAPH IS CONSISTENT WITH ITS LIST OF ROUTES\n",
    "                print(\"Checking for graph and route consistency...\")\n",
    "                check_graph_with_route(network_to_mutate)\n",
    "                print(\"Checking for graph and list of stops consistency...\")\n",
    "                check_graph_with_stops(network_to_mutate)\n",
    "                print(\"Checking if order of routes is correct...\")\n",
    "                check_order_route(network_to_mutate.routes)\n",
    "                print(\"Checking for list of stops and route consistency...\")\n",
    "                check_stops_routes(network_to_mutate)\n",
    "                print(\"Checking for duplicates in routes...\")\n",
    "                check_duplicate_routes(network_to_mutate)\n",
    "                \n",
    "                print(\"MUTATION DONE\", flush=True)\n",
    "                \n",
    "                \n",
    "                # Break the loop once we swap\n",
    "                print()\n",
    "                break  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitness Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitness function\n",
    "\n",
    "def select_highest_scoring_mutation(candidate_road_snapped_networks, num_failure_removal,\n",
    "                                    weight_random_failure, weight_targeted_failure, weight_radius_of_gyration):\n",
    "    max_fitness_score = -np.inf\n",
    "    max_candidate_route_snapped_network = None\n",
    "\n",
    "    for n in candidate_road_snapped_networks:\n",
    "        fitness_score = compute_fitness_score(n, num_failure_removal,\n",
    "                                              weight_random_failure, weight_targeted_failure, weight_radius_of_gyration)\n",
    "        if fitness_score > max_fitness_score:\n",
    "            max_fitness_score = fitness_score\n",
    "            max_candidate_route_snapped_network = n\n",
    "\n",
    "    return max_candidate_route_snapped_network\n",
    "\n",
    "def compute_fitness_score(road_snapped_network_graph, num_failure_removal,\n",
    "                          weight_random_failure, weight_targeted_failure, weight_connectivity):\n",
    "\n",
    "    random_failure_robustness = compute_random_failure_robustness(road_snapped_network_graph, num_failure_removal)\n",
    "    weighted_random_failure_robustness = weight_random_failure * random_failure_robustness\n",
    "\n",
    "    targeted_failure_robustness = compute_targeted_failure_robustness(road_snapped_network_graph, num_failure_removal)\n",
    "    weighted_targeted_failure_robustness = weight_targeted_failure * targeted_failure_robustness\n",
    "\n",
    "    connectivity_score = compute_connectivity(road_snapped_network_graph)\n",
    "    weighted_connectivity = weight_connectivity * connectivity_score\n",
    "    \n",
    "    # print(\"Random Failure Score: \", weighted_random_failure_robustness)\n",
    "    # print(\"Target Failure Score: \", weighted_targeted_failure_robustness)\n",
    "    # print(\"Connectivity: \", weighted_connectivity)\n",
    "\n",
    "    # Will use this return for now to utilize target and random failure nodes \n",
    "    return weighted_connectivity - weighted_random_failure_robustness - weighted_targeted_failure_robustness\n",
    "    # return weighted_radius_of_gyration\n",
    "\n",
    "\n",
    "### WRITTEN IN PSEUDOCODE\n",
    "def compute_connectivity(network):\n",
    "    # External connectivity - measure how connected is the jeepney route network with other modes of transpo\n",
    "    \n",
    "    # Get the ratio of transportation stops to total stops in the network\n",
    "    transpo_stops = [node for node, node_data in network.nodes(data=True) if node_data['isTranspo'] == True]\n",
    "    total_stops = len(network.nodes(data=True))\n",
    "    transpo_stop_ratio = len(transpo_stops) / total_stops\n",
    "\n",
    "    # Get the average degree of all transportation stops in the network\n",
    "    if len(transpo_stops) > 0:\n",
    "        avg_transpo_degree = sum(network.degree(stop) for stop in transpo_stops) / len(transpo_stops)\n",
    "    else:\n",
    "        avg_transpo_degree = 1\n",
    "\n",
    "    # Find a way to normalize the two values and combine them \n",
    "\n",
    "    # Internal connectivity - measure how connected is each jeepney route to other jeepney routes\n",
    "                    \n",
    "    # This counts how many nodes have intersections (Meaning node is connected to more than one route by route ID)\n",
    "    num_intersections = 0\n",
    "    for node, node_data in network.nodes(data=True):\n",
    "        connected_edges = network.edges(node)\n",
    "        unique_route_id = []\n",
    "        \n",
    "        for edge in connected_edges:\n",
    "            route_id = network[edge[0]][edge[1]]['route_id']\n",
    "            \n",
    "            if route_id not in unique_route_id:\n",
    "                unique_route_id.append(route_id)\n",
    "                \n",
    "        if len(unique_route_id) > 1:\n",
    "            num_intersections += 1\n",
    "\n",
    "    \n",
    "    # Change these weights based on what the expected values for \n",
    "    # the transpo_stop_ratio, avg_transpo_degree, and num_intersections will be\n",
    "    external_weight = 0.5\n",
    "    internal_weight = 0.5\n",
    "    \n",
    "    # TODO: Delete this\n",
    "    # print(\"Transpo stop ratio: \", transpo_stop_ratio)\n",
    "    # print(\"Num intersections: \", num_intersections)\n",
    "    # print(\"Average degree: \", avg_transpo_degree)\n",
    "\n",
    "    # Formula subject to change\n",
    "    return external_weight * (transpo_stop_ratio * avg_transpo_degree) + internal_weight * num_intersections\n",
    "\n",
    "\n",
    "def compute_random_failure_robustness(road_snapped_network_graph, num_removals):\n",
    "    graph_copy = road_snapped_network_graph.copy() # Make a copy\n",
    "    \n",
    "    for i in range(num_removals):\n",
    "        selected_node = random.choice(list(graph_copy.nodes()))\n",
    "        graph_copy.remove_node(selected_node)\n",
    "\n",
    "    diameter, avg_path_length = compute_network_statistics(graph_copy)\n",
    "    return compute_failure_robustness(graph_copy, diameter)\n",
    "\n",
    "def compute_targeted_failure_robustness(road_snapped_network_graph, num_removals):\n",
    "    graph_copy = road_snapped_network_graph.copy() # Make a copy\n",
    "    \n",
    "    for i in range(num_removals):\n",
    "        node_degrees = graph_copy.degree()\n",
    "        # Iterate over the DegreeView object to find the maximum degree\n",
    "        max_degree = max(degree for _, degree in node_degrees)\n",
    "        max_degree_node = get_node_with_degree(node_degrees, max_degree)\n",
    "        graph_copy.remove_node(max_degree_node)\n",
    "\n",
    "    diameter, avg_path_length = compute_network_statistics(graph_copy)\n",
    "    return compute_failure_robustness(graph_copy, diameter)\n",
    "\n",
    "def compute_failure_robustness(road_snapped_network_graph, max_path_length):\n",
    "    return float(max_path_length) / float(len(road_snapped_network_graph) - 1)\n",
    "\n",
    "def compute_network_statistics(road_snapped_network_graph):\n",
    "    path_lengths = get_path_lengths(road_snapped_network_graph) # Get the sum of all possible\n",
    "    avg_path_length = np.mean(path_lengths)\n",
    "    max_path_length = max(path_lengths)\n",
    "\n",
    "    #network_size = len(path_lengths)\n",
    "    #gcc = sorted(nx.connected_component_subgraphs(road_snapped_network_graph), key=len, reverse=True)\n",
    "    #giant_component_fraction = float(float(gcc[0].order()) / float(network_size))\n",
    "    #return max_path_length, avg_path_length, giant_component_fraction\n",
    "    return max_path_length, avg_path_length\n",
    "\n",
    "def get_node_with_degree(node_degrees, degree):\n",
    "    # Iterate over the DegreeView object to find the node with the specified degree\n",
    "    for node, _ in node_degrees:\n",
    "        if _ == degree:\n",
    "            return node\n",
    "    return None  # Return None if no node with the specified degree is found\n",
    "\n",
    "def get_path_lengths(snapped_road_network_graph):\n",
    "    return [sum(nx.single_source_shortest_path_length(snapped_road_network_graph, n).values())\n",
    "            for n in snapped_road_network_graph]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Error Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERROR CHECK - Checking if there are duplicate routes in the list of routes\n",
    "def check_duplicate_routes(network):\n",
    "    seen = set()\n",
    "    duplicates = []\n",
    "    error = \"xxx\"\n",
    "\n",
    "    for route in network.routes:\n",
    "        for lst in route:\n",
    "            tpl = tuple(lst)\n",
    "            if tpl in seen:\n",
    "                duplicates.append(lst)\n",
    "            else:\n",
    "                seen.add(tpl)\n",
    "\n",
    "    if duplicates:\n",
    "        print(f\"---- ERROR{error} Duplicate lists found\")\n",
    "        for duplicate in duplicates:\n",
    "            print(duplicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERROR Check - Checks if routes is consistent with its stops\n",
    "def check_stops_routes(network):\n",
    "    error = \"xxx\"\n",
    "    # Checks if each node in the route is in the list of stops\n",
    "    for route in network.routes:\n",
    "        for connection in route:\n",
    "            if connection[0] not in network.stops:\n",
    "                print(f\"---- ERROR{error} MISSING ROUTE ORIGIN STOP IN LIST OF STOPS \", connection[0])\n",
    "            if connection[-1] not in network.stops:\n",
    "                print(\"-- MISSING ROUTE DEST STOP IN LIST OF STOPS \", connection[-1])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERROR Check - Checks if the routes are in correct order\n",
    "def check_order_route(routes):\n",
    "    error = \"xxx\"\n",
    "    for route in routes:\n",
    "        for connection in route:\n",
    "            if route.index(connection) > 0:\n",
    "                if connection[0] != prev_connection[-1]:\n",
    "                    print(f\"---- ERROR{error} WRONG ORDER DETECTED --\")\n",
    "                    print(prev_connection[0], \" - \", prev_connection[-1])\n",
    "                    print(connection[0], \" - \", connection[-1])\n",
    "                    print(\"--------------------------\")\n",
    "            prev_connection = connection\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERROR CHECK - Checks the consistency of the network with its routes\n",
    "def check_graph_with_route(_network):\n",
    "    error = \"xxx\"\n",
    "    for route in _network.routes:\n",
    "        for connection in route:\n",
    "            if not _network.graph.has_node(connection[0]):\n",
    "                print(f\"---- ERROR{error} MISSING NODE IN GRAPH: \", connection[0])\n",
    "            if not _network.graph.has_node(connection[-1]):\n",
    "                print(f\"---- ERROR{error} MISSING NODE IN GRAPH: \", connection[-1])\n",
    "            if not _network.graph.has_edge(connection[0], connection[-1]):\n",
    "                print(f\"---- ERROR{error} MISSING EDGE IN GRAPH: \", connection[0], \" - \", connection[-1])\n",
    "                \n",
    "            if _network.graph.get_edge_data(connection[0], connection[-1]) == None:\n",
    "                print(f\"---- ERROR{error} MISSING EDGE INFORMATION: \", connection[0], \" - \", connection[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERROR CHECK - Checks the consistency of the network with its list of stops\n",
    "def check_graph_with_stops(_network):\n",
    "    error = \"xxx\"\n",
    "    # Checks if all stops in the list is in the graph\n",
    "    for stop in _network.stops:\n",
    "        if not _network.graph.has_node(stop):\n",
    "            print(f\"---- ERROR{error} MISSING LIST STOP IN GRAPH: \", stop)\n",
    "            \n",
    "    # Checks if all nodes in the graph are in the list\n",
    "    for node, node_data in _network.graph.nodes(data=True):\n",
    "        if node not in _network.stops:\n",
    "            print(f\"---- ERROR{error} MISSING GRAPH NODE IN LIST: \", node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: WORKING IN PROGRESS\n",
    "def simplicity_metric(network):\n",
    "    routes = network.routes\n",
    "    \n",
    "    for route in routes:\n",
    "        for i in range(len(route) - 1):\n",
    "            u, v = route[i], route[i + 1]\n",
    "            \n",
    "            if CITY_GRAPH.has_edge(u, v):\n",
    "                edge_data = CITY_GRAPH.get_edge_data(u, v)\n",
    "            else:\n",
    "                # Skip if there's no direct edge between u and v\n",
    "                continue\n",
    "            \n",
    "            # Edge data might have multiple edges with different keys\n",
    "            for key in edge_data:\n",
    "                road_name = edge_data[key].get('name', 'Unnamed Road')\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Analysis Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longest route, shortest route, average route length, network diamater"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GA and Fitness Function Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #Weights and Fitness Function configuration\n",
    "# num_failure_removal = 4\n",
    "# weight_random_failure = 0.15\n",
    "# weight_targeted_failure = 0.15\n",
    "# weight_connectivity = 0.7\n",
    "\n",
    "# i = 0\n",
    "# for network in list_of_networks_Manila:\n",
    "#     print(f\"NETWORK {i}\")\n",
    "#     road_snapped_network_graph = network.graph\n",
    "#     score = compute_fitness_score(road_snapped_network_graph, num_failure_removal, weight_random_failure, weight_targeted_failure, weight_connectivity)\n",
    "#     print(f\"Network {i} score: {score}\")\n",
    "#     print()\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #TODO: DELETE FOR GA TESTING ONLY\n",
    "# #Testing crossover and mutate\n",
    "\n",
    "# network1= list_of_networks_Manila[0]\n",
    "# network2= list_of_networks_Manila[1]\n",
    "\n",
    "# test_graph_net1 = network1.graph.copy()\n",
    "# test_routes_net1 = [copy.deepcopy(r) for r in network1.routes]\n",
    "# test_stops_net1 = network1.stops.copy()\n",
    "# copy_test_network1 = networkObj(test_routes_net1, test_stops_net1, test_graph_net1, list_of_networks_Manila[0].conn_type)\n",
    "\n",
    "# test_graph_net2 = network2.graph.copy()\n",
    "# test_routes_net2 = [copy.deepcopy(r) for r in network2.routes]\n",
    "# test_stops_net2 = network2.stops.copy()\n",
    "# copy_test_network2 = networkObj(test_routes_net2, test_stops_net2, test_graph_net2, list_of_networks_Manila[1].conn_type)\n",
    "\n",
    "# child1, child2 = crossover_split_index(copy_test_network1,copy_test_network2)\n",
    "\n",
    "# map_center = (14.599512, 120.984222)\n",
    "\n",
    "# print(\"--------------- START\")\n",
    "# if len(child1.graph) != len(child1.stops):\n",
    "#         print(\"-----CHILD 1 STOPS AND GRAPH NOT EQUAL\")\n",
    "# if len(child2.graph) != len(child2.stops):\n",
    "#     print(\"-----CHILD 2 STOPS AND GRAPH NOT EQUAL\")\n",
    "# print(\"--------------- END\")\n",
    "# print()\n",
    "        \n",
    "# # -----Child 1 Display -------------\n",
    "# m = folium.Map(location=map_center, zoom_start=1, tiles='openstreetmap')\n",
    "# add_markers(child1.stops, child1.graph)\n",
    "    \n",
    "# for route in child1.routes:\n",
    "#     for connection in route:\n",
    "#         ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "# m.save(f\"GA TEST (DELETE LATER)/child1_crossover.html\")\n",
    "\n",
    "# # ------Child 2 Display ------------\n",
    "# m = folium.Map(location=map_center, zoom_start=1, tiles='openstreetmap')\n",
    "# add_markers(child2.stops, child2.graph)\n",
    "    \n",
    "# for route in child2.routes:\n",
    "#     for connection in route:\n",
    "#         ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "# m.save(f\"GA TEST (DELETE LATER)/child2_crossover.html\")\n",
    "\n",
    "\n",
    "# # # ---------Graph test---------------\n",
    "# # # TODO: Delete FOR TESTING ONLY\n",
    "# # unique_nodes_G1 = set(child1.graph.nodes) - set(child2.graph.nodes)\n",
    "# # unique_edges_G1 = set(child1.graph.edges) - set(child2.graph.edges)\n",
    "\n",
    "# # unique_nodes_G2 = set(child2.graph.nodes) - set(child1.graph.nodes)\n",
    "# # unique_edges_G2 = set(child2.graph.edges) - set(child1.graph.edges)\n",
    "# # print(\"TESTING DIFFERENCES BETWEEN Child1 AND Child2\")\n",
    "\n",
    "# # # Display unique nodes and edges for G1\n",
    "# # print(\"Unique nodes in child1 (not in child2):\")\n",
    "# # for node in unique_nodes_G1:\n",
    "# #     print(node)\n",
    "\n",
    "# # print(\"Unique edges in child1 (not in child2):\")\n",
    "# # for edge in unique_edges_G1:\n",
    "# #     print(edge)\n",
    "\n",
    "# # # Display unique nodes and edges for G2\n",
    "# # print(\"Unique nodes in child2 (not in child1):\")\n",
    "# # for node in unique_nodes_G2:\n",
    "# #     print(node)\n",
    "\n",
    "# # print(\"Unique edges in child2 (not in child1):\")\n",
    "# # for edge in unique_edges_G2:\n",
    "# #     print(edge)\n",
    "\n",
    "# # --------Mutate test --------------\n",
    "# for i in range(1):\n",
    "#     print(\"Child 1 ATTEMPT MUTATION\")\n",
    "#     mutate(child1, graph_of_stops_Manila)\n",
    "#     print(\"-------------------------\")\n",
    "#     print()\n",
    "    \n",
    "#     print(\"Child 2 ATTEMPT MUTATION\")\n",
    "#     mutate(child2, graph_of_stops_Manila)\n",
    "#     print(\"-------------------------\")\n",
    "#     print()\n",
    "    \n",
    "#     if len(child1.graph) != len(child1.stops):\n",
    "#         print(\"-----CHILD 1 STOPS AND GRAPH NOT EQUAL\")\n",
    "#     if len(child2.graph) != len(child2.stops):\n",
    "#         print(\"-----CHILD 2 STOPS AND GRAPH NOT EQUAL\")\n",
    "\n",
    "#     # # -----Child 1 Mutation Display -------------\n",
    "#     # m = folium.Map(location=map_center, zoom_start=1, tiles='openstreetmap')\n",
    "#     # add_markers(child1.stops, child1.graph)\n",
    "        \n",
    "#     # for route in child1.routes:\n",
    "#     #     for connection in route:\n",
    "#     #         ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "#     # m.save(f\"GA TEST (DELETE LATER)/child1_mutation{i}.html\")\n",
    "\n",
    "#     # # ------Child 2 Mutation Display ------------\n",
    "#     # m = folium.Map(location=map_center, zoom_start=1, tiles='openstreetmap')\n",
    "#     # add_markers(child2.stops, child2.graph)\n",
    "        \n",
    "#     # for route in child2.routes:\n",
    "#     #     for connection in route:\n",
    "#     #         ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "#     # m.save(f\"GA TEST (DELETE LATER)/child2_mutation{i}.html\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot/visualize connected zones on the map\n",
    "import random\n",
    "\n",
    "# This is to better visualize the networks\n",
    "def plot_connected_zones_network_on_map(graph, initial_location=[0, 0], zoom_start=10):\n",
    "    # Create a map centered at the initial location\n",
    "    map_center = (14.599512, 120.984222) # TEMPORARY WILL ZOOM TO MANILA\n",
    "    m = folium.Map(location=map_center, zoom_start=zoom_start, tiles='openstreetmap')\n",
    "    \n",
    "    #Colours for Visualization\n",
    "    colors = [\n",
    "    \"Red\", \"Green\", \"Blue\", \"Yellow\", \"Orange\", \"Purple\", \"Cyan\", \"Magenta\", \"Maroon\",\n",
    "    \"Olive\", \"Lime\", \"Teal\", \"Navy\", \"Aqua\", \"Fuchsia\", \"Coral\", \"Indigo\", \"Violet\"]\n",
    "    \n",
    "    color_map = {}\n",
    "\n",
    "    # Iterate over the nodes in the network\n",
    "    for node, data in graph.nodes(data=True):\n",
    "        # Check if the node has a geometry attribute\n",
    "        if 'geometry' in data:\n",
    "            # Get the geometry of the node\n",
    "            geometry = data['geometry']\n",
    "\n",
    "            # Check the geometry type and plot accordingly\n",
    "            if geometry.geom_type == 'Point':\n",
    "                # Plot a marker for points    \n",
    "                #folium.Marker(location=[geometry.y, geometry.x], popup=f\"{data['name']}\").add_to(m)\n",
    "                continue\n",
    "            elif geometry.geom_type in ['Polygon', 'MultiPolygon']:\n",
    "                \n",
    "                network_id = data[\"network_id\"]\n",
    "                \n",
    "                if network_id not in color_map:\n",
    "                    color = random.choice(colors)\n",
    "                    color_map[network_id] = color\n",
    "                else:\n",
    "                    color = color_map[network_id]\n",
    "                \n",
    "                if geometry.geom_type == 'Polygon':\n",
    "                    polygons = [geometry]\n",
    "                else:\n",
    "                    polygons = geometry.geoms\n",
    "\n",
    "                for polygon in polygons:\n",
    "                    coordinates = []\n",
    "                    for point in polygon.exterior.coords:\n",
    "                        coordinates.append([point[1], point[0]])\n",
    "                    folium.Polygon(locations=coordinates, fill=True, color=color, fill_opacity=0.4).add_to(m)\n",
    "\n",
    "    # Return the map\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to visualize the stops\n",
    "def plot_stops_on_map(network_map, stops, initial_location=[0, 0], zoom_start=10):\n",
    "    # Iterate over the nodes in the network\n",
    "    for stop in stops:\n",
    "        folium.Marker(location=[stop.lat, stop.long], popup=f\"{stop.isTranspo}\").add_to(network_map)\n",
    "        \n",
    "    return network_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manila Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Paths\n",
    "Manila_pikl_filepath = \"Saved Networks/Manila/\"\n",
    "Manila_map_filepath = \"Saved Maps/Manila/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READING DATA (All Amenities in Manila)\n",
    "#CHANGE THIS BACK\n",
    "merged_amenities_points_gdf = gpd.read_file('./City Data/Manila City/Manila_point.geojson')\n",
    "merged_amenities_polygons_gdf= gpd.read_file('././City Data/Manila City/Manila_polygon.geojson')\n",
    "\n",
    "merged_amenities_polygons_gdf['amenity_points'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting total area to be used for the area connection type\n",
    "merged_amenities_polygons_gdf['area'] = degrees_to_meters(merged_amenities_polygons_gdf['geometry'].area)\n",
    "manila_area_sum = merged_amenities_polygons_gdf['area'].sum()\n",
    "\n",
    "manila_area_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spatial index for points\n",
    "idx = rtree_index.Index()\n",
    "for j, point in merged_amenities_points_gdf.iterrows():\n",
    "    idx.insert(j, point['geometry'].bounds)\n",
    "\n",
    "# Iterate over polygons\n",
    "for i, polygon in merged_amenities_polygons_gdf.iterrows():\n",
    "    points_within_polygon = []\n",
    "    \n",
    "    # Iterate over points within the bounding box of the polygon\n",
    "    for j in idx.intersection(polygon['geometry'].bounds):\n",
    "        point = merged_amenities_points_gdf.loc[j]\n",
    "        if polygon['geometry'].intersects(point['geometry']):\n",
    "            points_within_polygon.append(j)\n",
    "    \n",
    "    merged_amenities_polygons_gdf.at[i, 'amenity_points'] = points_within_polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Manila Zone Network Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- LEVEL 1 \n",
    "# IMPORT INITIAL NETWORK\n",
    "initial_network_Manila = import_networks(f\"{Manila_pikl_filepath}Manila_Initial_Network.pkl\")\n",
    "\n",
    "# IMPORT FILTERED NETWORK\n",
    "filtered_manila_amenities_network = import_networks(f\"{Manila_pikl_filepath}Manila_Filtered_Network.pkl\")\n",
    "\n",
    "# IMPORT COMBINED AMENITIES NETWORK\n",
    "combined_graph_Manila = import_networks(f\"{Manila_pikl_filepath}Manila_Combined_Amenities_Network.pkl\")\n",
    "\n",
    "# ------- LEVEL 2\n",
    "# IMPORT POPULATION GRAPH\n",
    "pop_graph = import_networks(f\"{Manila_pikl_filepath}Manila_Population_Graph.pkl\")\n",
    "\n",
    "# IMPORT ZONE NETWORK\n",
    "graph_networks_of_polygons_Manila = import_networks(f\"{Manila_pikl_filepath}Manila_Zone_Network.pkl\")\n",
    "networks_map_Manila = plot_connected_zones_network_on_map(graph_networks_of_polygons_Manila, initial_location=[0, 0], zoom_start=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Stop list and Graph (Only to test the same stops)\n",
    "list_of_stops_Manila = import_networks(f\"{Manila_pikl_filepath}stop_list_Manila.pkl\")\n",
    "graph_of_stops_Manila = import_networks(f\"{Manila_pikl_filepath}stop_graph_Manila.pkl\")\n",
    "\n",
    "# Visualize the stops\n",
    "stops_map = plot_stops_on_map(networks_map_Manila, list_of_stops_Manila, initial_location=[0, 0], zoom_start=100)\n",
    "stops_map.save(f\"{Manila_map_filepath}stops_map.html\") # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Generated Routes (Only to test the same routes)\n",
    "# WALKING_DISTANCES -> 300,550,800\n",
    "# CONNECTION_TYPES -> \"Default\", \"Area\", \"Degree\", \"Mixed\"\n",
    "import_conn_type = CONNECTION_TYPES[0]\n",
    "import_walk_distance = WALKING_DISTANCES[0]\n",
    "\n",
    "if import_conn_type == 'Mixed':\n",
    "    list_of_networks_Manila = import_networks(f\"{Manila_pikl_filepath}Manila_Route_networks_{import_conn_type}.pkl\")\n",
    "else:\n",
    "    list_of_networks_Manila = import_networks(f\"{Manila_pikl_filepath}Manila_Route_networks_{import_conn_type}_{import_walk_distance}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing GA Results (Only to analyze shared results)\n",
    "# WALKING_DISTANCES -> 300,550,800\n",
    "# CONNECTION_TYPES -> \"Default\", \"Area\", \"Degree\", \"Mixed\"\n",
    "import_conn_type = CONNECTION_TYPES[0]\n",
    "import_walk_distance = WALKING_DISTANCES[0]\n",
    "\n",
    "if import_conn_type == 'Mixed':\n",
    "    population = import_networks(f\"{Manila_pikl_filepath}Manila_GA_Route_networks_{import_conn_type}.pkl\")\n",
    "else:\n",
    "    population = import_networks(f\"{Manila_pikl_filepath}Manila_GA_Route_networks_{import_conn_type}_{import_walk_distance}.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop Placement (Only to generate new stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 3 - CREATING STOPS TO BE PLACED ON ZONES\n",
    "graph_of_stops_Manila = nx.Graph()\n",
    "add_points_to_graph(initial_network_Manila, graph_networks_of_polygons_Manila) # Add first all transportation stops\n",
    "list_of_stops_Manila = []\n",
    "place_stops_on_roads(graph_networks_of_polygons_Manila, graph_of_stops_Manila, list_of_stops_Manila) # Adds stops graph_of_stops\n",
    "\n",
    "# Visualize the stops\n",
    "stops_map = plot_stops_on_map(networks_map_Manila, list_of_stops_Manila, initial_location=[0, 0], zoom_start=100)\n",
    "stops_map.save(f\"{Manila_map_filepath}stops_map.html\") # Save the map to an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export stops to pickle\n",
    "file_path = f'{Manila_pikl_filepath}stop_list_Manila.pkl'\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(list_of_stops_Manila, f)\n",
    "    \n",
    "file_path = f'{Manila_pikl_filepath}stop_graph_Manila.pkl'\n",
    "with open(file_path, 'wb') as f:\n",
    "    pickle.dump(graph_of_stops_Manila, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_of_stops_Manila)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(graph_of_stops_Manila)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop Connection (Only to generate new routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEVEL 4 - CONNECTING STOPS INTO A NETWORK\n",
    "\n",
    "# Configuration\n",
    "set_walk_distance = WALKING_DISTANCES[1]\n",
    "num_of_networks = 100\n",
    "conn_type = CONNECTION_TYPES[3]\n",
    "max_stops = 20\n",
    "max_routes = 30 # temporary, should be 30\n",
    "map_html_location = f\"Generated Route Networks HTML/Manila/{conn_type}/\"\n",
    "        \n",
    "# Generate route network\n",
    "list_of_networks_Manila = []\n",
    "\n",
    "print(f\"CHOSEN CONNECTION TYPE: {conn_type}\")\n",
    "current_network_count = 0\n",
    "for _ in range(num_of_networks):\n",
    "    route_count = 0 # Route is the connection between list of stops\n",
    "    connection_count = 0 # Connection is the connection between two stops / nodes\n",
    "    \n",
    "    print(f\"NETWORK {current_network_count}\")\n",
    "    if conn_type == \"Mixed\":\n",
    "        temp_conn_type = random.choice(CONNECTION_TYPES[:-1])\n",
    "        temp_walk_type = random.choice(WALKING_DISTANCES)\n",
    "        print(f\"NETWORK CONNECTION TYPE: {temp_conn_type}\")\n",
    "        route_network, route_graph = generate_route_network(list_of_stops_Manila, set_walk_distance, max_stops, max_routes, graph_of_stops_Manila, manila_area_sum, temp_conn_type) # Default max walking distance is 300m\n",
    "        used_stops = add_stops_to_list(route_network)\n",
    "        new_network = networkObj(route_network, used_stops, route_graph, temp_conn_type, temp_walk_type)\n",
    "    else:\n",
    "        route_network, route_graph = generate_route_network(list_of_stops_Manila, set_walk_distance, max_stops, max_routes, graph_of_stops_Manila, manila_area_sum, conn_type) # Default max walking distance is 300m\n",
    "        used_stops = add_stops_to_list(route_network)\n",
    "        new_network = networkObj(route_network, used_stops, route_graph, conn_type, set_walk_distance)\n",
    "    \n",
    "    # ERROR CHECKS----------\n",
    "    #print(\"Performing error checks...\")\n",
    "    #check_graph_with_route(new_network)\n",
    "    #check_graph_with_stops(new_network)\n",
    "    #check_order_route(new_network.routes)\n",
    "    \n",
    "    print()\n",
    "    list_of_networks_Manila.append(new_network) # Append to list of networks\n",
    "    current_network_count += 1\n",
    "\n",
    "#Export networks and graphs using pickl\n",
    "if conn_type == 'Mixed':\n",
    "    export_networks(list_of_networks_Manila, f\"{Manila_pikl_filepath}Manila_Route_networks_{conn_type}.pkl\")\n",
    "else:\n",
    "    export_networks(list_of_networks_Manila, f\"{Manila_pikl_filepath}Manila_Route_networks_{conn_type}_{set_walk_distance}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Maps for visualization\n",
    "\n",
    "i = 1\n",
    "for route_network in list_of_networks_Manila:\n",
    "    map_center = (14.599512, 120.984222)\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "\n",
    "    # Plotting in the Map\n",
    "    add_markers(route_network.stops, route_network.graph)\n",
    "        \n",
    "    for route in route_network.routes:\n",
    "        for connection in route:\n",
    "            ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "    m.save(f\"{map_html_location}Route Map-{i}.html\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genetic Algorithm (Only to generate new GA results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING GA ---------------------------------------------------------]\n",
    "# There should a pickle file already of the latest networks\n",
    "\n",
    "# GA Configuration\n",
    "population_size = 100\n",
    "num_elites = 2\n",
    "num_generations = 5\n",
    "mutation_probability = 0.2\n",
    "num_mutations_probabilities = [0.05, 0.15, 0.4, 0.2, 0.2]\n",
    "num_crossovers_probabilities = [0.1, 0.1, 0.4, 0.2, 0.2]\n",
    "mutation_threshold_dist = 300\n",
    "with_elitism = False\n",
    "with_growing_population = False\n",
    "num_mutations_per_generation = 5\n",
    "\n",
    "#Weights and Fitness Function configuration\n",
    "num_failure_removal = 4\n",
    "weight_random_failure = 0.15\n",
    "weight_targeted_failure = 0.15\n",
    "weight_connectivity = 0.7\n",
    "\n",
    "population = perform_genetic_algorithm(list_of_networks_Manila, graph_of_stops_Manila, population_size, num_elites, num_generations, mutation_probability, \n",
    "                              num_mutations_probabilities, num_crossovers_probabilities, mutation_threshold_dist, num_failure_removal,\n",
    "                                      weight_random_failure, weight_targeted_failure, weight_connectivity, 40,\n",
    "                              with_elitism, with_growing_population, num_mutations_per_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting GA Results\n",
    "unique_types = {obj.conn_type for obj in list_of_networks_Manila}\n",
    "if len(unique_types) > 1:\n",
    "    export_conn_type = \"Mixed\"\n",
    "    \n",
    "    export_networks(population, f\"{Manila_pikl_filepath}Manila_GA_Route_networks_{export_conn_type}.pkl\")\n",
    "    print(f\"Exported: Manila_GA_Route_networks_{export_conn_type}.pkl\")\n",
    "else:\n",
    "    export_conn_type = list_of_networks_Manila[0].conn_type\n",
    "    export_walk_distance = list_of_networks_Manila[0].walking_distance\n",
    "\n",
    "    export_networks(population, f\"{Manila_pikl_filepath}Manila_GA_Route_networks_{export_conn_type}_{export_walk_distance}.pkl\")\n",
    "    print(f\"Exported: Manila_GA_Route_networks_{export_conn_type}_{export_walk_distance}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Genetic Algorithm Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "map_html_location = \"GA Result Route Networks HTML/Manila/\"\n",
    "\n",
    "i = 1\n",
    "for network in population:\n",
    "    map_center = (14.599512, 120.984222)\n",
    "    m = folium.Map(location=map_center, zoom_start=10, tiles='openstreetmap')\n",
    "    add_markers(network.stops, network.graph)\n",
    "    \n",
    "    for route in network.routes:\n",
    "        for connection in route:\n",
    "            ox.plot_route_folium(CITY_GRAPH, connection, route_map=m, tiles='openstreetmap', route_color=\"green\")\n",
    "\n",
    "    m.save(f\"{map_html_location}GA Map-{i}.html\")\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
